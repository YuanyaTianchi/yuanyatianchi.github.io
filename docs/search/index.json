[{"content":"hugo  git、go环境 下载解压并配置环境变量：https://github.com/gohugoio/hugo/releases/download/v0.78.0/hugo_0.78.0_Windows-64bit.zip  #创建项目\rhugo new site yuanyatianchi.github.io\r#主题下载\rcd testblog/themes\rgit clone https://github.com/amzrk2/hugo-theme-fuji.git fuji\r#下好后将fuji\\exampleSite目录下的context、config.toml复制到项目根目录testblog替换原来的文件\r#启动\rhugo server\r 访问本地测试：http://localhost:1313\n config.toml修改  #修改baseURL为你自己的gitpage\rbaseURL = \u0026quot;https://yuanyatianchi.github.io\u0026quot;\r  部署  #打包主题，所有的静态页面默认生成到public目录，-d指定目录生成\rhugo -t fuji -d docs\r#关联远程库\rgit init\rgit remote add origin git@github.com:YuanyaTianchi/yuanyatianchi.github.io\rgit commit -a -m \u0026quot;yuanyatianchi's blog\u0026quot;\rgit push\r 远程库注意设置gitpage，设置到docs作为源\n","date":"2020-11-11","permalink":"https://yuanyatianchi.github.io/post/blog.hugo/","tags":["blog"],"title":"Hugo"},{"content":"linux   内容综述\n Linux背景介绍 系统操作 服务管理 Shell脚本 文本操作 常用服务搭建    Linux：两种含义\n Linus Benedict Torvalds（Linux之父）编写的开源操作系统的内核 广义上的基于 Linux内核 的 Linux操作系统    内核版本：https://www.kernel.org/\n 内核版本分为三个部分：主版本号、次版本号、末版本号 次版本号是奇数为开发版，偶数为稳定版。但是实际上在2.6以后不这么区分了    发行版本：RedHat Enterprise Linux、Fedora、CentOS、Debian、Ubuntu\u0026hellip;\n  终端：图形终端，命令行终端，远程终端（SSH、VNC）\n  hello  镜像  CentOS：http://mirrors.aliyun.com/centos/ ，7.8.2003/isos/x86_64/CentOS-7-x86_64-DVD-2003.iso Ubuntu：http://mirrors.aliyun.com/ubuntu-releases/ ，20.04/ubuntu-20.04.1-live-server-amd64.iso    环境 VirtualBox  新建 名称：centos7 → 文件夹：D:\\it\\virtual_machine\\VirtualBoxVM → 类型：Linux → 版本：Red Hat (64-bit) 内存大小：2048mb 现在创建虚拟硬盘 → VDI (VirtualBox 磁盘映像) → 动态分配 → 硬盘大小：20G 设置 → 存储 → 右侧光盘图标选择虚拟盘 → OK 启动 → Install CentOS Linux 7 → English DATE \u0026amp; TIME → Asia Shanghai SOFTWARE SELECTION → Minimal Install INSTALL ATION DESTINATION → 直接点done即可 NETWORK \u0026amp; HOST NAME → Ethernet (enp0s3)：ON 开始安装 → 设置ROOT PASSWORD → 安装成功后reboot  VMware  新建虚拟机，自定义，稍后安装操作系统，2cpu2核心以上，内存2048以上，NAT网络，LSI Logic，SCSI 创建新虚拟磁盘，磁盘大小20G以上，将虚拟磁盘存储为单个文件   CentOS 修改/etc/sysconfig/network-scripts/ifcfg-ens33中NOBOOT=yes，表示系统启动时激活网卡  目录  目录  /：根目录 /root：root用户的家目录 /home/username：普通用户的家目录 /etc：配置文件目录 /bin：命令目录 /sbin：管理命令目录 /usr/bin、/usr/sbin：系统预装的其他命令    命令行  命令（command）：通过使用命令调用对应的命令程序文件，如使用ls命令将调用/bin/ls程序文件 参数（option选项）：  语法  命令 \u0026lt;必选参数1 | 必选参数2\u0026gt; [-option {必选参数1 | 必选参数2 | 必选参数3}] [可选参数\u0026hellip;] {(默认参数) | 参数 | 参数} 命令行语法符号  方括号****：可选参数，在命令中根据需要加以取舍 尖括号**\u0026lt; \u0026gt;**：必选参数，实际使用时应将其替换为所需要的参数 大括号**{ }**：必选参数, 内部使用, 包含此处允许使用的参数 小括号**()**：指明参数的默认值, 只用于{ }中 管道符（竖线）|：分隔多个互斥参数, 含义为\u0026quot;或\u0026quot;, 使用时只能选择一个 省略号**\u0026hellip;**：多个参数 分号**;**：分割多个命令，命令将按顺序执行   注意：命令行语法（包括在 UNIX 和 Linux 平台中使用的用户名、密码和文件名）是区分大小写的，如commandline、CommandLine、COMMANDLINE 是不一样的  简写  多参数简写  ls -l -r -t -R\rls -lrtR #简写\r  当前目录简写  ls ./\rls . #简写。具体到文件（或目录）时无法使用\u0026quot;.\u0026quot;作简写\rls #简写\rcd ../\rcd .. #简写\rcat ./config.yml\rcat config.yml #简写\r 用户 clear #清屏。或者快捷键CTRL+L\rsu - root #切换到root用户\rexit #退出当前系统用户\rinit 0 #关机\r 帮助命令  为什么要学习帮助命令：Linux的基本操作方式是命令行，海量的命令不适合“死记硬背”，你要升级你的大脑 使用网络资源（搜索引擎和官方文档)  help help cd #查看内部命令帮助\rtype cd #查看命令类型。shell（命令解释器）自带的命令称为内部命令，其他的是外部命令\rls --help #查看外部命令帮助\r info info ls #查看ls命令的信息。info比help更详细，作为help的补充\r man  man [(1)|2|3|4|5|6|7|8|9] [文件名]：查看指定文件（程序）对应的手册（如果有的话）。这里1-9指定要查看手册的类型，因为系统中很多重名文件，所以需要分类来区分 按Q退出手册  man man #查看man命令的手册。可以看到默认的选项\u0026quot;1\u0026quot;，表示查看 可执行程序或shell命令 这一类型的文件的手册\rman ls #查看ls命令的手册。选项\u0026quot;1\u0026quot;是默认选项，可以省略\rman 1 ls\rman -a ls #查看所有名为ls的文件的手册\r 文件  一切皆文件 TAB快捷键补全文件（目录）名 路径：  / ./ ../    查看 pwd pwd #显示当前的目录名称\r cd  更改当前的操作目录  cd /path/to/...：绝对路径 cd ./path/to/...：相对路径 cd ../path/to/...：相对路径    man cd #将查看/bin/bash（一个命令解释器shell的实现）的手册，因为cd是bash的内置命令\rcd ../ #回到上一级目录\rcd .. #简写\rcd - #回到上一次使用的目录。即可以实现两个目录来回切换的效果\r ls  ls [option]... [path]...：查看指定目录下的文件：ls / /root，可以同时显示/和/root下的目录 参数（常用）  -l：ls -l，等于ls -l .，等于ls -l ./，.和./表示当前目录，省略而已。默认根据文件名顺序显示  长格式显示文件：文件类型和权限，文件个数，创建用户，创建用户所属用户组，文件大小，最后修改时间，文件名 文件类型：文件为-，目录为d   -a：显示隐藏文件。文件名以\u0026quot;.\u0026ldquo;开头即隐藏文件 -r：逆序显示（根据文件名） -h：文件大小将使用单位m、g、t等（根据文件大小自判定的） -t：按照时间顺序显示 -R：递归显示所有文件    ls -lrt / /root #列出 / 和 /root 下的所有文件\r 新建 touch  touch \u0026lt;路径文件名\u0026gt;：新建文件   mkdir  mkdir [option]... [dirName]...：新建文件夹  mkdir ./a/1 ./a/2 #指定路径新建文件夹\rmkdir a #在当前目录新建文件夹可以简写\rmkdir -p /a/b/c/d/e #-p忽略报错，已存在的不会提示报错，路径上不存在的目录也都将被新建\r 删除 rm rmdir /a #只能删除空的目录\rrm -r /a #可以删除非空目录，但是会进行递归提示询问\rrm -r -f /a #参数f使删除时不进行递归提示询问\rrm -rf / a #参数f风险很大，一定要检查好参数，如果像这样/和a之间多了个空格，即删除整个根目录和当前目录下的a目录中的所有文件，gg\r 修改 cp  cp \u0026lt;源文件名\u0026gt; \u0026lt;目标文件名\u0026gt;：复制文件 -r：可以复制目录 -v：显示复制进度 -p：保留文件原来的时间属性 -a：保留文件原来的所有属性（ls -l能看到）  cp /a/\r mv  mv \u0026lt;源\u0026gt; \u0026lt;目标\u0026gt;：移动。在同一个目录内移动即实现改名  mv ./a1/b ./a2 #移动b到a2目录下\rmv ./a1/b ./a2/bre #移动并重命名\rmv file* ./a #*匹配1或多个字符，所有对应的文件都可以被移动\r  通配符  定义: shell 内建的符号 用途:操作多个相似（有简单规律）的文件 常用通配符  *：匹配任何字符串 ?：匹配1个字符串 [xyz]：匹配xyz任意一个字符   [a-z]：匹配一个范围 [!xyz]、[^xyz]：不匹配     *：匹配一或多个字符 ?：匹配一个字符    文本 cat  cat：文本内容显示到终端  head  head：查看文件开头。默认显示10行，-5参数显示5行  tail  tail：查看文件结尾。默认显示10行，-5参数显示5行  常用参数-f 文件内容更新后，显示信息同步更新，ctrl+c停止    wc  wc：统计文件内容信息。-l参数显示文件行数  more  more：将分页显示 less more  打包和压缩  Linux的备份压缩  最早的Linux备份介质是磁带，使用的命令是tar，即打包 可以对打包后的磁带文件进行压缩储存，压缩的命令是gzip和bzip2 经常使用的扩展名是.tar.gz.tar.bz2.tgz   /etc一般是保存配置文件的目录，属于重点备份的文件，以etc为例进行打包和压缩 tar [option]... \u0026lt;目标.tar.压缩方式\u0026gt; \u0026lt;源\u0026gt;：可以采用双扩展名以方便知道是那种方式打包的  #打包\rtar cf /tmp/etc-bk.tar /etc #c表示打包，f指定文件，tar的选项没有-或者--作选项引导符；\r#解包\rtar xf /tmp/etc-bk.tar -C /tmp #x表示解包，f指定文件，-C指定要存放的位置，不指定则存放在同目录下\r#打包并压缩。可以单独使用gzip或bzip2命令进行压缩，但是tar已经集成了它们的功能。gzip压缩速度更快，bzip2压缩比例更小\rtar zcf /tmp/etc-bk.tar.gz /etc #z即使用gzip进行压缩，也可以单后缀.tgz\rtar jcf /tmp/etc-bk.tar.bz2 /etc #j即使用bzip2进行压缩，也可以但后缀.tbz2\r#解压缩并解包，即zxf或jxf\rtar x\r 文本编辑 vi  vi是多模式文本编辑器 多模式产生的原因 四种模式，通过模式的切换，就可以无需鼠标仅使用键盘进行各种各样的文本操作  正常模式(Normal-mode)：进入编辑器界面时的初始模式，显示文本内容，有光标，光标可以移动。该模式下所有键盘输入的按键都是对编辑器所下的命令。 插入模式(Insert-mode)：  Normal模式下，使用快捷键 i 进入insert模式，可以输入文本内容    命令模式(Command-mode) 可视模式(Visual-mode)   vi：进入编辑器，默认进入的是vim的版本，是原始vi编辑器的扩展，是一个同vi向上兼容的文本编辑器 vim：进入vim编辑器，或者vim \u0026lt;filename\u0026gt;以vim编辑器打开某个文件  esc回到Normal模式，有光标 正常模式  h、j、k、l：左、下、上、右，移动光标。在图形界面或远程终端上，如果有 左、下、上、右（箭头）方向键，效果是一样的，但是如果是字符终端，可能会出现乱码 复制  一行：Normal模式下，按yy可以复制一行内容 多行：Normal模式下，按3yy即可复制当前光标所在行开始的3行 光标到行尾：y$   剪切：dd、d$，与y类似 粘贴：按p键，可以在光标所在行的下一行粘贴，继续按p键可以粘贴多次 撤销：u键 重做：把撤销的内容恢复，ctrl+R 删除单个字符：x 替换单个字符：按r键，在输入新的字符 显示行数：:set nu 移动到指定行：5G移动到第5行，g移动到第一行，G移动到最后一行 ^，或者说shift+6：移动光标到一行开头 $，或者或shift+4：移动光标到一行末尾   insert  Normal模式下，使用快捷键 i 进入insert模式，光标位置不变 大写的I，进入插入模式，光标将从，光标将移动到光标所在行的开头 小写a：光标右移一位， 大写A：光标行最右 o：光标到下一行，并且是新开空行 O：光标到上一行，并且是新开空行   命令模式：  :：进入命令模式，窗口末尾显示:时即表示处于命令模式了，可以键入命令  按esc退出命令模式 w \u0026lt;filename\u0026gt;：保存文件到目标，如w /tmp/a.txt，如果是通过文件名打开的vim编辑器，只需要w命令即可保存修改 q：退出vim编辑器 wq、wq \u0026lt;filename\u0026gt;：连用，即保存并退出 q!：不保存并退出 !\u0026lt;命令\u0026gt;：如果想要临时执行一些系统命令，查看系统命令的结果，可以通过该命令来进行，如!ip addr查看ip地址，按回车即可重新回到编辑器界面   /字符串：查找指定字符串，按n跳到下一个，shift+n跳到上一个 :s/旧串/新串：替换光标所在的行的匹配的字符 :%s/旧串/新串：替换全文匹配的字符第一个字符 :%s/旧串/新串/g：替换全文匹配的字符所有 :set nu：显示行数。只单次生效，需要修改vim配置以长期生效  vim /etc/vimrc：移动到最后一行插入内容set nu，保存退出即可   :set nonu：不显示行数   Visual：可视模式  v：字符可视模式 V：行可视模式 ctrl+v：块可视模式（类似于列模式）  d：删除选中块 ctrl+i：进入插入模式，输入要插入的内容，按2次esc，可以批量给选中的每一行前面添加相同内容        用户 useradd user1 #添加新用户\r#创建用户后会在/home中创建用户对应的目录，目录名与用户名一致\rls -a /home/yuanya #会有一些隐藏文件\rtail -10 /etc/passwd #会有用户相关内容\rtail -10 /etc/shaow #会有用户相关内容，密码相关\rid #查看当前用户\rid root #查看指定用户。可以借此验证是否存在指定用户\r#用户会有唯一id，系统是通过id识别不同用户的。root用户uid=0，如果把普通用户的uid改为0，则也会被系统当作root用户对待\r#用户有用户组，创建时不指定用户组则属于其同名组，即用户组名与用户名一致，只有该用户一人\rgroupadd group1 #新建用户组\rgroupdel group1 #删除用户组\ruseradd user2 group1 #添加新用户并指定用户组\rpasswd #为当前用户自己设置密码\rpasswd yuanya #为指定用户设置密码\ruserdel yuanya#删除用户，用户的家目录/home/yuanya会被保留，文件所属用户变为数字，只有root用户可以使用，加-r则不会保留家目录。/etc/passwd、/etc/shaow中相关用户信息都将被删除\rman usermod #usermod用于修改用户属性\rusermod /home/yuanya yuanyatianchi #修改家目录/home/yuanya的名字为yuanyatianchi，相当于搬家\rusernod -g group1 yuanya #将指定用户分配到指定用户组\rman chage #更改用户密码过期信息\r#root用户切换普通用户无需密码，普通用户切换其它用户需要密码\rsu - user1 #切换用户，\u0026quot;-\u0026quot;表示用户及用户运行环境的完全切换，这里运行环境切换指自动进入到user1的家目录/home/user1，root的家目录是/root\rsu user1 #不完全切换，仍在之前用户的家目录中，但是已经没有ls读取权限了，需要手动切换user1自己的家目录\r 网络配置 网卡 查看\nip addr #查看网卡及相关信息。简写，等价于ip addr ls、ip addr show\rip addr ls ens33 #查看指定网卡。不能省略ls或show\rip addr add 10.0.0.1/24 dev ens33 #设置ip\rip link #查看网卡物理连接情况。ip link ls、ip link show等都是一样的\rip link ens33 #查看指定网卡\rip link set dev ens33 up #网卡启动\rip link set dev ens33 down #网卡停止\r 修改\n 网卡接口命名修改：默认为ens33或enp0s3之类的。没有特殊需求默认即可  vim /etc/default/grub编辑grub，在GRUB_CMDLINE_LINUX参数内容的末尾rhgb quiet的后面添加 biosdevname=0 net.ifnames=0两项，网卡命名受这两个参数影响（如下表） grub2-mkconfig -o /boot/grub2/grub.cfg更新到真正的启动配置文件 reboot重启        biosdevname net.ifnames 网卡名     默认 0 1 ens33或enp0s3\u0026hellip;   组合1 1 0 em1   组合2 0 0 eth0    网关 ip route #查看网关信息。ip route ls、ip route show等都是一样的\rip route | column -t #格式化一下\r#设置路由\rip route add default gw \u0026lt;网关ip\u0026gt; #设置默认路由\rip route add -host\u0026lt;指定ip\u0026gt; gw\u0026lt;网关ip\u0026gt; #为目的地址设置指定网关\rip route add -net\u0026lt;指定网段\u0026gt; netmask \u0026lt;子网掩码\u0026gt; gw\u0026lt;网关ip\u0026gt; #为目的网段设置指定网关\rip route add 192.168.56.0/24 via 192.168.56.2 dev ens33 #设置静态路由\r#删除路由\rip route del 192.168.56.0/24 #删除静态路由\r 网络故障排除命令  从上到下逐步分析，基本能够解决大部分网络问题了 ping www.baidu.com：到目标主机是否畅通 traceroute www.baidu.com：追踪路由。centos7没有原装 mtr www.baidu.com：检查到目标主机之间是否有数据丢失。centos7没有原装 nslookup www.baidu.com：搜索域名的ip。centos7没有原装 telnet www.baidu.com：检查端口连接状态，键入^]然后quit退出telnet。centos7没有原装 tcpdump -i any -n host 10.0.0.1 and port 80 -w /tmp/filename：更细致的分析数据包，抓包工具，后面详细讲。centos7没有原装。centos7没有原装 netstat -ntpl：查看本机服务监听地址。n显示ip地址而不是域名，t以tcp截取显示的内容（udp等就不显示了），p显示端口对应的进程，l即listen表示处于监听状态的服务。centos7没有原装，通过ss -ntpl代替 ss -ntpl：查看本机服务监听地址。n显示ip地址而不是域名，t以tcp截取显示的内容（udp等就不显示了），p显示端口对应的进程，l即listen表示处于监听状态的服务  网络服务管理   前面的很多配置都是临时的，网卡重启后就重置了，通过配置文件修改才能实现持久配置\n  网络服务管理程序分为两种，分别为SysV和systemd（centos7中新的），最好不要同时使用两套网络管理系统，可以选择关闭其一\n  SysV\n service network start|stop|restart|status：service的操作 chkconfig -list network：查看SysV服务在不同运行级别中的启用状况 chkconfig --level 2345 network \u0026lt;on|off\u0026gt;：打开或关闭运行级别为2、3、4、5的SysV服务。这样就将网络管理都交给systemd的NetworkManager了    systemd的NetworkManager额外功能在于：比如插入网线（或者连接无线）可以识别网卡激活状态自动进行一些网络激活，对个人电脑来说颇有用处，对服务器来说稍显鸡肋。如果都是新写一些脚本，可以使用systemd；如果有一些SysV的脚本需要延用，为了方便可以继续使用SysV\n systemctl list-unit-files NetworkManager.service：查看是否开启 systemctl start|stop|restart NetworkManger.service：启动、停止、重启NetworkManger systemctl enable|disable NetworkManger：启用、禁用NetworkManger      网络配置相关文件   /etc/sysconfig/network-scripts/ifcfg-ens33（根据网卡名有变）\n  BOOTPROTO=\u0026ldquo;dhcp\u0026rdquo;：遵循dhcp协议的动态ip，可以改为\u0026quot;none\u0026quot;表示静态ip\n  ONBOOT=\u0026ldquo;yes\u0026rdquo;：是否开机启动，\u0026ldquo;no\u0026quot;时则需要手动启动网卡\n  静态内容\nTYPE=Ethernet\rUUID=045d35e8-49bc-4865-b0\rNAME=eth0\rDEVICE=eth0\rONBOOT=yes\rB0OTPROTO=none #静态\rIPADDR=10.211.55.3 #地址\rNETMASK=255.255.255.0 #子网掩码\rGATEWAY=10.211.55.1 #网关\rDNS1=114.114.114.114 #nds，可以有3个，NDS1、NDS2、NDS3\r   service network restart或systemctl restart NetworkManger.service重启网卡即可生效\n    主机\n  hostname查看\n  hostname 临时主机名\n  hostname set-hostname 永久主机名\n  hosts配置文件：/etc/hosts。因为有些服务绑定的可能是主机名，所以记得在hosts文件的最后面中配置映射。否则可能启动时会卡住某些服务直到超时，会很慢\n127.0.0.1 主机名如yuanya.tianchi\r   reboot重启主机以验证\n    软件管理 rpm 软件包管理器 rpm包和rpm命令 yum仓库 源代码编译安装 内核升级 grub配置文件\n 包管理器是方便软件安装、卸载，解决软件依赖关系的重要工具  Centos、RedHat使用yum包管理器，软件安装包格式为rpm（RedhatPackageManager） Debian、Ubuntu使用apt包管理器，软件安装包格式为deb（）   rpm包格式  vim-common-7.4.10-5.el7.x86_64.rpm 软件名称-软件版本.系统版本.平台.rpm   rpm命令常用参数  -q查询软件包 -i安装软件包 -e卸载软件包   ls -l查看/dev，这里面都是设备文件，发现c和b的文件类型，c表示字符设备，b表示块设备，把光盘加载到虚拟机即加载到/dev/sr0中的，dd if=/dev/sr0 of=/xxx/xxx.iso就可以把真的光盘做成光盘镜像，块设备不能通过cp等命令直接进行操作，需要挂载（类似于windows中插入光盘后会自动挂载弹出新盘符，linux需要自行手动操作），mount /dev/sr0 /mnt ，linux下推荐挂载到/mnt目录，-t可以指定挂载类型，默认则会是自动识别。之后可以发现文件是只读的，但是可以拷贝 rmp -qa | more：a是查询所有的意思，可以查询所有系统安装的软件包，软件包很多，通过管道符 | more分屏显示，按空格下一页，按q退出 rmp -q vim-common：根据软件名查询软件包名 rmp -e vim-enhanced：卸载软件 rmp -i vim-enhanced-7.4.160-5.el7.x86_64.rpm：安装软件包。vim-enhanced依赖vim-common，如果vim-common没有被安装，将安装失败，所以需要先安装vim-common，如果把两个软件包都放在同一个目录，也可以自动安装依赖  yum   rpm问题很明显了，如果是一个庞大的依赖树，将会非常恐怖，难以人工安装，所以就有了yum仓库（包管理器），用于实现rmp安装自动依赖；还有如果版本不符合要求，还需要通过源代码编译安装软件包\n  rpm包的问题：需要自己解决依赖关系，软件包来源不可靠\n  Centos yum源：http://mirror.centos.org/centos/7/\n  国内镜像：https://developer.aliyun.com/mirror/\n  配置yum源\n  mv /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.bk #备份\rwget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo #下载ailiyun的yum源配置文件，最小安装不原装wget用curl也行\rinstall epel-release -y #安装epel，用于扩展yum仓库可以安装的软件包，比如最新的linux内核等\rwget http://mirrors.aliyun.com/repo/epel-7.repo -O /etc/yum.repos.d/epel.repo #epel的aliyun镜像配置\ryum clean all \u0026amp;\u0026amp; yum makecache #清空并刷新缓存\r apt 替换为阿里源：https://blog.csdn.net/wangyijieonline/article/details/105360138\nlsb_release -a #查看代号codename\r 到阿里源看下对应代号的源是否存在：http://archive.ubuntu.com/ubuntu/dists/ ，存在则可以根据模板进行替换\n#把所有的TODO替换成系统的codename\rdeb http://mirrors.aliyun.com/ubuntu/ TODO main restricted universe multiverse\rdeb-src http://mirrors.aliyun.com/ubuntu/ TODO main restricted universe multiverse\rdeb http://mirrors.aliyun.com/ubuntu/ TODO-security main restricted universe multiverse\rdeb-src http://mirrors.aliyun.com/ubuntu/ TODO-security main restricted universe multiverse\rdeb http://mirrors.aliyun.com/ubuntu/ TODO-updates main restricted universe multiverse\rdeb-src http://mirrors.aliyun.com/ubuntu/ TODO-updates main restricted universe multiverse\rdeb http://mirrors.aliyun.com/ubuntu/ TODO-proposed main restricted universe multiverse\rdeb-src http://mirrors.aliyun.com/ubuntu/ TODO-proposed main restricted universe multiverse\rdeb http://mirrors.aliyun.com/ubuntu/ TODO-backports main restricted universe multiverse\rdeb-src http://mirrors.aliyun.com/ubuntu/ TODO-backports main restricted universe multiverse\r #以codename=focal为例\rdeb http://mirrors.aliyun.com/ubuntu/ focal main restricted universe multiverse\rdeb-src http://mirrors.aliyun.com/ubuntu/ focal main restricted universe multiverse\rdeb http://mirrors.aliyun.com/ubuntu/ focal-security main restricted universe multiverse\rdeb-src http://mirrors.aliyun.com/ubuntu/ focal-security main restricted universe multiverse\rdeb http://mirrors.aliyun.com/ubuntu/ focal-updates main restricted universe multiverse\rdeb-src http://mirrors.aliyun.com/ubuntu/ focal-updates main restricted universe multiverse\rdeb http://mirrors.aliyun.com/ubuntu/ focal-proposed main restricted universe multiverse\rdeb-src http://mirrors.aliyun.com/ubuntu/ focal-proposed main restricted universe multiverse\rdeb http://mirrors.aliyun.com/ubuntu/ focal-backports main restricted universe multiverse\rdeb-src http://mirrors.aliyun.com/ubuntu/ focal-backports main restricted universe multiverse\r wget $ yum install wget -y\r  yum常用选项：-y：安装、更新过程中选yes  yum install [软件名]：安装软件包 yum remove [软件名]：卸载软件包 yum list查看软件列表，listl grouplist查看软件包 yum update检查yum仓库并更新所有可更新软件包，yum update [软件名]更新指定软件包   如果要使用yum中没有的或者还未更新的包，可以使用使用源代码编译安装的方式安装软件包  二进制安装 即类似与windows上的大部分软件安装方式，安装过程也需要授权各种协议，也非常麻烦\n源代码编译安装   将源代码编译成可以执行程序，copy到指定目录使用即可\n  源代码编译安装\n 获取压缩包：wget https://openresty.org/download/openresty-1.15.8.1.tar.gz 解压：tar -zxf openresty-VERSION.tar.gz 进入目录：cd openresty-VERSION/ ./configure \u0026ndash;prefix=/usr/local/openresty：当前的系统环境已经预设在源代码中了，但是没有与真正的系统环境匹配，运行可执行文件configure使其配置（没有的话看看有没有README等指导），\u0026ndash;prefix指定程序目录 make -j2：编译。j2表示用2个逻辑上的cpu进行编译，如果代码之间没有上下文依赖关系则可以提高编译速度 make install：把编译好的程序安装到\u0026ndash;prefix指定的目录    源代码编译安装可能会遇到各种错误，比如依赖问题，需要根据提示逐一解决，非常麻烦，不到迫不得已还是yum吧\n  linux内核升级\n rpm格式内核  uname -r：查看内核版本 yum install kernel-3.10.0：升级指定内核版本 yum update：升级已安装的软件包（包括linux内核）和补丁   源代码编译安装内核  yum install gcc gcc-C++ make ncurses-devel openssl-develeurutls-Deu-uevet：安装依赖包，可以看到有这么多依赖包，如果提前不知道，直接安装的话就需要逐个查看报错并安装解决 下载并解压缩内核并解压：https://www.kernel.org ，生成环境一定要用稳定stable或者长期支持langterm版本，tar xvf linux-5.1..10.tar.xz -C /usr/src/kernels解压（tar已经直接支持xz格式了） 配置内核编译参数  cd /usr/src/kernels/linux-5.1.10/ make menuconfig | allyesconfig | allnoconfig。选择menuconfig弹出会出来界面菜单自行配置，allyesconfig则全部配置yes，allnoconfig则全部配置no（甚至可能无法启动）  menuconfig配置支持NTFS文件系统：找到Filesytems，找到NTFS file system support，空格进行选择，默认为空表示no，变为[M]表示作为内核的模块，将编译进内核使用模块的方式加载，模块意味着可以移除，以减小内核体积，[*]表示固化到内核中，不能被移除。选中NTFS后还出现了子选项，比如NTFS write support表示写入支持，子选项的[*]表示固化到父选项，而不是内核。 其实这个未安装的内核，其所有配置都在内核目录下的.config文件中，启用的项等于m或者y，未启用的则被#注释掉了，非常熟悉的话甚至可以直接修改配置文件 当前使用中的内核的配置文件，在/boot目录下，如果想要沿用当前系统内核配置，拷贝配置文件即可：cp /boot/config-kernelversion.platform /usr/src/kernels/linux-5.1.10/.config 当然仍然可以再make menuconfig进入菜单进行更多修改     编译：make -j2 all，通过lscpu查看CPU信息 安装内核：注意保证磁盘空间充足，df -h可以查看磁盘分区信息  先安装内核所支持的模块：make modules_install 再安装内核：make install   reboot重启进入系统引导界面，可以发现新安装的内核可以选择了      grub配置   grub：centos7使用的是grub2，此前是grub1，grub1中所有的配置文件需要手动去编辑，要像网卡配置文件一样记住每个项是什么功能，grub2则可以用命令即可进行修改\n  grub配置文件：/boot/grub2/grub.cfg，一般不要直接编辑该文件，而是修改/etc/default/grub文件（一些基本配置），如果还有更详细的配置，可以修改/etc/grub.d/下的文件\n  grub2-mkconfig -o /boot/grub2/grub.cfg：产生新的grub配置文件\n  /etc/default/grub\n  GRUB_DEFAULT=saved。表示系统默认引导的版本内核。通过命令grub2-editenv list查看默认引导的版本内核\n grep ^menu /boot/grub2/grub.cfg：找到文本文件当中包含关键字的一行，^表示以什么开头，这里即在grub配置文件去找到以menu开头的，能够看到内核的列表，按索引以0开始 grub2-set-default 0：选择第一个内核作为linux启动时的默认引导 grub2-editenv list：查看当前默认引导内核已经改变了    GRUB_CMDLINE_LINUX：确认引导时对linux内核增加什么参数\n  rhgb：引导时为图形界面\n  quiet：静默模式，引导时只打印必要的消息，启动出现异常时可以去除quiet和rhgb以显示更多信息\n  readhat7重置root密码\n  引导界面时，选择要引导的内核，按E进入设置信息，找到linux16开头的一段，可以发现刚刚quiet、rhgb等信息，可以直接键盘输入添加更多项，在该行末尾添加rd.break，ctrl+x启动\n  进入后是内存中的虚拟的一个文件系统，而真正的根目录是/sysroot（输入命令mount可以发现根为/sysroot），在这里所做的操作是不会进行保存的，并且是只读方式的挂载，不能写，防止修复时损坏原有文件\n  mount -o remount,rw /sysroot，重新挂载到根目录并且是要可读写的，之后mount，发现有了r,w权限\n  chroot /sysroot 选择根，即设置根为/sysroot目录；\n  echo 123456|passwd \u0026ndash;stdin root 修改root密码为redhat，echo正常情况是打印到终端，这里通过管道符发送给password命令，\u0026ndash;stdin是password命令的参数，正常情况是通过终端输入，这里即表示通过标准输入进行输入，并传递给root用户。或者password 123456；或者输入passwd，交互修改；\n  SELinux安全组件，叫做强制访问控制，会对etc/password和/etc/shadow进行校验，如果这两个文件不是在系统进行标准修改的，会导致无法进入系统。vim /etc/selinux/config中可以通过设置SELINUX=disabled关闭SELinux，即使生产环境也多半会关掉它\n  或者修改/etc/shadow文件，touch /.autorelabel，这句是为了selinux生效\n  注意备份\n    exit退出根回到虚拟的root中，然后reboot\n          进程管理  进程：进行中的程序。运行中的程序，从程序开始运行到终止的整个生命周期是可管理的。C程序的启动是从main函数int main(int agrc, char*argv[])开始的，终止的方式分为正常终止、异常终止，正常终止有从main返回、调用exit等方式，异常终止有调用abort、接收信号等方式。计算机资源不足时等情况进行，进程和权限有着密不可分的关系。  进程查看 ps ps -efL\r  ps：process status，进程状态  参数 -e：可以查看更多进程，类似于win中的系统进程  -f：额外的信息UID、PPID -L：Light，表示轻量级，轻量级进程，实际上即线程   内容  PID：唯一标识进程（不同用户使用同样的程序也是不同的进程） TTY：终端的次要装置号码（minor device number of tty）。即表示当前执行程序的终端 UID：效用户id。表示进程是由哪个用户启动的信息（可修改），默认显示为启动进程的用户 PPID：进程的父进程id。（linux的 0号进程 和 1 号进程：https://www.cnblogs.com/alantu2018/p/8526970.html ，注意centos7的systemd即以前的init）     pstree：查看进程的树形结构，父子进程关系清晰，但是是静态查看的，ps是动态刷新的。非默认安装的程序，需要自行下载  top  top：系统状态，包括进程状态，是动态更新的   参数\n -p 1：指定pid查看进程    内容\n 系统状态  up：运行时长 users：当前登录用户数量 load average：平均负载，系统进行采用对不同时间内的系统负载进行的计算，3个数值分别是1、5、15分钟内的负载，1即满负载 Tasks：任务状态  total：当前运行的总进程数 running：运行进程数 sleeping：睡眠进程数 stopped：停止进程数 zombie：僵尸进程数   %Cpu(s)：cpu使用情况（平均值）  us：用户空间使用cpu占比 sy：内核空间使用cpu占比 ni：用户进程空间内改变过优先级的进程使用cpu占比 id：空闲cpu占比 wa：等待输入输出的CPU时间百分比 hi：硬件CPU中断占用百分比 si：软中断占用百分比 st：虚拟机占用百分比   KiB Mem：内存状态  total：物理内存总量 used：使用内存量 free：空闲内存量 buffers：用作内核缓存的内存量   KiB Swap：交换区状态  total：交换区总量 used：使用交换区量 free：空闲交换区量 buffers：缓冲的交换区量。内存中的内容被换出到交换区，而后又被换入到内存，但使用过的交换区尚未被覆盖，该数值即为这些内容已存在于内存中的交换区的大小，相应的内存再次被换出时可不必再对交换区写入     进程状态：  PID：进程id USER：进程所有者的用户名 PR：优先级 NI：nice值。负值表示高优先级，正值表示低优先级 VIRT：进程使用的虚拟内存总量，单位kb。VIRT=SWAP+RES RES：进程使用的、未被换出的物理内存大小，单位kb。RES=CODE+DATA SHR：共享内存大小，单位kb S：进程状态(D=不可中断的睡眠状态,R=运行,S=睡眠,T=跟踪/停止,Z=僵尸进程 %CPU：上次更新到现在的CPU时间占用百分比 %MEM：进程使用的物理内存百分比 TIME+：进程使用的CPU时间总计，单位1/100秒 COMMAND：命令名/命令行      操作\n s：按s可以输入数字更改状态刷新间隔（默认3秒/次），回车确认      控制命令 优先级 nice  nice：优先级调整。优先级值从-20到19，值越小优先级越高，抢占资源就越多。写一个无限循环的脚本demo.sh，./demo.sh运行  -n 10 ./demo.sh：设置demo.sh的优先级为10   renice：重新设置优先级  -n 15：重新设置优先级值为15    作业控制 jobs  jobs：查看后台作业的工作程序   内容  bg 1指定程序序号使其到后台运行 fg 1指定程序序号使其到前台运行，通过CTRL+Z可以再入后台并暂停挂起，可以通过bg或fg再运行    \u0026amp;  \u0026amp;：使程序后台运行  ./demo.sh \u0026amp;\r 进程的通信方式—信号   信号是进程间通信方式之一，典型用法是:终端用户输入中断命令，通过信号机制停止一个程序的运行。\n  使用信号的常用快捷键和命令\n kill -l：查看所有信号  SIGINT：2号信号，通知前台进程组终止进程，可以被程序处理，快捷键CTRL+C SIGKILL：9号信号，立即强制结束程序，不能被阻塞和处理，kill -9 [pid]      nohup：一般与\u0026amp;符号配合运行一个命令\n nohup命令使进程忽略hangup（挂起）信号：比如一个进程正在前台运行，关闭该终端则将发起hangup信号，会使该进程被关掉，如果使用nohup则忽略该信号，即使关闭终端也不会被关闭，但是会变成一个孤儿进程，因为终端关闭了，其父进程没了，但是会被新终端的1号进程作为父进程，nohup启动的进程仍然是用户有关的，会随着用户终端而改变    守护（Daemon）进程：随着开机启动，是用户无关的、在用户之前启动的进程，不需要用户终端的，因为没有终端打印日志等信息，所以一般是以文件的形式记录日志信息\n 守护进程会将其使用的目录切换为根目录，这是什么意思呢，比如windows下，如果使用一个软件的时候，你要删除这个软件所在的目录，会提示目录被使用无法删除，实际上进程运行是基于所在目录的，而根目录只有在关机或重启时才会被卸载    系统日志：/proc，这个目录下所有的内容在硬盘中默认是不存在的，它是操作系统去内存中读取信息以文件的形式进行呈现。比如启动了一个进程，会有与进程号同名的目录，类似于：/proc/27451，进入即可看到关于进程属性的文件\n ps -ef | grep sshd：sshd为例 ls -l cwd：可以看到该进程使用的目录 ls -l fd：可以看到标准输入输出及其输入输出的目录，输入一般是/dev/null表示没有，因为因为终端都没有；输出如果是nohup则一般是输出到，如果是Daemon程序一般是通过socket输出给系统日志程序，系统日志程序将打印到默认的/var/log/下进程对应的目录文件下    cd /var/log：存放系统日志，由进程通过socket通信给日志系统，写入该目录对应文件。下面是一些常见日志\n tail -f /var/log/message：该文件被写入一些系统常规日志 tail -f /var/log/dmesg：内核启动日志 tail -f /var/log/secure：安全日志 tail -f /var/log/cron：cron周期任务日志信息    使用screen命令：因为守护进程就是为了使进程脱离终端，防止进程因终端关闭而关闭，screen工具也可以实现，进入终端操作时先进入screen的环境中，即使终端因为某些原因比如网络中断而断开，screen还是可以继续运行程序，下次连接时也能过screen恢复，\n yum install screen screen进入screen环境 先按ctrl+a，然后按d，即可退出(detached) screen环境 screen -ls查看screen的会话，会话有sessionid唯一标识 screen -r sessionid恢复会话    服务管理工具systemctl\n service：执行简单，但是启动停止重启的脚本完全由你自己编写，服务控制的好坏全凭编写脚本的人决定  cd /etc/init.d：该目录存放service启动的各种服务脚本，比如network 级别：chkconfig \u0026ndash;list，可以发现已经被systemd取代了，https://blog.csdn.net/ctthuangcheng/article/details/51219848  运行级别0：系统停机状态，系统默认运行级别不能设为0，否则不能正常启动 运行级别1：单用户工作状态，root权限，用于系统维护，禁止远程登陆 运行级别2：多用户状态(没有NFS) 运行级别3：完全的多用户状态(有NFS)，登陆后进入控制台命令行模式 运行级别4：系统未使用，保留 运行级别5：X11控制台，登陆后进入图形GUI模式 运行级别6：系统正常关闭并重启，默认运行级别不能设为6，否则不能正常启动     systemctl：  vi /usr/lib/systemd/system：该目录存放systemctl启动的各种服务脚本，比如sshd.service enable：随着开机启动 级别文件：cd /lib/systemd/system，有很多.service，其中级别相关的是：ls -l runlevel*.target 查看当前级别：systemctl get-default 设置默认开机级别：systemctl set-default multi-user.target        SELinux  安全增强linux。一般是利用用户、文件的权限进行安全控制，即自主访问控制；强制访问控制：给用户、进程、文件打上标签，只要用户、进程、文件的标签能对应一致即可以允许访问和控制，比如之前的通过grub进入救援模式修改etc中的password和shadow，selinux就会拒绝访问linux的密码，就需要在根目录下/.autorelabel 会降低服务器性能 MAC（强制访问控制）与DAC（自主访问控制) 查看SELinux的命令  getenforce：查看selinux的状态。默认有3种状态，在/etc/selinux/config文件中，持久修改的话需要重启，临时修改可以通过如setenfortce 0设置 查看标签（label）：ps -Z查看进程标签，id -Z查看用户标签，ls -Z查看文件标签 /usr/sbin/sestatus ps -Z and ls -z and id -z   关闭SELinux  setenforce 0 letc/selinux/sysconfig    内存和磁盘管理  内存和磁盘使用率查看  内存：  free：默认bit为单位，-m、-g等可以指定单位 top   磁盘  fdisk：fdisk -l，fdisk -l /dev/sd?，磁盘在linux中也是文件，以扇区划分，start、end都是指扇区，system指文件系统类型为linux（或其它）类型，比如ntfs就不能被linux文件系统读取，除非格式化为linux文件系统，或者编译内核时设置开启ntfs parted -l也可以查看，与fdisk -l展示的信息基本一致 df：df -h，可以理解为fdisk的补充，可以看到分区挂载的目录等 du：ls -lh /etc/passwd查看文件占用内存，du /etc/passwd可以查看实际占用空间 du 与ls的区别：ls是记录文件开头到结尾的空间，du为实际占用空间，不会计算文件空洞，dd if=afile bs=4M count=10 of=bfile创建空洞文件，if表示输入文件，of表示输出文件，bs表示blockSize，即4M作为一个块进行读写，count表示读写次数，当afile足够大时可以创建一个40m的bfile，dd if=/dev/zero bs=4M count=10 of=afile，从/dev/zero可以读取无穷多个0，用以测试dd，ls -lh和du分别查看afile都是40m，dd if=/dev/zero bs=4M count=10 seek=20 of=bfile，seek表示跳过20个块，即有80m不写入，即将成为文件的空洞，ls -lh和du分别查看bfile分别为120、40m。比如给linux创建一个虚拟机的磁盘空间1T，但是实际只存放1m的数据，其它都是空洞     Linux支持多种文件系统，常见的有  ext4（centos6默认） xfs（centos7默认） NTFS （需安装额外软件ntfs-3g，有版权的，windows用）   ext4文件系统  结构  超级块：会记录文件数，有副本 超级块副本：恢复数据用 i 节点(inode)：记录每一个文件的信息，权限、编号等，文件名与编号不在同一inode，而是记录在其父目录的inode中。ls -i可以查到每一个文件的inode 数据块(datablock)：存放文件的数据内容，挂在inode上的，如果一个数据块不够就接着往后挂，链式   所以ls查看的是inode中的文件信息，du统计的是数据块的个数用来计算大小等。默认创建的数据块为4k，即使只写了1个字符也是4k，所以存储大量小文件会很费磁盘，所以网络上有一些专门用来存储小文件的文件系统。echo \u0026gt;写入文件只会改变数据块，而vim会改变inode，vim编辑时，会在家目录下复制一份临时文件进行修改，然后保存复制到源目录，并删除原来的文件（应该是）。rm afile4是从父inode删除文件名，所以文件再大都是秒删，ln afile bfile，将bfile只向afile并也加入到父inode，且不会占用额外空间 软（符号）连接：ln -s afile cfile，ls -li afile cfile查看可以看到，其实cfile就记录了目标文件afile的路径，链接文件的权限修改对其自身是无意义的，对其权限修改将在目标文件上得到反馈。可以跨分区（跨文件系统） facl：文件访问控制，getfacl afile查看文件权限，setfacl -m u:user1:r afile：u表示为用户分配权限，g表示用户组，r表示读权限，m改成x即可收回对应用户（组）权限   磁盘配额的使用：给多个用户之间磁盘使用做限制  分区   磁盘的分区与挂载：如果是虚拟机，可以直接在vbox上给其添加一块硬盘进行练习（比如叫sdc），可能需要关机才能添加\n  常用命令\n fdisk：fdisk -l查看，fdisk /dev/sdc2指定磁盘进行分区，会进入交互界面，输入m获取帮助，可以看到n是add a new partition即新建分区 mkfs：使用分区，输入mkfs.可以看到有很多不同后缀，都是指不同的文件系统，比如mkfd.ext4 /dev/sdc2即可格式化为ext4的文件系统。但是文件操作是文件系统之上的操作，无法直接操作，需要将其挂载到某个目录，对目录进行操作， mount：mount -t auto自动检测文件系统，或者直接mount /dev/sdc2 /mnt/sdc2也会自动检测，将/dev/sd2挂载到/mnt/sd2，但是是临时挂载，vim /etc/fstab进行修改，dev/sdc1 /mnt/sdc1 ext4 defaults 0 0，即磁盘目录 挂载目录 文件系统指定 权限(defauls表示可读写) 磁盘配额相关参数1 磁盘配额相关参数2 parted：如果磁盘大于2T，不要用fdisk进行分区，而是parted，parted /dev/sdd    用户磁盘配额：限制用户对磁盘的使用，比如创建文件数量（即限制i节点数）、数据块数量\n  xfs文件系统的用户磁盘配额quota，修改步骤如下\n  mkfs.xfs /dev/sdb1：创建分区，如果分区已经存在，为了防止这是一个误操作，会提示使用-f参数强制覆盖，mkfs.xfs -f /dev/sdb1\n  mkdir /mnt/disk1\n  mount -o uquota,gquota /dev/sdb1 /mnt/disk1，-o开启磁盘配额，uquota表示支持用户磁盘配额，gquota表示支持用户组磁盘配额\n  chmod 1777 /mnt/disk1：赋予1777权限\n  xfs_quota -x -c \u0026lsquo;report -ugibh\u0026rsquo;/mnt/disk1：有参数时直接非交互配置，xfs_quota可以直接进入交互模式，但是一般非交互即可，\n -c表示命令，report -ugibh，report表示报告（查看）磁盘配额，-u表示用户磁盘配额，g表示组磁盘配额，i表示节点，b表示块，h可以更人性化显示    xfs_quota -x -c \u0026lsquo;limit -u isoft=5 ihard=10 user1\u0026rsquo; /mnt/disk1：root是无限制的，不要对root进行磁盘配额，没意义。这里对user1进行磁盘配额，limit表示限制磁盘配额，限制用户磁盘配额加-u，限制组磁盘配额加-g；isoft软限制i节点，ihard将硬限制，软限制比硬限制的配置的值更小，达到软限制之后，会提示用户在某一个宽限的时间条件内可以用超过软限制的值，硬限制则绝对不能超过限制的值；数据块限制即bsoft、bhard\n      常见配置文件\n letc/fstab      交换分区（虚拟内存）的查看与创建\n free查看mem和swap，前面提到过 增加交换分区的大小，使用硬盘分区扩充swap  mkswap：如mkswap /dev/sdd1将标记上swap swapon：swapon /dev/sdd1打开swap，通过free可以看到swap被扩充了，swapoff /dev/sdd1关闭swap   使用文件制作交换分区：可以直接创建一个比如10G的文件，或者创建带有空洞的文件，使其在swap的使用过程中逐渐扩大也可以  dd if=/dev/zero bs=4M count=1024 of=/swapfile：创建文件 mkswap /swapfile：即可为文件打上swap标记使其成为swap的空间 chmod 600 /swapfile：为了安全起见，一般修改为600权限 swapon、swapoff   同样swap设置也是临时的，vi /etc/fstab。/swapfile swap swap defaults 0 0，即 swap文件或分区 挂载到swap目录（这是一个虚拟目录，因为swap不需要用文件目录来进行操作，挂载到这个虚拟目录即可） 文件系统格式（也是swap），第一个0表示做dump备份时要不要备份该硬盘（分区），但是现在一般都是tar进行备份，所以设置为0即可，第二个0表示开机的时候进行磁盘的自检的顺序问题，是针对之前的ext2、ext3的文件系统的设置，但是现在已经不需要了，如果发现写入是不完整的自动会对那个分区进行检查，所以也是0即可  如果写错了东西，发现重启启动不起来了，通过grap进入到单一用户模式，来去修改/etc/fstab      raid  软件RAID的使用：RAID（磁盘阵列）  RAID的常见级别及含义  RAID 0 striping条带方式，提高单盘吞吐率 RAID 1 mirroring镜像方式，提高可靠性，需要两块磁盘组成，其中有给做镜像备份 RAID5有奇偶校验，至少需要3块硬盘，2块硬盘写数据，还有1块做奇偶校验（存储2块数据盘的校验数据，该盘损坏，校验数据还是可以通过2块数据盘重新生成），当某一块数据硬盘损坏了，奇偶校验的硬盘就通过奇偶校验来通过未损坏的数据盘来还原数据，但是如果2块数据盘都损坏了，还是没办法了 RAID 10是RAID 1与RAIDO的结合，共4块，两块硬盘做raid1，两块做raid1和raid0   raid控制器（raid卡）：硬件设备，通过数据读写自动计算校验值，自动计算把数据放在哪块硬盘上的，甚至可以带有缓存功能加速硬盘访问 软件RAID的使用：对cpu性能消耗较大，一般不实际使用，而是使用raid卡  需要安装软件包yum install mdadm，练习raid建议划分3个同样大小的空白分区，做软件raid如果分区有大有小默认采用最小的空间，fdisk -l /dev/sd?? mdadm -C /dev/md0 -a yes -l1 -n2 /dev/sdb1 /dev/sdc1：-C /dev/md0创建raid，-a yes表示全部提示都选择yes，比如有数据、格式化等提示，所以要注意分区会被格式化，-l1指定raid级别为raid1，-n2表示2块硬盘是活动的，/dev/sdb1 /dev/sdc1即指定这两块硬盘，实际上可以简写为通配符形式/dev/sd[b,c]1。 可能会提示may not suitable as a boot device什么的，因为是软件不支持      物理卷 逻辑卷  逻辑卷管理：在物理卷之上的虚拟卷，linux根目录就是逻辑卷的，可以将一块硬盘拆分为多个逻辑卷，也可以将多个硬盘合并为一个逻辑卷，根据场景对逻辑卷进行缩放容  新建逻辑卷  先添加几个磁盘/dev/sdb1、/dev/sdc1、/dev/sdd1：pvcreate /dev/sdb1 /dev/sdc1 /dev/sdd1或者简写pvcreate /dev/sd[b,c,d]1，注意前面做了软件raid的磁盘如果没有停掉raid将失败  停止raid：mdadm --stop /dev/md0，破坏超级块：dd if=/dev/zero of=/dev/sdb1 bs=1M count=1、dd if=/dev/zero of=/dev/sdc1 bs=1M count=1 重新创建一下：pvcreate /dev/sd[b,c,d]1，pvs查看。信息：lvm即逻辑卷管理器、PSIZE即物理大小、PREE即物理卷的物理空间剩余量 vgcreate vg1 /deb/sdb1 dev/sdc1给物理卷分组，pvs查看可以发现已经被分到vg1这个卷组了 vgs查看卷组 lvcreate -L 100M -n lv1 vg1：从卷组vg1创建名字为lv1大小为100M的逻辑卷，lvs查看逻辑卷   使用逻辑卷：  格式化：mkdir /mnt/test、mfs.xfs /dev/vg1/lv1 进行挂载：fdisk /dev/sd?? pv vg1 lv1 xfs mount。命令解释：fdisk命令用来分区，用/dev/sd??磁盘建立一个pv，通过pv创建一个vg1，通过vg1创建lv1，lv1上通过xfs命令创建文件系统，mount将文件系统进行挂载。这个复杂过程相当实现了：pv vg1 lv1实现可动态扩展的功能，xfs使可以以文件形式操作的功能，mount实现内存和管理的映射。所以如果不需要扩展，可以直接fdisk /dev/sd?? xfs mount在sd磁盘设备上使用文件系统即可，如果还需要实现更复杂的功能还可以在其上进行raid功能（但就不能直接在磁盘上搭建逻辑卷了，需要在raid的基础上比如搭建一个/dev/md0，然后再在其上进行逻辑卷实现）   用途：可以用来扩展现有的如root、user、src 等分区   扩充逻辑卷  vgextend centos /dev/sdd1，将/dev/sdd1这个pv划分到centos这个vg下 lvextend -L +50G /dev/centos/root df -h查看发现文件系统的容量并没有变大，也需要告知文件系统卷已经扩大了，xfs_growfs /dev/centos/root   缩容 可以发现，卷管理实际上就是一层一层的，从物理磁盘到逻辑卷到文件系统    系统综合状态 sar   使用sar命令查看系统综合状态，可以对系统进行全面的体检\n  参数\n sar -u 1 10：-u是cpu信息。1是采样时间间隔，每1秒采样10次 sar -r 1 10：-r显示内存情况 sar -b 1 10：-b显示IO信息 sar -d 1 10：-d磁盘信息 -q 1 10：进程信息    使用第三方命令iftop查看网络流量情况\n yum install epel-release yum install iftop iftop -P：默认只监听eth0的网络接口    更多好用的工具自行到网络上找寻\n  shell shell：在计算机科学中，Shell俗称壳（用来区别于核），是指\u0026quot;为使用者提供操作界面\u0026quot;的软件-命令解析（解释）器，即用于解释用户对操作系统的操作，bash即shell实现之一，其它还有cat/etc/shells等\nshell会把用户所执行的命令翻译给内核，内核将命令执行的结果反馈给用户。ls为例，当输入ls时，首先由shell接收到用户执行的命令，对命令选项和参数进行分析，ls是查看文件的，将交给文件系统（属于内核层面了），然后内核把ls要查看的文件和目录翻译成硬盘对应的扇区（ssd硬盘是另外结构），硬件会把查询的结果交给内核，内核在返回给shell，最后返回给用户\nlinux启动过程   BIOS：基本输入输出系统，是主板上的功能，通过bios选择要引导的介质 - 硬盘、或光盘，如果选择了硬盘，就会有一个引导的部分-MBR\n  MBR：硬盘的主引导记录部分，就进入到linux的过程了（以下）\n  BootLoader(grub)：BootLoader指启动和引导内核的工具，现在用的grub2.0，可以引导linux内核（选择哪个内核启动），甚至是windows系统\n  kernel：内核启动\n  systemd（centos7，6中是init）：systemd启动（1号进程）。centos6时，init启动后的所有系统初始化内容都是由shell脚本完成（/etc/rc.d目录下会有大量脚本，比如用于激活软件raid、lvm等系统初始化工作），centos7中则有些内容改变为systemd的配置文件方式（到/etc/systemd/system目录下，根据启动级别来到/user/lib/systemd/system目录下，在这个目录下读取各种各样的配置文件），由应用程序引导。\n  系统初始化（）：比如通过驱动程序加载各种硬件，是由shell脚本完成的\n  shell：shell开始工作\n  bios：系统启动的时候按F2进入界面来选择不同的引导介质，如果选择了硬盘，就会有一个引导的部分-mbr，通过dd命令可以查看MBR（linux中一切皆文件，磁盘也可以当作文件被读取）\n dd if=/dev/sda of=mbr.bin bs=446 count=1，if是磁盘，of指定输出文件，bs指定块大小，count指定1个块。因为mbr.bin是没有文件系统的，所以不能通过cat直接查看其中内容，这里使用hexdump -C mbr.bin用16进制的方式去查，-C将能够显示为字符的内容显示为字符 dd if=/dev/sda of=mbr2.bin bs=512 count=1，扩大到512字节，mbr将包括自盘分区表，最后的55 aa即证明引导扇区是正确的    BootLoader：cd /boot/grub2\n grub2-editenv list：显示默认引导的内核 uname -r：查看当前所使用的内核    base   命令中也大量使用了shell脚本，以/sbin/grub2-mkconfig为例，file /sbin/grub2-mkconfig可以看到文件的描述shell script，vim打开可以发现也就是一个shell脚本\n  shell脚本区别于py、php等脚本，无需掌握那些语言函数，完全由命令构成\n  UNIX的哲学：一条命令只做一件事\n  为了组合命令和多次执行，使用脚本文件来保存需要执行的命令\n  如果是二进制可执行文件，赋予可执行（-x）权限即可，但是如果是shell脚本文件想要执行，还需要额外赋予该文件可读（-r）权限(chmod u+rx filename)\n  #比如某个目录经常反复cd进入并ls查看\rcd /var ; ls ; pwd ; du -sh ; du -sh *\r 可以保存为sh文件，比如叫tmp.sh\n#一般shell脚本头部上会加这样一个申明，这个申明叫做\u0026quot;Sha-Bang\u0026quot;\r#!/bin/bash\rcd /var ; ls ; pwd ; du -sh ; du -sh *\r #赋予权限\rchmod u+rx tmp.sh\r#可以通过bash执行，在bash中\u0026quot;#!/bin/bash\u0026quot;将被当作注释\rbash ./tmp.sh\r#直接运行，当前系统是什么shell就将用什么shell解释，\u0026quot;#!/bin/bash\u0026quot;将是非注释的，它将告诉系统使用/bin/bash来解释执行\r./tmp.sh\r  执行命令的方式  bash ./filename.sh：会在当前终端下fork一个叫做bash的子进程，通过子进程去运行脚本，所以执行脚本后当前终端线程并没有真正进入到/var目录，因为是子进程进到目录的。注意：通过bash执行脚本是不用赋予执行权限的，因为是通过bash的 ./filename.sh：也是产生子进程然后运行，不同的是通过Sha-Bang去解释运行脚本的。直接运行脚本文件，必须有可执行权限， source ./filename.sh：在当前进程运行，所以当前终端进入到了/var目录 . ./filename.sh：开头的.即source的缩写   内建命令和外部命令的区别  内建命令：内建命令不需要创建子进程，将对当前Shell 生效，如cd、pwd、source等 外部命令：需要创建子进程，不会对当前shell生效，如bash    管道 待整理    快捷键：\n TAB快捷键补全文件（目录）名 CTRL+L清屏 CTRL+C终止（命令）程序    添加执行权限：chmod a+x 文件名，a表示所有，x表示执行\n  ","date":"2020-11-11","permalink":"https://yuanyatianchi.github.io/post/ops.linux/","tags":["sys","linux"],"title":"Linux"},{"content":"redis https://redis.io/，http://www.redis.cn/\n Redis的特性  速度快  数据存在内存（主要原因） c语言编写（50000line，单机的核心代码只有23000line） 单线程：   持久化：断电不丢数据。Redis所有数据保持在内存中,对数据的更新将异步地保存到磁盘上  RDB AOF   多种数据结构：key:value，value支持以下结构  基本  Strings/Blobs/Bitmaps Hash Tables (objects!) Linked Lists Sets Sorted Sets   衍生  BitMaps：位图。本质是字符串实现 HyperLogLog：超小内存唯一值计数。本质是字符串实现 GEO：地理信息定位。本质是集合实现     支持多种编辑语言 功能丰富  发布订阅 Lua脚本 事务 pipeline   \u0026ldquo;简单\u0026rdquo;  不依赖外部库(like libevent) 单线程模型   主从复制 高可用、分布式  高可用Redis Sentinel(v2.8)支持高可用 分布式Re dis Cluster(v3.0)支持分布式     典型使用场景  缓存系统  user - AppServer - cache - Stoage：如果缓存中有直接返回，没有则到Storage中取（并存入cache）。redis则充当cache的角色   计数器  如点赞转发评论数，可以在单线程下非常高效的进行计数   消息队列系统  redis提供了发布订阅、阻塞队列来实现类似的模型，可用于实现一些对消息队列功能需求不是很强的系统时，可以直接使用redis，节省技术成本   排行榜  有序集合   社交网络  粉丝数、关注数、共同关注、时间轴列表，等都可以用redis实现   实时系统  如使用位图实现类似布隆过滤器这样的功能，实现对一些垃圾邮件过滤、实时系统处理等非常有帮助      client https://redis.io/clients ，redis客户端每种语言都有很多，自行选择\ngo redigo $ go get github.com/gomodule/redigo\r .go c, err := redis.Dial(\u0026quot;tcp\u0026quot;, \u0026quot;127.0.0.1:6379\u0026quot;)\rif err != nil {\rfmt.Println(err)\rreturn\r}\rdefer c.Close()\r/*set*/\rV, err := c.Do(\u0026quot;SET\u0026quot;, \u0026quot;hello\u0026quot;, \u0026quot;world\u0026quot;)\rif err!=nil{\rfmt.Println(err)\rreturn\r}\rfmt.Println(v)\r/*get*/\rv, err = redis.String(c.Do(\u0026quot;GET\u0026quot;, \u0026quot;hello\u0026quot;))\rif err!=nil{\rfmt.Println(err)\rreturn\r}\r/*其它命令大都类似*/\r java jedis .pom \u0026lt;!--redis-client：jedis--\u0026gt;\r\u0026lt;dependency\u0026gt;\r\u0026lt;groupId\u0026gt;redis.clients\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;jedis\u0026lt;/artifactId\u0026gt;\r\u0026lt;version\u0026gt;3.2.0\u0026lt;/version\u0026gt;\r\u0026lt;/dependency\u0026gt;\r\u0026lt;!--还可以导入jackson-databind进行redis string序列化相关操作--\u0026gt;\r Jedis直连  jedis直连：TCP连接。适用于少量长期连接的场景。存在每次新建/关闭TCP开销，资源无法控制,存在连接泄露 的可能，Jedis对象线程不安全  生成一个Jedis对象，这 个对象负责和指定Redis节点进行通信：Jedis jedis = new Jedis(\u0026quot; 127.0.0.1\u0026quot;, 6379);  构造函数很多，介绍一个：Jedis(String host, int port, int connectionTimeout, int soTimeout)  host：Redis节点的所在机器的IP port：Redis节点的端口 connectionTimeout：客户端连接超时 soTimeout：客户端读写超时     jedis执行set操作：jedis.set(\u0026ldquo;hello\u0026rdquo;, \u0026ldquo;world\u0026rdquo;); jedis执行get操作，value= \u0026ldquo;world\u0026rdquo;：String value = jedis.get(\u0026ldquo;hello' ); 关闭连接：jedis.close(); 所有 jedis 操作函数名都和 redis api 操作命令一致    jedis连接池   jedis连接池：Jedis预先生成,降低开销使用，连接池的形式保护和控制资源的使用。相对于直连，使用相对麻烦, 尤其在资源的管理上需要很多参数来保证, 一旦规划不合理也会出现问题。和一般的连接池一样，需要合理规划防止连接池爆满阻塞或者大量连接闲置等\n//初始化Jedis连接池，通常来讲JedisPool是单例的。\rGenericObjectPoolConfig config = new GenericObjectPoolConfig();\rconfig.setMaxTotal(10);\rJedisPool jedisPool = new JedisPool(config, \u0026quot;127.0.0.1\u0026quot;, 6379)\rJedis jedis = null;\rtry {\r// 1.从连接池获取jedis对象\rjedis = jedisPool.getResource();\r// 2.执行操作\rjedis.set(\u0026quot;hello\u0026quot; ，\u0026quot;world\u0026quot; );\r} catch (Exception e) {\re.printStackTrace();\r} finally {\rif (jedis != nulI) {\r//如果使用JedisPool,close操作不是关闭连接，代表归还到连接池\rjedis. close();\r}\r}\r   配置优化  commons-pool配置(1)-资源数控制  maxTotal：资源池最大连接数，缺省值8。  建议：比较难确定的，举个例子 :1.命令平均执行时间0.1ms = 0.001S；2.业务需要50000 QPS；3.maxTotal理论值= 0.001 * 50000 = 50个。实际值要偏大一些。或者通过jmx来统计后设置 业务希望Redis并发量 客户端执行命令时间 Redis资源:例如nodes(例如应用个数) * maxTotal是不能超过redis的最大连接数。(config get maxclients)   maxIdle：资源池允许最大空闲连接数，缺省值8。后面讨论  建议maxIdle = maxTotal，减少创建新连接的开销。   minIdle：资源池确保最少空闲连接数，缺省值0。后面讨论  建议预热minIdle，减少第一次启动后的新连接开销。在连接池初始化的时候提前去getResource一下   jmxEnabled：是否开启jmx监控,可用于监控，缺省值true。建议开启   借还参数  blockWhenExhausted：当资源池用尽后,调用者是否要等待。只有当为true时，下面的maxWaitMillis才会生效。缺省值true。建议使用默认值 maxWaitMillis：当资源池连接用尽后,调用者的最大等待时间(单位为毫秒)。缺省值-1，表示永不超时。不建议使用默认值 testOnBorrow：向资源池借用连接时是否做连接有效性检测(ping)，无效连接会被移除。缺省值false。建议false testOnReturn：向资源池归还连接时是否做连接有效性检测(ping)，无效连接会被移除。缺省值false。建议false    常见问题  redis.clients.jedis. exceptions. JedisConnectionException: Could not get a resource from the pool  获取空闲连接超时：Caused by: java.util.NoSuchElementException: Timeout waiting for idle object。连接池没有空闲资源了 池枯竭，资源耗尽：Caused by: java.util.NoSuchElementException: Pool exhausted。如maxIdle和minIdle不等时，   常见解决思路：  慢查询阻塞：出现一个连接查询慢，其它连接阻塞等待。需要根据业务场景合理设置超时时间 资源池参数不合理：例如QPS高、池子小。调大池子 连接泄露(没有close())：此类问题比较难定位，可通过client list、netstat等，最重要的是代码 DNS异常等    python redis-py hello redis安装 wget http://download.redis.io/releases/redis-3.0.7.tar.gz #下载\rtar -xzf redis-3.0.7.tar.gz #解压\rln -s redis-3.0.7 redis #软连接，便于升级\rcd redis #进入软连接目录\rmake #编译\rmake install # #安装\rcd src/\rll | grep redis- #查看redis-开头的文件\r   可执行文件：src目录\n redis-server：Redis服务器 redis-cli：Redis命令行客户端 redis-benchmark：Redis性能测试工具 redis-check-aof：AOF文件修复工具 redis-check-dump：RDB文件检查工具 redis-sentinel：Sentinel服务器(2.8以后)    启动方法:\n  最简启动：默认。直接执行redis-server\n  动态参数启动：指定一些动态参数。redis-server \u0026ndash;port 6380\n  配置文件启动：推荐。redis-server 。生成环境选择配置启动，单机多实例配置文件可以用端口区分开\ncd redis #进入redis目录\rmkdir config #创建config目录，可能启动很多redis，为了统一管理\rcp redis.conf config/redis-6379.conf #拷贝默认配置文件到config，以对应端口号命名\r#删掉所有注释和空格并重定向到redis-6382.conf\rcat config/redis-6381.conf| grep -v \u0026quot;#\u0026quot; | grep -v \u0026quot;^$\u0026quot; \u0026gt; config/redis-6382.conf\rvim config/redis-6382.conf #编辑\r #暂时只需要这些参数，其它都删掉\rdaemonize yes #是否以守护进程的方式启动，默认no，一般设置yes\rport 6382\rdir \u0026quot;/app/it/database/redis/data\u0026quot;\rLogfile \u0026quot;redis-6382.log\u0026quot;\r src/redis-server config/redis-6382.conf #启动\rps -ef | grep redis-server | grep 6382 #检查\rcat data/redis-6382.log #查看日志\r     启动验证\n 查看进程的方式：ps -ef | grep redis-server、ps -ef | grep redis-server | grep -v grep 查看端口是否时lesten的状态：netstat -antpl| grep redis 直接ping：redis-cli -h ip -p port ping    Redis客户端连接\nredis-cli -h 10.10.79.150 -p 6380 #连接，缺省参数为127.0.0.1和6379\rping #连接成功的话可以收到响应：PONG\rset hello world #响应：OK\rget hello #响应：\u0026quot;world\u0026quot;\r   响应\n 状态回复，如：ping→PONG 错误恢复，如：hget hello field → (error) WRONGTYPE Operation against 整数回复，如：incr hello → (integer) 1 字符串回复，如：get hello → \u0026ldquo;world\u0026rdquo; 多行字符串回复，如：mget hello foo → 1) \u0026ldquo;world\u0026rdquo; 2) \u0026ldquo;bar\u0026rdquo;    常用配置\n daemonize：是否是守护进程(no|yes) port：Redis对外端口号。缺省值6379，对应手机9宫格键盘的MERZ，取自意大利歌女Alessia Merz的名字 logfile：Redis系统日志，仅指定日志名 dir：Redis工作目录，日志、持久化文件的存储目录 RDB config、AOF config、slow Log config、maxMemory等等，后续章节介绍    docker安装 $ docker pull redis:5.0.9\r$ docker run --name redis01 -d -p 6379:6379 redis:5.0.9 redis-server --appendonly yes #run并启用持久化\r$ docker exec -it redis01 /bin/bash\r$ redis-cli #使用客户端\r$ set hello \u0026quot;world\u0026quot;\r$ get hello\r$ del hello\r api  Redis API使用和理解  通用命令  通用命令 数据结构和内部编码 单线程架构   字符串类型 哈希类型 列表类型 集合类型 有序集合类型    通用命令 info info memory：查看redis内存使用信息\nkeys O(n)\n 用于展示key。  keys命令一般不要在生产环境使用  是一个O(n)的命令 redis是单线程，会阻塞其它命令   怎么用  热备从节点：在热备从节点上使用 scan      set hello world\rset php good\rset java best\rkeys * #遍历所有key\rdbsize #计算key的总数\r mset hello world hehe haha php good phe his #批量插入数据\rkeys he* #展示以he开头的key，hehe、hello\rkeys he[h-l]* #第三个字母是h到l的范围\rkeys ph? #一个?代表一位，即长度为3位的ph开头的key\r dbsize O(1)\n 可以在生产环境使用。redis内置有计数器，实时记录key的总数，O(1)  dbsize #计算key的总数\r exists key O(1)，一般来说可以随意使用\nset a b\rexists a #存在响应：(integer) 1\rdel a\rexists a #不存在响应：(integer) 0\r del key [key ..] O(1)\nset a b\rget a #响应：\u0026quot;b\u0026quot;\rdel a #删除。删除成功响应：(integer) 1\rget a #响应：(nil)\rdel key [a k1 k2] #批量删除。删除失败响应：(integer) 0\r expire、ttl、persist O(1)\nexpire key 3 #key在3秒后过期\rttl key #查看key剩余的过期时间。-2表示key已经过期（已经不存在），-1表示key存在并且没有设置过期时间\rpersist key #去掉key的过期时间\r type key O(1)\ntype key #返回key的类型。string、hash、list、set、zset、none（不存在的key）\r 数据结构和内部编码  key：key的数据结构有 string、hash、list、set、zset  string：string内部编码有 raw、int、embstr  raw int embstr   hash：string内部编码有 hashtable、ziplist  hashtable：hash表 ziplist：压缩列表   list：string内部编码有 linkedlist、ziplist  linkedlist ziplist   set：string内部编码有 hashtable、intset  hashtable intset   zset：string内部编码有 skiplist、ziplist  skiplist ziplist     redisObject  数据类型(type)：用户只需要知道数据结构即可，而不需要知道编码方式，类似于面向接口编程 编码方式(encoding) 数据指针(ptr) 虚拟内存(vm) 其他信息    单线程  命令串行执行，类似于队列 单线程为什么这么快？  纯内存：主要原因，其它都是辅助原因 非阻塞IO：阻塞IO和非阻塞IO的区别 https://www.cnblogs.com/ynyhl/p/9792699.html 避免线程切换和竞态消耗   使用  一次只运行一条命令 拒绝长(慢)命令：keys、flushall、flushdb、slow lua script、mutil/exec、operate big value(collection) 其实不是单线程，如 fysnc file descriptor、close file descriptor 这样的操作会有独立的线程来做，但是整体模型大致是单线程的，只有极个别例外    字符串 结构和命令\n  Up to 512MB：最大512MB，但是一般不要存太大（考虑网络开销、单线程等），所以一般100KB以内差不多了，一般也够用，最多几MB吧\n  key:value\n hello world：value可以是字符串的 counter 1：value可以是数字的，是可以内部数字、字符串转换的 bits 10111101：value是二进制的 还有json、xml等序列化或者压缩的value，实际上本质上所有的key value的value都是二进制的    场景\n 缓存 计数器 分布式锁 等等    命令\n set：O(1)。设置key-value。set hello \u0026ldquo;world\u0026rdquo; get：O(1)。获取key对应的value。get hello del：O(1)。删除key-value。del hello incr：O(1)。key自增1，如果key不存在，自增后get(key)=1，即创建key并0开始计算并加1。incr count。因为redis天然单线程无竞争，不会因为大并发量记错数。所以也可以用这种方式实现自增的分布式id decr：O(1)。key自减1，如果key不存在，自减后get(key)=-1，即创建key并0开始计算并减1。decr count incrby：O(1)。key自增k，如果key不存在，自增后get(key)=k。incrby count 3 decrby：O(1)。key自减k，如果key不存在，自减后get(key)=-k。decrby count 3    实战\n  记录网站每个用户个人主页的访问量\n incr userid:pageview：如userid为1，pageview为index。则 incr 1:index string实现用户信息  一个key:value记录一个用户，如key是\u0026quot;user:1\u0026rdquo;，value是json串。使用时必须全部取出，且需要序列化开销 多个key:value记录一个用户，一个key:value记录一个属性，key命名\u0026quot;user:1:age\u0026quot;，value是属性值，key较多，内存开销多一些，且key教分散的      缓存视频的基本信息（数据源在MySQL中）伪代码\n  如用户通过vedio_id获取视频信息，先到redis中找，找到则返回，找不到则到mysql中找，返回给用户同时也将视频信息存入redis\n//伪代码\rpublic VideoInfo get(long id) {\rString redisKey = redisPrefix + id;\rVideoInfo videoInfo = redis.get(redisKey).desocialization(); //有反序列化的过程，因为redis中存的是二进制，转为VideoInfo对象需要反序列化\rif (videoInfo == nul) {\rvideoInfo = mysql.get(id);\rif (videoInfo != nul) {\rredis.set(redisKey, videoInfo.serialize()); //序列化并存入redis\r}\r}\rreturn videoInfo;\r}\r       补充：\n 选择操作  set：set key value #不管key是否存在，都设置 setnx：setnx key value #key不存在，才设置。类似于新增操作 set xx：set key value xx #key存在，才设置。类似于更新操作 无论setnx还是set xx本质上都是set命令，nx和xx类似于选项，如还有set ex，这是一个set和expire的组合命令，可以在set的同时设置过期时间，且是一个原子操作，这在分布式锁的时候非常有帮助   批量  mget key1 key2 key3\u0026hellip;：O(n)。批量获取key，原子操作。相比于 n次get = n次网络时间+n次命令时间，网络时间是巨大的开销，因为我们的程序服务器与redis可能在不同的机器、不同的机房、甚至不同的地区城市。而1次mget = 1次网络时间 + n次命令时间，节省网络时间，但要注意mget一次携带太多数据也会产生负面影响（数据量很大一般拆分开来，如1000个kv使用一次mget），且要注意时间复杂度是O(n) mset key1 value1 key2 value2 key3 value3：O(n)。批量设置key-value   more  getset key newvalue：O(1)。set key newvalue并返回旧的value append key value：O(1)。将value追加到旧的value strlen key：O(1)。返回字符串的长度（注意中文，redis中utf8的一个中文是2字节）。之所以是O(1)，是因为在存储的字符串内部也实时记录了该字符串的长度，不需要遍历字符计算长度 incrbyfloat key 3.5：O(1)。增加key对应的值3.5 getrange key start end：O(1)。获取字符串指定下标所有的值 setrange key index value：O(1)。设置指定下标所有对应的值，即给指定下标设置新的值      hash   一个key→多个field:value：类似于一个Map\u0026lt;String,Map\u0026lt;String,String\u0026raquo;\n user:1:info  name:Ronaldo age:40 Date:201 viewCounter:50      命令：\n  hget：O(1)。hget key field #获取hash key对应的field的value\n hgetall #获取所有field和value    hset：O(1)。hset key field value #设置hash key对应field的value\n  hdel：O(1)。hdel key field #删除hash key对应field的value\n  hexists：O(1)。hexists key field #判断hash key是否有field\n  hlen：O(1)。hlen key #获取hash key field的数量\n  hmget：O(n)。hmget key field1 field2\u0026hellip;fieldN #批量获取hash key的一批field对应的值\n  hmset：O(n)。hmset key field1 value1 field2 value2\u0026hellip;fieldN valueN #批量设置hash key的一批field value、\n    实战\n  记录网站每个用户个人主页的访问量\n hash记录用户信息就简单的多了。key为\u0026quot;user:1:info\u0026quot;，多个field和对应value做属性名和值。直观，可以部分更新，且节省内存。而且使用ziplist编码可以更加节省内存。但是ttl不好控制，因为过期时间无法设置到个体fied，只能针对key，想要实现只能自己写管理或删除的逻辑  hincrby user:1:info pageview count\r   缓存视频的基本信息(数据源在mysqI中)\n//伪代码，相比字符串，无须序列化和反序列化过程\rpublic VideoInfo get(long id) {\rString redisKey = redisPrefix + id;\rMap \u0026lt; String,String\u0026gt; hashMap = redis .hgetAll(redisKey);\rVideoInfo videoInfo = transferMap ToVideo(hashMap);\rif (videoInfo == nulI) {\rvideoInfo = mysql.get(id);\rif (videoInfo != nul) {\rredis.hmset(redisKey, transferVideo ToMap(videoInfo));\r}\r}\r}\r     补充：\n  hgetall：O(n)。hgetall key #返回hash key对应所有的field和value。小心使用，牢记redis是单线程，如果field过多，获取过大数据量影响很大\n  hvals：O(n)。hvals key #返回hash key对应所有field的value\n  hkeys：O(n)。hkeys key #返回hash key对应所有field\n  hsetnx：O(1)。类似setnx，hsetnx key field value #设置hash key对应field的value(如field已经存在，则失败)\n  hincrby：O(1)。类似incrby。hincrby key field intCounter #hash key对应的field的value自增intCounter\n  hincrbyfloat：O(1)。hincrbyfloat key field floatCounter #hincrby浮点数版\n    list 有序，可以重复\n 命令  rpush：O(1~n)。rpush key value1 value2\u0026hellip;valueN #从列表 右 端插入值(1-N个) lpush：O(1~n)。lpush key value1 value2\u0026hellip;valueN #从列表 左 端插入值(1-N个) linsert：O(n)。linsert key before|after value newValue #在list指定的值前|后插入newValue lpop：O(1)。lpop key #从列表 左 侧弹出一个item rpop：O(1)。rpop key #从列表 右 侧弹出一个item Irem：O(n)。Irem key count value #根据count值，从列表中删除所有value相等的项  (1) count\u0026gt;0，从左到右，删除最多count个value相等的项 (2) count\u0026lt;0，从右到左，删除最多Math.abs(count)个value相等的项 (3) count=0，删除所有value相等的项   ltrim：O(n)。ltrim key start end #按照索弓|范围修剪列表，即保留start-end，其它都删掉（不含start和end） lrange：O(n)。lrange key start end (包含end) #获取列表指定索引|范围所有item  list还有一个从右到左的索引，如从左到右索引是0~5，则从右到左则是-1~6，所以lrange key 1 5 与 lrange key 1 -1 是等价的   lindex：O(n)。lindex key index #获取列表指定索引|的item llen：O(1)。llen key #获取列表长度 lset：O(n)。Iset key index newValue #设置列表指定索弓|值为newValue   实战  TimeLine：如微博，它会将你关注用户的动态按时间排序，你的timeline中存按序存放着微博动态的id（具体内容可以存为hash或者sting之类的用id进行外联即可），关注的人有新的动态就push进来   补充  blpop：O(1)。blpop key timeout #lpop阻塞版本，timeout是阻塞超时时间，timeout=0将一直阻塞，如对空的list执行lpop将立刻return，但是如果使用blpop它就会阻塞等待，直到list不为空，然后pop一个出来。对生产者消费者模式或者消息队列有帮助 brpop：O(1)。   数据结构实现：  LRUSH + LPOP = Stack LPUSH + RPOP = Queue LPUSH + LTRIM = Capped Collection LPUSH + BRPOP = Message Queue    set  元素：无序、不可重复 命令   sadd：O(1)。sadd key element #向集合key添加element(如果element已经存在添加失败)\n  srem：O(1)。srem key element #将集合key中的element移除掉\n  scard ber (1)。scard user:1:follow = 4 #计算集合大小\n  sismember ：O(1)。sismember user:1:follow it = 1(存在) #判断it是否在集合中\n  srandmem ：O(1)。srandmember user:1:follow count= his #从集合中随机挑count个元素\n  spop：spop user:1:follow = sports #从集合中随机弹出一个元素\n  smembers：O：O(1)。smembers user:1:follow = music his sports it #获取集合所有元素，返回结果无序，数据较多时谨慎使用\n  sscan：O(1)。使用游标获取集合中的值。即扫集合中的元素，根据游标\n   实战  转发抽奖：将转发者存入集合，spop弹出 赞、踩：将点赞者存入集合，scard获取数量，当然其它数据结构也可以做 标签：给用户添加标签和给标签添加用户属于同一个事务  给用户添加标签：sadd user:1:tags tag1 tag2 tag5，sadd user:2:tags tag2 tag3 tag5，sadd user:k:tags tag1 tag2 tag4 给标签添加用户：sadd tag1:users user:1 user:3，sadd tag2:users user:1 user:2 user:3，sadd tagk:users user:1 user:2     补充：   sdiff：sdiff user:1:follow user:2:follow = music his #差集\n  sinter：sinter user:1:follow user:2:follow = it sports #交集，如共同关注\n  sunion：sunion user:1:follow user:2:follow = it music his sports news ent #并集\n  sdif | sinter | suion + store destkey .. #将差集、交集、并集结果保存在destkey中\n   TIPS  SADD = Tagging SPOP/SRANDMEMBER = Random item SADD + SINTER = Social Graph    zset 有序集合，通过打分score来实现有序，无重复element\n 一个key，多个score:element 命令  zadd：o(logN)。zadd key score element(可以是多对) #添加score和element zrem：o(1)。zrem key element(可以是多个) #删除元素 zscore：o(1)。zscore key element #返回元素的分数 zincrby：o(1)。zincrby key increScore element #增加或减少(负数)元素的分数 zcard：o(1)。zcard key #返回元素的总个数 zrank：o(n)。zrank key #获取元素从低到高的排名 zrange：o(log(n)+m)，n指元素总数，m指要获取的范围个数。zrange key start end [WITHSCORES] #返回指定索引|范围内的升序元素[分值]，WITHSCORES可选，如果写上会带上分值 zrangebyscore：o(log(n)+m)。zrangebyscore key minScore maxScore [WITHSCORES] #返回指定分数范围内的升序元素[分值] zcount：o(log(n)+m)。zcount key minScore maxScore #返回有序集合内在指定分数范围内的个数 zremrangebyrank：o(log(n)+m)。zremrangebyrank key start end #删除指定排名内的升序元素 zremrangebyscore：o(log(n)+m)。zremrangebyscore key minScore maxScore #删除指定分数内的升序元素   实战  排行榜：score设定: timeStamp saleCount followCount   补充  zrevrank：zrevrank key #获取元素从低到高的排名，与zrank相反 zrevrange：从高到低，与zrange相反 zrevrangebyscore：从高到低，与zrangebyscore相反 zinterstore：计算交集并存储 zunionstore：计算并集并存储    更多功能 慢查询  一个查询的生命周期：client 发送命令→阻塞等待排队执行（redis单线程，命令执行类似于队列）→执行命令→返回结果  慢查询发生在执行命令阶段，如hgetAll一个很大的hash 客户端超时不一定是因为慢查询，但慢查询是客户端超时的一个可能因素，因为4个阶段任意一个阶段慢了都可能导致超时   一个列表：慢查询列表，一个redis list实现的队列  如果一个命令执行时间超过了所配置的慢查询时间阈值，将作为慢查询被列入慢查询列表 慢查询列表是固定长度：由slowlog-max-len配置 慢查询列表保存在内存中   两个配置：修改配置文件（一般仅第一次启动时这样做），启动后建议动态配置即可  slowlog-max-len：配置慢查询列表大小  查看：config get slowlog-max-len。缺省值128。 动态配置：config set slowlog-max-len 1000   slowlog-log-slower-than：慢查询时间阈值。单位：微秒。为0时记录所有命令（开发调试可能用到吧，为了查看某个具体的命令临时设置一次）。  查看：config get slowlog-log-slower-than。缺省值10000。 动态配置：config set slowlog-log-slower-than 1000     三个命令  slowlog get [n]：获取慢查询队列，n指定条数 slowlog len：获取慢查询队列长度 slowlog reset：清空慢查询队列   运维经验  slowlog-max-len不要设置过小，通常设置1000左右 slowlog-log-slower-than不要设置过大，默认10ms，通常设置1ms。当然实际场景还是根据qps适当调整 理解命令生命周期 定期持久化慢查询：需要自己或者通过其它开源工具实现    pipeline   pipeline：流水线。用于打包一批命令，批量执行\n 一次网络命令通信模型：客户端传输命令（网络）→服务器计算（执行命令）→返回结果（网络）。即1次时间= 1次网络时间（1、3）+ 1次命令时间（2） 批量网络命令通信模型：n次时间= n次网络时间+ n次命令时间。 流水线通信模型：1次pipeline(n条命令) = 1次网络时间+ n次命令时间。命令时间很快（redis命令时间是微秒级的），但是网络时间可能很大（跨地区跨城市），也许会想到mget、mset，但是如果是hash结构，不存在mhmset，包括也许还想要同时统一发送get、hget，流水线就是为此存在的，将一批命令批量打包一次发送，再在服务端批量计算，按顺序将结果批量打包一次性返回 redis命令时间是微秒级的；pipeline每次条数要控制（网络因素，一次性传递巨大的数据包是不太好的）    客户端实现\n//hset 10000次。这样就只需要10次网络时间\rJedis jedis = new Jedis(\u0026quot;127.0.0.1\u0026quot; 6379);\rfor (inti = 0;i \u0026lt; 10=; i++) {\rPipeline pipeline = jedis. pipelined();\rfor (intj= i* 1000;j \u0026lt; (i+ 1) * 1000;j++) {\rpipeline.hset(\u0026quot;hashkey:\u0026quot; + j, \u0026quot;field\u0026quot; + j, \u0026quot;value\u0026quot; + j);\rpipeline.syncAndReturnAll();\r}\r}\r   对比原生操作（即m操作，如mset）\n m命令：是原子的，是redis原生支持的命令，在操作队列中就是一个命令 pipeline命令：是非原子的，将根据其中打包的命令，被重新拆为一堆pipeline子命令，然后才挨个进入命令操作队列，中间是可以穿插其它操作命令的    使用建议\n 注意每次pipeline携带数据量 pipeline每次只能作用在一个Redis节点 上    发布订阅   发布订阅：redis仅提供发布订阅的功能，但没有消息堆积的功能，新的订阅者无法从redis获取到历史消息\n  角色：发布者publisher、订阅者subscriber、频道channel\n  API\n  publish：publish channel message\nredis\u0026gt; publish yuanya:channel \u0026quot;hello\u0026quot; #向\u0026quot;yuanya:channel\u0026quot;频道发布消息\r(integer) 3 #订阅者个数\r   subscribe：subscribe [channel] #一个或多个\nredis\u0026gt; subscribe yuanya:channel #从yuanya:channel订阅消息\r1) \u0026quot;subscribe\u0026quot;\r2) \u0026quot;yuanya:channel\u0026quot;\r3) (integer) 1\r1) \u0026quot;message\u0026quot;\r2) \u0026quot;yuanya:channel\u0026quot;\r3) \u0026quot;hello\u0026quot;\r   unsubscribe：unsubscribe [channel] #一个或多个\n    补充\n psubscribe [pattern..] #订阅模式。psubscribe v* #订阅v开头的频道 punsubscribe [pattern..] #退订指定的模式。 pubsub channels #列出至少有一个订阅者的频道。pubsub numsub [channel..] #列出给定频道的订阅者数量，pubsub numpat #列出被订阅模式的数量      消息队列：消费者是竞争关系，每一条消息只被一个消费者消费一次。可以使用list来实现\n  Bitmap   位图：如 \u0026ldquo;big\u0026rdquo; 对应 ascii 码的二进制为：01100010 01101001 01100111，通过位图可以获取其每一个位的值\nset hello big #OK\rgetbit hello 0 #(integer) 0\rgetbit hello 1 #(integer) 1\r   命令\n  setbit：setbit key offset value #给位图指定索弓|设置值（值只能是0或1）。返回结果是之前该位置对应的值（如果没有值就是0），offset 跳过的中间未设置值的位将补0，所以最大offset不要突然变大，否则补0影响性能\nsetbit key 0 1 #(integer) 0。当前位图：1\rsetbit key 7 1 #(integer) 0。当前位图：10000001\rsetbit key 9 1 #(integer) 0。当前位图：1000000101\r   bitcount：bitcount key [start end]，获取位图指定范围（start到end，单位为字节，如果不指定就是获取全部）位值为1的个数\n  bitop：bitop op destkey key [key\u0026hellip;.，做多个Bitmap的and(交集)、or(并集)、 not(非)、 xor(异或) 操作并将结果保存在destkey中\n  bitpos：bitpos key targetBit [start] [end]，算位图指定范围(start到end，单位为字节，如果不指定就是获取全部)第一个偏移量对应的值等于targetBit的位置\n    实战\n  独立用户统计：总共有1亿用户\n  假如每天5千万独立访问用户，使用set和Bitmap对比\n   数据类型 每个userid占用空间 需要存储的用户量 全部内存量（一天） 一个月 一年     set 32位(假设userid用的是整型，实际很多网站用的是长整型) 50,000,000 32位 * 50,000,000= 200MB 6G 72G   Bitmap 1位 100,000,000 1位 * 100,000,000 = 12.5MB 375M 4.5G      假如每天只有10万独立用户，合适的场景使用合适的技术\n   数据类型 每个userid占用空间 需要存储的用户量 全部内存量（一天）     set 32位(假设userid用的是整型，实际很多网站用的是长整型) 1,000,000 32位 * 1,000,000= 4MB   Bitmap 1位 100,000,000 1位 * 100,000,000 = 12.5MB          经验\n 要注意的是位图type=string，所以最大是512M，大部分情况都可以满足一天的统计量，无法满足时，拆分为多个位图即可 注意setbit时的偏移量,可能有较大耗时 位图不是绝对好    HyperLogLog   基于HyperLogLog算法：极小空间完成独立数量统计。本质还是字符串\n  命令\n pfadd：pfadd key element [element .. #向hyperloglog添加元素 pfcount：pfcount key [key .. #计算hyperloglog的独立总数 pfmerge：pfmerge destkey sourcekey [sourcekey \u0026hellip;] #合并多个hyperloglog  redis\u0026gt; pfadd 2017_03_06:unique:ids \u0026quot;uuid-1\u0026quot; \u0026quot;uuid-2\u0026quot; \u0026quot;uuid-3\u0026quot; \u0026quot;uuid-4\u0026quot;\r(integer) 1\rredis\u0026gt; pfcount 2017_03._06:unique:ids\r(integer) 4\rredis\u0026gt; pfadd 2017_ 03_06:unique:ids \u0026quot;uuid-1\u0026quot; \u0026quot;uuid-2\u0026quot; \u0026quot;uuid-3\u0026quot; \u0026quot;uuid-90\u0026quot;\r(integer) 1\rredis\u0026gt; pfcount 2017_03_06:unique:ids\r(integer) 5\r  内存消耗(百万独立用户)：1天 15KB    经验\n 是否能容忍错误? (官方给出错误率: 0.81%) 是否需要单条数据?不能单独取出    GEO  GEO(地理信息定位)：存储经纬度,计算两地距离,范围计算等 应用场景：实现如微信摇一摇这种类似功能、计算附近一定距离的酒店  5个城市经纬度  北京，116.28，39.55，beijing 天津，117.12，39.08，tianjin 石家庄，114.29，38.02，shijiazhuang 唐山，118.01，39.38，tangshan 保定，115.29，38.51，baoding     api  geo：geo key longitude latitude member [longitude latitude member\u0026hellip;] #增加地理位置信息 geopos：geopos key member [member\u0026hellip;] #获取地理位置信息 geodist：geodist key member1 member2 [unit] #获取两个地理位置的距离  unit：m(米)、 km(千米)、mi(英里)、ft(尺)   georadius：georadius key longitude latitude radiusm|km|ft|mi [withcoord] [withdist] [withhash] [COUNT count] [asc|desc] [store key] [storedist key] georadiusbymember：georadiusbymember key member radiusm|km|ft|mi [withcoord] [withdist] [withhash] [COUNT count] [asc|desc] [store key] [storedist key] #获取指定位置范围内的地理位置信息集合  withcoord：返回结果中包含经纬度。 withdist：返回结果中包含距离中心节点位置。 withhash：返回结果中包含geohash COUNT count：指定返回结果的数量。 asc|desc：返回结果按照距离中心节点的距离做升序或者降序。 store key：将返回结果的地理位置信息保存到指定键。 storedist key：将返回结果距离中心节点的距离保存到指定键      持久化  持久化：redis所有数据保持在内存中,对数据的更新将异步地保存到磁盘上  快照：将数据备份。如 MySQL Dump、Redis RDB 日志：记录所有数据更新操作到日志，数据丢失时，完整重走一边日志记录的操作即可恢复。如 MySQL Binlog、Hbase HLog、Redis AOF    RDB 在硬盘创建RDB文件（二进制）备份数据，redis启动的时候载入RDB文件。主从复制中也可以用RDB文件做复制媒介\n触发机制 触发机制-主要三种方式\n  save：该命令是同步的。主动创建RDB文件，执行时将阻塞redis。不会消耗额外内存\n 文件策略：如存在老的RDB文件，将替换 复杂度：O(n)    bgsave：异步。主动创建RDB文件，将调用fork()（fork非常快，会消耗一定内存，使用不当还是可能发生阻塞），开一个子进程来执行，不会阻塞redis客户端命令（除了fork）\n 文件策略：如存在老的RDB文件，将替换 复杂度：O(n)    自动：达到某些条件时自动触发RDB文件生成（bgsave方式），save配置。自动生成的文件为./dump.rdb\n  以下是redis默认的3条save配置，满足任意一个即可触发\n   配置 seconds changes 说明     save 900 1 900秒改变（增删改等）了1条数据，生成rdb文件。即使每900秒只改变1条，也会每900秒生成rdb文件   save 300 10 300秒改变了10条数据，生成rdb文件   save 60 10000 60秒改变了10000条数据，生成rdb文件      无法控制生成rdb的频率，写操作大的情况可能会很高\n  默认配置\nsave 900 1\rsave 300 10 save 60 10000\rdbfilename dump.rdb #rdb文件文件名\rdir ./ #rdb文件保存目录\rstop-writes-on-bgsave-error yes #如果bgsave发生error，是否停止写入\rrdbcompression yes #是否采用压缩格式\rrdbchecksum yes #是否进行校验和检验\r   推荐配置\n#删掉默认save配置\rdbfilename dump-${port}.rdb #因为一台机器可能有多个redis\rdir /bigdiskpath #选择一个较大的磁盘路径，甚至可能根据不同端口上的redis分盘\rstop-writes-on-bgsave-error yes\rrdbcompression yes\rrdbchecksum yes\r     触发机制补充-不容忽略方式\n 全量复制：如主从复制时，主会自动生成RDB文件 debug reload：debug级别的重启，不清空内存的重新加载，这也会触发生成RDB文件 shutdown：执行shutdown时会执行一个shutdownsave，也会生成RDB文件    试验\n  save阻塞：执行save同时在另一个窗口get一下，可以发现在save完成之前是阻塞的\n  bgsave fork：执行bgsave时立马查看进程，可以发现有多出一个子进程（执行完后消失），文件夹多出一个临时rdb文件（执行完后用替换掉原来的dump-6379.rdb）\ndata ps -ef | grep redis- | grep -V \u0026quot;redis-cli\u0026quot; | grep -V \u0026quot;grep\u0026quot;\r501 36775 1 0 10:22下午 ?? 0:17.91 redis-server *:6379\r501 36954 36775 0 10:28下午 ?? 0:02.81 redis-rdb-bgsave *:6379 #子进程\r\u0026gt; data ll\rtotal 1126064\r-rw-r--r-- 1 carlosfu staff 1.9K 10 6 22:29 6379.10g\r-rw-r--r-- 1 carlosfu staff 459M 10 6 22:28 dump-6379.rdb\r-rw-r--r-- 1 carlosfu staff 90M 10 6 22:29 temp-36985.rdb #临时文件\r   真的自动?是的\n  RDB长啥样?二进制文件，看不懂\n     总结与问题   总结\n  RDB是Redis内存到硬盘的快照,用于持久化。\n save通常会阻塞Redis。 bgsave不会阻塞Redis ,但是会fork新进程。 save自动配置满足任一就会被执行。 有些触发机制不容忽视    问题\n 耗时、耗性能  O(n)数据:耗时 fork() :消耗内存，copy-on-write策略 DiskI/O : IO性能   不可控、丢失数据  T1：执行多个写命令 T2：满足RDB自动创建的条件 T3：再次执行多个写命令 T4：宕机，T3的命令将丢失      AOF   AOF文件：记录所有写命令到AOF文件。\n 如客户端发送set hello world命令→rerdis保存set hello world命令到AOF文件。 如果宕机了，重启redis时载入aof文件进行恢复    三种策略 三种策略：aof并不是直接写入磁盘，是写在磁盘的缓冲区中，缓冲区根据策略刷新到磁盘（为了提高写入）\n always：每条命令都fsync到硬盘。不会丢失数据，io开销大，一般sata盘只有几百tps everysec：默认策略。每秒把缓冲区fsync到硬盘。有可能丢失最后1秒的命令。一般就使用everysec no：操作系统os决定fsync。不用管，不可控。一般不使用  AOF重写 AOF重写：对redis当前在内存中的数据进行一次回溯，回溯成一个新aof文件，并覆盖旧aof文件\n  因为要记录每条写命令，长期下来aof文件会变得很大，恢复和写入都有一定性能影响。进行重写优化，来减少硬盘占用量、加速恢复速度\n  例子：例子只是作用效果举例，不是真的对原aof文件重写，实际是内存数据回溯\n 假如有set hello world、set hello java、set hello hehe是aof中的记录，实际上只有最后一条是有意义的，AOF重写就会优化为只记录最后一条命令set hello hehe 如incr counter、incr counter优化为set counter 2（假如incr了1e次，将优化了太多） 如rpush mylist a、rpush mylist b、rpush mylist c，优化为rpush mylista bc 设置过期时间并已经过期的数据，其相关操作直接优化为无了    实现\n bgrewriteaof：异步，fork一个子进程执行 AOF重写配置：aof重写自动触发相关配置  配置  auto-aof-rewrite-min-size：AOF文件重写需要的尺寸 auto-aof-rewrite-percentage：AOF文件增长率   统计  aof_current_size：AOF当前尺寸(单位:字节) aof_base_size：AOF_上次启动和重写的尺寸(单位:字节)   触发时机：以下条件需要同时满足  当前尺寸\u0026gt;AOF文件重写需要的尺寸：aof_current_size \u0026gt; auto-aof-rewrite-min-size 当前增长率\u0026gt;AOF文件增长率：aof_current_size - aof_base_size / aof_base_size \u0026gt; auto-aof-rewrite-percentage        流程：bgrewriteaof命令发送给redis父进程。父进程fork一个子进程，去执行回溯；同时父进程任然会将新收到的写命令写入缓冲aof_buf并同步到旧aof文件；同时还会将新收到的写命令写入另一个缓冲当中aof_rewrite_buf，这个buf会在新aof文件生成完毕之后补充进去。最后新aof文件覆盖旧aof文件\n  配置\nappendonly yes #默认值是no。开启以使用aof重写相关功能\rappendfilename \u0026quot;appendonly-${port}.aof\u0026quot; #命名\rappendtsync everysec #同步策略\rdir /bigdiskpath #选一个大磁盘目录，甚至在比较严格情况情况下分盘\rno-appendtsync-on-rewrite yes #在aof重写的时候，是否不执行旧aof文件的append同步操作，yes即不做这个操作。如果是完全不允许丢失数据的场景，就设置no，因为万一aof重写时宕机，这段时间的数据可能就丢失了\rauto-aof-rewrite-percentage 100\rauto-aof-rewrite-min-size 64mb\raof-load-truncated yes #重启加载aof文件时，如果出现错误是否忽略，因为可能重写时只刷入一半缓存时宕机，造成文件内容不完整\r   aof文件内容：\ndata\u0026gt; head appendonly.aof\r*2 # *指定接下来的一个命令是几个参数。下面这个命令有2个参数\r$6 # $指定接下来的一个参数是几个字节。下面这个参数有6个字节\rSELECT #确实是6个字节\r$1\r0 #select 0即选中了0号数据库\r*3\r$3\rset\r$5\rhello\r$5\rworld\r   取舍和选择   对比\n   命令 RDB AOF     启动优先级（如果都配置了，优先启动谁） 低 高   体积 小 大   恢复速度 快 慢   数据安全性 丢数据 根据策略决定   轻重 重（每次从内存全部写入硬盘） 轻（每次只追加缓冲内的）      RDB最佳策略\n \u0026ldquo;关\u0026rdquo;，但是启动时主从复制时全量复制还是会用到RDB，所以是无法彻底关闭的 集中管理：用于备份数据是不错的选择 主从，从开?：有时候需要在从节点开启RDB，以保存历史的RDB文件，但要控制自动生成的力度，不要太频繁，因为redis一般都是混合部署，单机多部署，而RDB是一个重操作    AOF最佳策略\n \u0026ldquo;开\u0026rdquo;：缓存和存储。因为一般是每秒追加缓存同步，如果丢失数据，从数据源加载即可，redis毕竟大多只作缓存，不是数据源。如果对数据源压力不大，redis也只是起到一定缓存作用，关掉也无妨，因为AOF每秒追加缓存到磁盘确实是有一定开销的 AOF重写集中管理：一般分配百分之六七十内存给redis，剩下的要留给做类似fork这样的操作，因为单机多部署，可能AOF重写集中发生，产生大量fork，就可能内存爆满等情况 everysec：建议使用everysec策略    最佳策略\n 小分片（没听懂，对fork不熟）：使用max memory（最大内存）对redis进行规划，如每个redis的max memory只设置4g，这样fork、rdb复制传输、等操作都只会产生较小的开销。但也有缺点，分布式下，产生更多的redis进程可能对cpu占用更多 缓存、存储：根据存储和缓存的特性来决定是否使用那种的策略 监控(硬盘、内存、负载、网络) 足够的（冗余）内存    开发运维常见问题 （很多没搞懂，对fork和linux不熟）\n fork操作：fork操作本身，不包括fork后产生的子进程  fork操作本身，是一个在主进程中完成的同步操作，只是做一个内存页的拷贝而不是完全做内存的拷贝，所以大部分情况下速度是非常快的。但如果fork操作本身较慢，则会阻塞redis主进程 与内存量息息相关：内存越大，耗时越长(与机器类型有关) info: latest fork_ usec：查询上一次fork操作消耗的微秒数，如果对此要关注，可以做一些监控或相对应的告警 改善fork  优先使用物理机或者高效支持fork操作的虚拟化技术 控制Redis实例最大可用内存: maxmemory 合理配置Linux内存分配策略: vm.overcommit _memory= 1。默认值0，如果没有足够内存做内存分配的时候（内存较低时）就不去分配，这将造成fork阻塞 降低fork频率：例如放宽AOF重写自动触发时机，不必要的全量复制     进程外开销：子进程开销和优化  CPU：  开销：RDB和AOF文件生成，属于CPU密集型（写入是一个集中的过程） 优化：不做CPU绑定（如果绑定，会和主进程集中消耗cpu，可能对主进程造成很大资源影响），不和CPU密集型应用部署在一起   内存：  开销: fork内存开销，copy-on-write。因为子进程是通过fork来产生的，理论上占用内存是等于父进程，但是linux有一个显式复制的机制copy-on-write，父子进程共享相同的物理内存页，当父进程有写请求的时候，会创建一个副本，相当于这是才会消耗内存，而在整个期间子进程会共享fork时父进程的内存的快照，即在做如aof重写fork产生子进程过程中，如果父进程有大量内存写入，就证明子进程的内存会开销比较大，因为它会做一个副本，如果父进程没什么写入，实际上子进程也就开销不了多少内存 优化: echo never \u0026gt; /sys/kernel/mm/transparent hugepage/enabled   硬盘  开销: AOF和RDB文件写入，可以结合iostat、iotop等工具分析 优化  不要和高硬盘负载服务部署一 起:存储服务、消息队列等 no-appendfsync-on-rewrite = yes 根据写入量决定磁盘类型:例如ssd 单机多实例持久化文件目录可以考虑分盘       AOF追加阻塞  everysec流程：  主线程将命令写入aof缓冲区；主线程还会负责对比上次fsync时间，如果距离上次fsync时间小于2秒，主线程返回继续其它操作，否则阻塞直到同步完成，这是为了保证aof文件安全性的策略 同时还有一个AOF同步线程，用来每秒将缓冲区内容同步到硬盘，并且会记录最近一次fsync时间   问题：  主线程阻塞问题 aof丢失的数据，最大可达2秒   AOF阻塞定位  Redis日志：Asynchronous AOF fsync is taking too long (disk is busy?). Writing the AOF buffer without waiting for fsync to complete, this may slow down Redis info persistence：记录上述过程发生的数量，aof_ delayed fsync: 100。没发生一次+1 查看硬盘：top命令，查看是否有发生io资源紧张的时间   硬盘优化策略，在上面已经有了，根据实际情况考量即可   单机多实例部署  Redis缓存  缓存的使用与设计  缓存的受益与成本 缓存更新策略 缓存粒度控制 缓存穿透优化 无底洞问题优化 缓存雪崩优化 热点key重建优化    缓存的受益与成本  收益  加速读写  通过缓存加速读写速度：如CPU L1/L2/L3 Cache、Linux page Cache加速硬盘读写、浏览器缓存、Ehcache缓存数据库结果。   降低后端负载  后端服务器通过前端缓存降低负载：业务端使用Redis降低后端MySQL负载等     成本  数据不一致：缓存层和数据层有时间窗口不一致，和更新策略有关。如redis做缓存层，mysql做数据源，需要将数据源的数据放到缓存层进行缓存，而数据源更新时缓存需要如何更新？是立刻发出通知还是，按时间间隔轮询自动更新，还是懒加载用到时才更新。策略要根据所能容忍的时间窗口或范围来决定 代码维护成本：多了一层缓存逻辑，缓存的读写、缓存与数据库的沟通等 运维成本：例如Redis Cluster 经济成本：实体机器成本或者云计算机器成本   使用场景  降低后端负载  对高消耗的SQL：join结果集/分组统计结果缓存。比如做排行榜计算，涉及很多表，做一个实时计算，很复杂，我们不需要每次都实时计算，只需要计算某个时间点的结果进行缓存即可   加速请求响应:  利用Redis/Memcache优化IO响应时间   大量写合并为批量写  如计数器：如果真的需要将计数写入DB，我们不能每次计数都写DB，先Redis累加再批量写DB      缓存更新策略 缓存的数据通常都有生命周期，需要做定期更新或删除以保证空间在可控范围内，且保证数据的定期更新。但是缓存中的数据和真实的数据可能存在不一致，需要一个合理的更新策略来保证数据的不一致在可容忍范围内\n  LRU/LFU/FIFO算法剔除：例如maxmemory-policy，最大内存对应的策略，在达到最大内存时执行的策略\n LRU：把最近没有使用的key删除，保证不超过maxmemory，尽可能保证了数据安全。还有all keys lru，即在所有的键去执行LRU 使用场景：需要控制配置maxmemory    超时剔除：例如expire。设置过期时间，时间内访问到缓存中读来保证性能，如果时间内用户更行了一些重要的信息，expire就不太好了，所以对于不重要的信息可以expire，比如一个视频信息的说明修改了一个标点符号，可能时间内信息不一致是可以容忍的，但如果是涉及钱的金融方面的信息，肯定就不能用这样的策略了\n  主动更新：开发控制生命周期。用户信息在存储层发生了变化，如果对应的缓存层能通过业务代码或者开发一些工具能知道存储层的变化，比如订阅存储层一些消息的变化，比如更新存储层时会发布一条消息，缓存层收到消息则主动更新或者做一次重建，到数据层重新取一次数据然后缓存，来实现数据的一致性，虽然仍然不是完全一致的强一致性，而是需要一个最终一致性，最终实现一致性的时间也是比较短的，即由该更新机制保证的\n   策略 一致性 维护成本     LRU/LIRS算法剔除 最差 低   超时剔除 较差 低   主动更新 强 高      建议：\n 低一致性环境：最大内存和淘汰策略。随意往缓存里扔就行了，达到最大内存就淘汰即可，淘汰什么也无所谓，没有的话下次再到存储层读取重新构建缓存即可 高一致性情境：超时剔除、主动更新结合，超时策略为主动更新兜底，最大内存和淘汰策略做最终兜底。主动更新的代码是开发人员自己维护的，万一出了问题，没有将真正的数据删除，后期我们无法发现这样的问题，那么我们就给数据设置一个较长的过期时间，如果出了问题，最终数据也会被超时剔除，当然这里的数据指真正有生命周期的，确实要在一定时间后过期的，如果有数据真的是不会过期，就不能设置过期时间。最后是最大内存和淘汰策略兜底，因为无法保证那天监控不到位内存就上去了，保证高可用性，而不会直接爆内存导致缓存不可用  缓存粒度控制  从MySQL获取用户信息：select * from user where id= {id} 设置用户信息缓存：set user:{id} \u0026lsquo;select * from user where id= {id}'。缓存数据来源于存储层，是需要做一个两者间映射的，key需要id值，value是select * from user where id= {id}的结果值，可能需要很多操作，如果对它做一个压缩，或者不使用字符串类型，使用hash类型，将每一个属性变成hash的field和value 缓存粒度：到底是缓存select *得到的所有字段还是仅仅缓存需要的字段  全部属性：set user:{id} \u0026lsquo;select * from user where id={id} 部分重要属性：set user:{id} select importantColumn1, \u0026hellip;importantColumnK from user where id={id}\u0026rsquo;   缓存粒度控制-三个角度  通用性：全量属性更好   占用空间：部分属性更好 代码维护：表面上全量属性更好。不会出现有新的业务需求时，需要用到的字段没有，还要重新到存储层单独取字段又更新到缓存。但是大部分时候，需求和业务固定了，我们只需要缓存我们需要的属性，而不需要过多考虑扩展性，虽然考虑扩展性是一个很好的习惯，但是在使用缓存的时候要更多考虑空间占用和性能问题，因为内存空间珍贵，而缓存也更是为了解决性能问题而存在的。所以还是要综合考虑  缓存穿透优化   缓存穿透：key对应的数据在数据源并不存在，每次针对此key的请求从缓存获取不到，请求都会到数据源，从而可能压垮数据源。比如用一个不存在的用户id获取用户信息，不论缓存还是数据库都没有，若黑客利用此漏洞进行攻击可能压垮数据库。\n  缓存穿透问题-大量请求不命中：request打到cache上，如果miss未命中，就会把流量往下引到storage层，正常情况存储层拿到对应的结果回写cache并返回response，当下次再有同样的数据请求时就可以直接命中cache，不需要到存储层取了。但是如果cache中miss时，storage也miss，将响应一个空的业务，当下一次再进行同样的请求时，他仍然会先访问cache再导到storage，并任然全部miss响应空，所有的流量都会打到存储层，这就是缓存穿透。缓存穿透使得缓存失去了意义，因为本来缓存就是为了保护存储层的，如果有大量这样的请求穿透缓存直击存储层，会给存储层带来很大的隐患\n  原因\n 业务代码自身问题：比如从mysql拿了数据，结果存的时候用了空的或错的变量，导致存入了mysql原本根本不存在内容，并且还将key响应了出去供用户使用 恶意攻击、爬虫等等：我们知道虽然一般视频网站的url做了很多加密，来防止别人猜到视频的id规则，但别人仍然可以强制访问不存在的id，就可能会发生缓存穿透    发现\n 业务的响应时间：一般都会有监控系统，平时缓存扛了很大量，并且响应速度会很快，是可预期的，如果出现缓存穿透，必然会在响应时间上有所体现 业务本身问题 相关指标：总调用数、缓存层命中数、存储层命中数，比如采集每分钟的变化，可以知道有没有这样的问题    解决方法\n  缓存空对象：如果缓存穿透，存储层返回了null，我们仍然将null当作结果，配合请求的id值将其回写到缓存层。\n 使用：当然请求的数据可能是真的不可用，也可能比如存储层对外提供了接口，该节点暂时不可用，等等原因，那么就可以将null结果的cache设置过期时间，就可以在过期时间内暂缓缓存穿透对存储层带来的影响 两个问题：  需要更多的键：会占用额外的空间，为了不使key越堆越多，设置过期时间就是一个较好的方法 缓存层和存储层数据\u0026quot;短期\u0026quot;不一致。在null缓存过期时间内都是不一致的，可以订阅消息，尽量使存储层恢复后能马上同步回写数据刷新null缓存的这个key，甚至可以使用消息队列单独定位到某个key或者某个业务，来解决不一致问题。当然仍然不是强一致的，永远会存在短期的不一致   总的来说是一个不错的解决方式  //java伪代码。具体的过期时间还有逻辑要根据实际开发需求进行变动\rpublic String getPassThrough(String key) {\rString cacheValue = cache.get(key);\rif (StringUtils.isBlank(cacheValue)) {\rString storageValue = storage.get(key);\rcache.set(key, storageValue);\r//如果存储数据为空，需要设置一个过期时间(300秒)\rif (StringUtils.isBlank(storageValue)) {\rcache.expire(key, 60 * 5);\r}\rreturn storageValue;\r} else {\rreturn cacheValue;\r}\r}\r   布隆过滤器拦截：通过很小的内存来实现对数据的过滤。比如巨大的电话本，10E行，判断一个电话是否在这个电话本里。电话本如此巨大不可能放在内存中，bloom filter就是解决类似问题的，可以通过一些算法将电话本这样的大数据放在bloom filter预热一遍，当下次访问需要判断一个电话是否在这个电话本里的时候，可以用很小的内存来解决这个问题。bloom filter后面说明\n bloom filter在cache前再做一次拦截，如果在bloom filter这里被过滤了，就不认为请求的数据是有效的，没被过滤才能到cache层去。问题就在于bloom filter如何去生成？离线去生成或者如何去做？对于固定的数据很好解决，对于频繁更新的数据要如何解决就有很多问题了。比如一个非实时的推荐服务，根据用户前一天的日志给出第二天的结果，一般就可以在夜间去计算，存储在如hbase上，对于第二天来说这就是一个比较固定的数据，有每个用户的行为，可以把每个用户的key做成布隆过滤器，就会是一个相对可信的布隆过滤器，而如果是现在大多数的实时推荐，需要实时更新布隆过滤器，就相对不可信，可能会不完全符合实时。所以说布隆过滤器是有一定局限性的，需要特殊使用场景，布隆过滤器本身也需要单独维护代码，实现过滤也是需要额外的空间来完成的       缓存击穿 缓存击穿：key对应的数据存在，但在redis中过期，此时若有大量并发请求过来，这些请求发现缓存过期一般都会从后端DB加载数据并回设到缓存，这个时候大并发的请求可能会瞬间把后端DB压垮。业界比较常用的做法，是使用mutex。简单地来说，就是在缓存失效的时候（判断拿出来的值为空），不是立即去load db，而是先使用缓存工具的某些带成功操作返回值的操作（比如Redis的SETNX或者Memcache的ADD）去set一个mutex key，当操作返回成功时，再进行load db的操作并回设缓存；否则，就重试整个get缓存的方法\n 解决：通过redis的setnx（不存在才set）设置key做互斥锁，设置成功的才去数据库加载数据  缓存雪崩优化  缓存雪崩：当缓存服务器重启或者大量缓存集中在某一个时间段失效，这样在失效的时候，也会给后端系统(比如DB)带来很大压力。加锁或者请求队列，还有尽量不要使大量数据的过期时间在同一个时间段 缓存失效时的雪崩效应对底层系统的冲击非常可怕！大多数系统设计者考虑用加锁或者队列的方式保证来保证不会有大量的线程对数据库一次性进行读写，从而避免失效时大量的并发请求落到底层存储系统上。还有一个简单方案就时讲缓存失效时间分散开，比如我们可以在原有的失效时间基础上增加一个随机值，比如1-5分钟随机，这样每一个缓存的过期时间的重复率就会降低，就很难引发集体失效的事件  https://zhuanlan.zhihu.com/p/75588064\n无底洞问题优化   问题描述\n 2010年, Facebook有了3000个Memcache节点。 发现问题：\u0026ldquo;加\u0026quot;机器性能没能提升，反而下降。节点过多了    关键点：批量操作的变化，如mget，单机是一个原子操作O(1)，集群则不是，前面提到过了\n 更多的机器!=更高的性能 批量接口需求(mget,mset等) 数据增长与水平扩展需求：服务端水平扩容无非就是加节点、加机器，而客户端又需要更高的性能    优化思路：如redis这种命令本身很快的，就更多考虑优化网络时间，但是如果是mysql这种可能命令会执行极慢的关系型数据库，可能就需要更多考虑优化sql本身。不过一般情况下mysql本来也不需要像redis那么高的性能。要学会根据不同类型数据库调整不同的优化思路\n 命令本身优化：例如慢查询keys、hgetall bigkey 减少网络通信次数 降低接入成本：例如客户端长连接/连接池、NIO等    优化方法：跟前面一样，不再赘述\n 串行mget 串行IO 并行IO hash_tag     热点key重建优化   缓存重建：到cache中获取数据，miss则到数据源获取，这个过程就是缓存重建\n  问题：比如一个微博大V在重要的时间节点发布了一个重要消息会落在一个重要的key上，成为一个有极大访问量的热点key，在重建完成之前，有巨大的多线程的访问打过来，那么每个线程都miss，都都要去数据源取，即很多线程都参与重建，重建可能很慢，比如是一个复杂的sql、一个很慢的api，这就产生了问题，每个线程都要执行一遍重建过程，会很浪费时间，会对数据源造成巨大压力，\n  三个目标\n 减少重缓存的次数 数据尽可能一致 减少潜在危险：比如死锁，线程池被阻塞等    解决\n  互斥锁(mutex key)将重建的过程上互斥锁，其它线程则阻塞等待，重建好之后，其它线程则可以直接获取缓存。个人理解：为了防止大量线程都阻塞等待，可以直接响应一些提示内容\n 问题：重建过程中需要其它线程都阻塞等待  //java伪代码\rString get(String key){\rString value = redis.get(key);\rif (value == nul) {\rString mutexKey = \u0026quot; mutex:key.\u0026quot; + key;\rif (redis.set(mutexKey, \u0026quot;1\u0026quot;, \u0026quot;ex 180\u0026quot;, \u0026quot;nx\u0026quot;)) { //设置一个互斥锁，只有1个线程可以进去执行，为了保证这个锁会被删掉，设置一个过期时间180秒。ex和nx是一个组合命令，set exnx，保证命令的原子性\rvalue = db.get(key);\rredis.set(key, value);\rredis.delete(mutexKey);\r} else {\r//其他线程休息50毫秒后重试\rThread.sleep(50);\rget(key);\r}\rreturn value;\r}\r}\r   永远不过期：\n 缓存层面：不设置过期时间(没有用expire)。 功能层面：为每个value添加逻辑过期时间，但发现超过逻辑过期时间后，会使用单独的线程去构建缓存。 问题：存在数据不一致，虽然数据永远不会过期，任何时刻到来的线程都可以无需等待获取数据，但某一时刻一个线程A发现数据逻辑时间到期，则单独开启一个线程去完成重建并设置新的过期时间，而重建过程中，线程A和之后时间的线程获取到的数据等于是旧的数据  String get(final String key){\rV v = redis.get(key);\rString value = v.getValue();\rlong logicTimeout = v.getLogicTimeout();\rif (logicTimeout \u0026gt;= System.currentTimeMillis()) {\rString mutexKey = \u0026quot; mutex🔑\u0026quot; + key;\rif (redis set(mutexKey, \u0026quot;1\u0026quot;, \u0026quot;ex 180\u0026quot;, \u0026quot;nx\u0026quot;)) {\r//异步更新后台异常执行\rthreadPool.execute(new Runnable() {\rpublic void run() {\rString dbValue = db.get(key);\rredis.set(key, (dbValue,newLogicTimeout));\rredis.delete(keyMutex);\r}\r});\r}\r}\rreturn value;\r}\r      方案 优点 缺点     互斥锁 思路简单保证一致性 代码复杂度增加存在死锁的风险   永远不过期 基本杜绝热点key重建问题 不保证一致性逻辑过期时间增加维护成本和内存成本      总结  缓存收益：加速读写、降低后端存储负载。 缓存成本：缓存和存储数据不一致性、代码维护成本、运维成本。 推荐结合剔除、超时、主动更新三种方案共同完成。 穿透问题：使用缓存空对象和布隆过滤器来解决，注意它们各自的使用场景和局限性。 无底洞问题:分布式缓存中,有更多的机器不保证有更高的性能。有四种批量操作方式:串行命令、串行IO、并行IO、hash_tag。 雪崩问题:缓存层高可用、客户端降级、提前演练是解决雪崩问题的重要方法。 热点key问题:互斥锁、“永远不过期”能够在一-定程度 上解决热点key问题，开发人员在使用时要了解它们各自的使用成本。  RedisBloomFilter 基于Redis的分布式布隆过滤器\n 引出布隆过滤器 布隆过滤器原理 布隆过滤器误差率 本地布隆过滤器 Redis单机布隆过滤器 Redis分布式布隆过滤器  引出布隆过滤器  问题：现有50亿个电话号码，现有10万个电话号码，要 快速、准确 判断这些电话号码是否已经存在?  通过数据库查询：实现快速有点难。假设在mysql中，写个in？肯定跑飞了；循环？也肯定快不起来 数据预放在集合中：50亿*8字节(long型)≈40GB，内存浪费或不够。比如java集合？jvm一般也不可能开这么大。hbase？可能会开一些比较大的堆栈，但为了这么一个小功能也太过于浪费 hyperloglog：准确有点难。很好，但是违背准确性   类似问题很多  垃圾邮件过滤 文字处理软件(例如word )错误单词检测 网络爬虫重复ur|检测 Hbase行过滤   布隆过滤器：1970年伯顿.布隆提出,用很小的空间,解决上述类似问题  实现原理：一个很长的二进制向量和若干个哈希函数  内容  二进制向量：比如000000000000000000000000000000000000000000000 哈希函数：如F1、F2、\u0026hellip;Fn 过滤的内容：如 p=185xxxxxxxx。   构建过程  p通过F1进行hash，假设落在第3位，则将第3位变成1，001000000000000000000000000000000000000000000 p通过F2进行hash，假设落在第9位，则将第9位变成1，001000001000000000000000000000000000000000000 \u0026hellip;一直到Fn全部执行完         布隆过滤器原理  构建  参数  m个二进制向量：00000\u0026hellip;0，m个初始的0 k个hash函数：一般8个即可 n个预备数据：比如那5E个电话号码   过程  n个预备数据全部走一遍上面过程  如果m值较小，比如只有10个0，而n是50，就算只有少量hash函数，这个二进制向量也可能直接全部变为1了，所以二进制向量的1的密度跟m和n比例是很有关系的 当然和hash函数的个数也有关系，不过hash函数个数越多对判断的提高是有帮助的       判断元素存在：让元素走一遍同样的过程：如果得到的位置在二进制向量上都是1，则在表示存在，反之表示不存在  布隆过滤器误差率   误差率：肯定存在误差，对的肯定是对的，错的可能是对的，错的也可能恰好都命中了\n  只管因素：m/n的比率，hash函数的个数\n  实际误差率公式\n  1个元素，1个hash函数，任意一个比特为1的概率为1/m，依然为0的概率为1 - 1/m\n  k个函数， 任意一个比特依然为0的概率为 $$ (1-1/m)^k $$ n个元素，任意一个比特依然为0的概率为(1-M)nk $$ (1-1/m)^{kn} $$\n  任意一个比特位被设置为1的概率 $$ 1-(1-1/m)^{kn} $$\n  新元素全中的概率为 $$ (1-(1-1/m)^{kn})^k≈(1-e^{-kn/m})k $$\n    m/n与误差率成反比，k与误差率成反比\n     本地布隆过滤器  现有库：guava，https://github.com/google/guava 本地布隆过滤器的问题  容量受限制：受限于容器，比如jvm，或者tomcat（也是jvm）等web容器。在n的体量较大、或者期望的误差率较低，还是会受限于容量，单机也会成为限制 多个应用存在多个布隆过滤器，构建同步复杂：多个应用都需要在本地构建布隆过滤器，它们之间会产生布隆过滤器同步问题，而前端发来的请求可能通过一些负载均衡是落在不同的应用上的，布隆过滤器的范围类似于session，无法跨应用（container），需要去实现同步，比如session集中存储，就采用一个独立的session，让所有的container去访问它，或者笨一点让该用户的请求一定要打在之前的容器上，但这违背了负载均衡 使用redis来实现布隆过滤器的集中存储    Redis单机布隆过滤器  基于位图：布隆过滤器的二进制向量天然吻合redis位图，redis位图提供了setbit、getbit等功能 实现  定义布隆过滤器构造参数：m、n、k、误差概率 定义布隆过滤器操作函数：add和contain 封装Redis位图操作 开发测试样例    BloomFilter package com.yuanya.bloomFilter;\rimport java.util.List;\rimport java.util.Map;\r/**\r* 布隆过滤器接口\r*\r* @param \u0026lt;T\u0026gt;\r* @author yuanya\r* 2017年12月23日 下午10:03:12\r*/\rpublic interface BloomFilter\u0026lt;T\u0026gt; {\r/**\r* 添加\r*\r* @param object\r* @return 是否添加成功\r*/\rboolean add(T object);\r/**\r* 批量添加\r*\r* @param objectList\r* @return\r*/\rMap\u0026lt;T, Boolean\u0026gt; batchAdd(List\u0026lt;T\u0026gt; objectList);\r/**\r* 是否包含\r*\r* @param object\r*/\rboolean contains(T object);\r/**\r* 批量是否包含\r*\r* @param object\r*/\rMap\u0026lt;T, Boolean\u0026gt; batchContains(T object);\r/**\r* 预期插入数量\r*/\rlong getExpectedInsertions();\r/**\r* 预期错误概率\r*/\rdouble getFalseProbability();\r/**\r* 布隆过滤器总长度\r*/\rlong getSize();\r/**\r* hash函数迭代次数\r*/\rint getHashIterations();\r/**\r* 获取子布隆过滤器个数\r*/\rint getChildNum();\r}\r RedisBloomFilter /**\r* 布隆过滤器接口\r* * @param \u0026lt;T\u0026gt;\r* @author yuanya\r* 2019年4月15日 下午10:06:54\r*/\rpublic class RedisBloomFilter\u0026lt;T\u0026gt; implements BloomFilter\u0026lt;T\u0026gt; {\rprivate Logger logger = LoggerFactory.getLogger(RedisBloomFilter.class);\rprivate BloomFilterBuilder config;\rpublic RedisBloomFilter(BloomFilterBuilder bloomFilterBuilder) {\rthis.config = bloomFilterBuilder;\r}\rpublic boolean add(T object) {\rif (object == null) {\rreturn false;\r}\r//偏移量列表\rList\u0026lt;Integer\u0026gt; offsetList = this.hash(object);\rif (offsetList == null || offsetList.isEmpty()) {\rreturn false;\r}\r//设置偏移量到二进制向量位图\rfor (Integer offset : offsetList) {\rJedis jedis = null; try {\rjedis = getJedisPool().getResource();\rjedis.setbit(getName(), offset, true);\r} catch (Exception e) {\rlogger.error(e.getMessage(), e);\rreturn false;\r} finally {\rif (jedis != null) {\rjedis.close();\r}\r}\r}\rreturn true;\r}\rpublic Map\u0026lt;T, Boolean\u0026gt; batchAdd(List\u0026lt;T\u0026gt; objectList) {\rif (objectList == null || objectList.isEmpty()) {\rreturn Collections.emptyMap();\r}\rMap\u0026lt;T, Boolean\u0026gt; resultMap = new HashMap\u0026lt;T, Boolean\u0026gt;();\rfor (T object : objectList) {\rboolean result = this.add(object);\rresultMap.put(object, result);\r}\rreturn resultMap;\r}\rpublic boolean contains(T object) {\rif (object == null) {\rreturn false;\r}\r//偏移量列表\rList\u0026lt;Integer\u0026gt; offsetList = hash(object);\rif (offsetList == null || offsetList.isEmpty()) {\rreturn false;\r}\rfor (int offset : offsetList) {\rJedis jedis = null;\rtry {\rjedis = getJedisPool().getResource();\rboolean result = jedis.getbit(getName(), offset);\rif (!result) { //如果是0，即没有在列表中\rreturn false;\r}\r} catch (Exception e) {\rlogger.error(e.getMessage(), e);\r} finally {\rif (jedis != null) {\rjedis.close();\r}\r}\r}\rreturn true; //所有位都是1则返回true\r}\rpublic Map\u0026lt;T, Boolean\u0026gt; batchContains(T object) {\rreturn null;\r}\rpublic BloomFilterBuilder getConfig() {\rreturn config;\r}\rpublic long getExpectedInsertions() {\rreturn getConfig().getExpectedInsertions();\r}\rpublic double getFalseProbability() {\rreturn getConfig().getFalseProbability();\r}\rpublic long getSize() {\rreturn getConfig().getTotalSize();\r}\rpublic int getHashIterations() {\rreturn getConfig().getHashIterations();\r}\rpublic int getChildNum() {\rreturn getConfig().getChildNum();\r}\rpublic String getName() {\rreturn getConfig().getName();\r}\rpublic JedisPool getJedisPool() {\rreturn getConfig().getJedisPool();\r}\rpublic HashFunction getHashFunction() {\rreturn getConfig().getHashFunction();\r}\rpublic List\u0026lt;Integer\u0026gt; hash(Object object) {\rbyte[] bytes = object.toString().getBytes();\rreturn getHashFunction().hash(bytes, (int) getSize(), getConfig().getHashIterations());\r}\r}\r BloomFilterBuilder /**\r* 布隆过滤器构造器\r*\r* @author yuanya\r* 2019年4月15日 下午10:05:57\r*/\rpublic class BloomFilterBuilder {\rprivate Logger logger = LoggerFactory.getLogger(RedisBloomFilter.class);\rprivate static final long MAX_SIZE = Integer.MAX_VALUE * 100L;\r/**\r* 需要的JedisPool\r*/\rprivate JedisPool jedisPool;\r/**\r* 需要的JedisCluster\r*/\r/**\r* 布隆过滤器名(位图的key)\r*/\rprivate String name;\r/**\r* 位图总长度\r*/\rprivate long totalSize;\r/**\r* hash函数循环次数\r*/\rprivate int hashIterations;\r/**\r* 预期插入条数\r*/\rprivate long expectedInsertions;\r/**\r* 预期错误概率\r*/\rprivate double falseProbability;\r/**\r* 子布隆过滤器个数\r*/\rprivate int childNum;\r/**\r* 子布隆过滤器m。根据需求设置即可\r*/\rprivate int childMaxSize = 1000000000;\r/**\r* hash函数:默认murmur3\r* 自己随便找一个hash也都行\r*/\rprivate HashFunction hashFunction = new MurMur3HashFunction();\r/**\r* 是否完成\r*/\rprivate boolean done = false;\rpublic BloomFilterBuilder(JedisPool jedisPool, String name, long expectedInsertions, double falseProbability) {\rthis.jedisPool = jedisPool;\rthis.name = name;\rthis.expectedInsertions = expectedInsertions;\rthis.falseProbability = falseProbability;\r}\rpublic BloomFilterBuilder setHashFunction(HashFunction hashFunction) {\rthis.hashFunction = hashFunction;\rreturn this;\r}\rpublic \u0026lt;T\u0026gt; RedisBloomFilter\u0026lt;T\u0026gt; build() {\rcheckBloomFilterParam();\rreturn new RedisBloomFilter\u0026lt;T\u0026gt;(this);\r}\r/**\r* 检查布隆过滤器参数\r*/\rprivate void checkBloomFilterParam() {\rif (done) {\rreturn;\r}\rif (name == null || \u0026quot;\u0026quot;.equals(name.trim())) {\rthrow new\rIllegalArgumentException(\u0026quot;Bloom filter name is empty\u0026quot;);\r}\rif (expectedInsertions \u0026lt; 0 || expectedInsertions \u0026gt; MAX_SIZE) {\rthrow new\rIllegalArgumentException(\r\u0026quot;Bloom filter expectedInsertions can't be greater than \u0026quot; + MAX_SIZE + \u0026quot; or smaller than 0\u0026quot;);\r}\rif (falseProbability \u0026gt; 1) {\rthrow new IllegalArgumentException(\u0026quot;Bloom filter false probability can't be greater than 1\u0026quot;);\r}\rif (falseProbability \u0026lt; 0) {\rthrow new IllegalArgumentException(\u0026quot;Bloom filter false probability can't be negative\u0026quot;);\r}\r//计算布隆过滤器(位图)长度\rtotalSize = optimalNumOfBits();\rlogger.info(\u0026quot;{} optimalNumOfBits is {}\u0026quot;, name, totalSize);\rif (totalSize == 0) {\rthrow new IllegalArgumentException(\r\u0026quot;Bloom filter calculated totalSize is \u0026quot; + totalSize);\r}\rif (totalSize \u0026gt; MAX_SIZE) {\rthrow new IllegalArgumentException(\u0026quot;Bloom filter totalSize can't be greater than \u0026quot; + MAX_SIZE\r+ \u0026quot;But calculated totalSize is\u0026quot; + totalSize);\r}\r// hash函数迭代次数\rhashIterations = optimalNumOfHashFunctions();\rlogger.info(\u0026quot;{} hashIterations is {}\u0026quot;, name, hashIterations);\rchildNum = (int) (totalSize / childMaxSize + 1);\rdone = true;\r}\r/**\r* 根据预期插入条数和概率计算布隆过滤器(位图)长度\r*/\rprivate long optimalNumOfBits() {\rif (falseProbability == 0) {\rfalseProbability = Double.MIN_VALUE;\r}\rreturn (long) (-expectedInsertions * Math.log(falseProbability) / (Math.log(2) * Math.log(2)));\r}\r/**\r* 根据布隆过滤器长度与预期插入长度之比，计算hash函数个数\r*/\rprivate int optimalNumOfHashFunctions() {\rreturn Math.max(1, (int) Math.round((double) totalSize / expectedInsertions * Math.log(2)));\r}\rpublic Logger getLogger() {\rreturn logger;\r}\rpublic static long getMaxSize() {\rreturn MAX_SIZE;\r}\rpublic JedisPool getJedisPool() {\rreturn jedisPool;\r}\rpublic String getName() {\rreturn name;\r}\rpublic long getTotalSize() {\rreturn totalSize;\r}\rpublic int getHashIterations() {\rreturn hashIterations;\r}\rpublic long getExpectedInsertions() {\rreturn expectedInsertions;\r}\rpublic double getFalseProbability() {\rreturn falseProbability;\r}\rpublic int getChildNum() {\rreturn childNum;\r}\rpublic int getChildMaxSize() {\rreturn childMaxSize;\r}\rpublic HashFunction getHashFunction() {\rreturn hashFunction;\r}\rpublic boolean isDone() {\rreturn done;\r}\r}\r 存在的问题  速度慢：比本地慢，输在网络  解决：单独部署，与应用同机房甚至机架部署   容量受限：Redis最大字符串为512MB，通过拆分成多个子串解决，但仍然收Redis单机容量限制  解决：基于Redis Cluster实现    Redis分布式布隆过滤器  实现方法：基于单机改改即可  个布隆过滤器：二次路由。输入参数不变，m比如100E，预定好多少个布隆过滤器，比如一个布隆过滤器最大是1E，即需要100份，设计的时候对key做一个二次路由即可 基于pipeline提高效率：不然分布式布隆过滤器性能下降还是会比较厉害    主从   单机存在的问题：机器故障（分布式问题）、容量瓶颈（分布式问题）、QPS瓶颈（高可用问题）\n  主从复制：一个master可以有多个slave。主复制到从，类似于数据备份的作用，多副本，高可用，读写分离，读分流负载均衡\n 一个master可以有多个slave 一个slave只能有一-个master 数据流向是单向的, master到slave slave要保证只读：因为主从复制只能从主到从，从如果写入数据，主不会知道。且主节点宕机，由某个从节点补上，要保证数据一致 作用  数据副本；做rdb也可以在从节点做，减轻master负载 扩展读性能      配置\n  命令：无需重启，但不便于管理\n slaveofs：在从节点执行 slaveof 主节点ip port。是异步的 slaveof no one：不成为任何节点的从节点，即辞掉从节点地位，与主节点断开连接。如果再次成为其它节点的slave，主节点会清除掉从节点所有旧的数据    配置：需要重启，但可以统一配置管理\nslaveof ip port #在从节点配置的，指向主节点的ip和port\rslave-read-only yes #从节点只读\r     操作\n  查看节点状态，在成为从节点之前每个节点都是master\nsys\u0026gt; redis-cli info #查看所有信息\rsys\u0026gt; redis-cli -p 6380 info replication #在客户端外查看\r127.0.0.1:6379\u0026gt; info replication #客户端内查看\r     全量复制和部分复制\n  run_id：每个redis启动都会有一个run_id作为标识。例子，如果从节点发现主节点run_id发生了变化（如主节点重启，或者从节点第一次连接主节点，即第一次获得主节点的run_id标识），这种变化可以引起从节点全量复制主节点数据\nredis-cli -p 6379 info server | grep run #查看run_id\r   偏移量：是主从之间实时同步的一个指标，如果主从之间偏移量差值过大，可能是主从同步复制发生了问题\nredis-cli -p 6379 info replication #其中master_repl_offset:1865\r   全量复制：master将当前状态RDB文件同步给slave，在同步期间产生的新数据也将被记录，通过对比偏移量，再同步给slave\n  流程\n 从节点发送命令 psync ? 1 给主节点：psync（2.8之前是sync）可以完成全量复制和部分复制的功能。参数1是run_id，参数2是偏移量，首次复制还不知道主节点的run_id和自己的偏移量是多少，run_id以?占位，偏移量以-1 master收到命令，从参数可见从节点都不知道run_id和偏移量，肯定就全量复制了，并会返回run_id和offset slave保存mster的信息 run_id、offset mster执行bgsave，主从复制期间，master中新增的命令被保存在repl_back_buffer（用于记录最新写入的命令）中 master向slave send RDB master向slave send buffer 从节点flush old data（删除原来的数据） 从节点加载RDB和buffer    开销\n bgsave时间 RDB文件网络传输时间 从节点清空数据时间 从节点加载RDB的时间 可能的AOF重写时间：如果开启了AOF将进行一次AOF重写，保证AOF是最新的状态    问题：如果网络主从之间网络抖动，从节点无法及时同步数据：2.8以前，会直接再进行一次全量复制，会消耗较大资源；2.8之后\n master在会写命令到复制缓冲区repl_back_buffer（默认1mb） 当slave再次连上master时，slave向mster发送pysnc {offset} {runId} mster对比偏移量，如果发现slave错过的数据还在缓冲区记录范围内 master发送continue表示继续部分复制 然后send partial data      故障处理\n 自动故障转移：当一个机器挂掉了，另一台机器自动顶上，之后再对故障机器或服务进行处理，保证高可用 主从结构故障转移：假设一主（读写）二从（只读）  slave宕掉：宕一个，如果另一个从节点有足够性能冗余，将宕掉从节点的客户端改到另一个上即可 master宕掉：从节点仍可以正常服务，然后发送命令slaveof no one让其中一个成为master，让另一个成为新mster的从节点slaveof new master 但是都没有实现自动故障转移，等待redis-sentinel出场吧      常见问题\n 读写分离：读流量分摊到从节点  可能遇到问题：  复制数据延迟 读到过期数据：删除过期数据有两种策略  lazy：去操作key的时候才判断该key是否过期，过期则返回空 定时任务：每次去采样一些key，看它是否过期，但是如果采样速率低于数据产生速率，可能会发生很多过期数据没有删除，然后在主从复制中，slave没有删除数据的资格，如果mster没有及时将删除命令同步给slave时，slave就可能读到脏（过期）数据，但是redis3.2已经解决了这个问题   从节点故障，需要迁移其客户端到其它从节点进行数据读取，如果很多应用使用这个节点，迁移成本就很高了     主从配置不一致  例如maxmemory不一致：丢失数据。比如mster配置4g、slave配置2g，主从复制可以正常进行，mster传输RDB，slave加载RDB，但这就可能RDB过大，触发从节点maxmemory的触发策略，将数据进行淘汰（这个过程有可能产生OOM），如果触发策略是以剔除过期数据优先的策略，就会剔除过期数据，对于数据这就已经没有真正实现副本的功能了，也不会报任何错误，如果主节点再宕机，从节点顶替为主节点，从节点无法挽回那些剔除的数据，数据丢失。比较好的办法是使用一些标准工具安装上对其做监控 例如数据结构优化参数：内存不一致。例如主节点设置hash-max-ziplist-entries优化值，从节点没优化，就会造成主从节点内存不一致   规避全量复制  第一次全量复制：第一次不可避免  小主节点：数据分片，maxmemory不要设置太大，这样bgsave、传输、加载、fork等速度都会更快，开销相对更小 低峰：在访问量较低的时候（如夜间）进行   节点运行ID不匹配：主节点重启run_id改变，主从节点记录的master run_id不一致，会认为数据不安全，将全量复制  redis4.0中提供了psyncto的规则可以有效解决这类问题 故障转移，例如哨兵或集群，让从节点顶替成为新的master   复制积压缓冲区（repl_back_buffer，实际上是一个队列，默认大小1mb）不足：网络中断，部分复制可能无法满足  增大复制缓冲区配置rel_ backlog_ size，根据实际情况设置，假如网络故障一般是几分钟，就根据统计每分钟传输字节数*分钟数来计算大小 网络\u0026quot;增强\u0026rdquo;     规避复制风暴：感觉最好的办法还是直接让slave顶替为master这种高可用的方式，后面讲，这里讲重启方式  单主节点复制风暴，如果一个mster上挂载了很多slave，如果master宕掉重启，所有slave都要做主从复制，虽然redis有优化，master只生成一次rdb，但要做多次传输，对master开销极大  更换复制拓扑：树形。不是所有slave都挂在master上，可以master上挂一个slave1，这个slave上再挂载其它几个salve，这样就将传输压力分担到了一个slave上。但是这会产生新的问题，如果slave1故障了\u0026hellip;如何处理故障或者如何故障转移   单机器（机器上很多mster）复制风暴：机器宕机后，大量全量复制  主节点分散多机器        RedisSentinel   主从复制高可用？：主从复制存在问题\n 手动故障转移：虽然也可以用脚本监控master，出现问题就让slave顶替上来，但这就很复杂，比如怎么判定master是有问题的，怎么通知客户端更改为服务端为新的master，还有保证事务，所以有了Redis Sentinel这样高可用的实现服务 来完成这些事情 写能力和存储能力受限    架构说明\n client从sentinel获取redis信息，即 sentinel挡在redis集群前面，监控其后每一个mster和slave。sentinel也是多个的，且一套sentinel可以同时监控多套mster及其slave，每套mster及其slave将以master-name这个配置作为标识    故障自动转移：即sentinel将作为redis客户端来自动进行操作\n 多个sentinel发现并确认master有问题 选举出一个sentinel作为领导 选出一个slave作为master 通知其余slave成为新的master的slave 通知客户端主从变化 等待老的master复活成为新master的slave：依然会对老的mster进行监控（死的时候就已经配置为slave了，复活直接复制master的数据）    安装配置\n  配置开启主从节点\nport 7002\rdaemonize yes\rpidfile /var/run/redis-7002.pid\rlogfile \u0026quot;7002. log\u0026quot;\rdir \u0026quot;/opt/soft/redis/redis/data/\u0026quot;\rslaveof 127 .0.0.1 7000 #主节点不用配置\r   配置开启sentinel监控主节点。(redis-sentinel是特殊的redis，不存储数据，支持的redis命令非常有限，主要功能就完成监控、故障转移、通知)\ndaemonize yes #以守护进程方式启动\rport ${port} #默认26379\rdir \u0026quot;/opt/soft/redis/data/\u0026quot;\rlogfile \u0026quot;${port}.log'\rsentinel monitor mymaster 127.0.0.1 7000 2 #监控的 主节点名字、ip、端口，2表示至少几个sentinel发现该出master出现问题才会进行故障转移 sentinel down-after-milliseconds mymaster 30000 #故障判定时间，30000毫秒无法连通则判定master为故障\rsentinel parallel-syncs mymaster 1 #故障转移后其它slave会对新master进行复制，这个配置指定同时复制的个数，1表示每次只复制一个，减轻master压力\rsentinel failover-timeout mymaster 180000 #故障转移超时时间\r#可以发现只有master的配置，因为sentinel通过对master执行info并解析就可以获取对应从节点信息并自动添加配置，以及会去掉一些与默认配置相同的配置以及添加一些配置\r   多个sentinel实际应该多机器，演示仅一台机器\nredis-sentinel redis-sentinel-26379.conf #启动\rredis-cli -p 26379 #连接\rping\rinfo #命令和redis一样，只是支持的命令更少\rsed \u0026quot;s/26379/ 26380/g\u0026quot; redis-sentinel-26379.conf \u0026gt; redis-sentinel-26380.conf #sed命令偷懒copy出26380和26381即可\r     客户端连接：现在要从直连redis换为连接sentinel，这样才能达到客户端也高可用\n  过程：client会获取到Sentinel节点集合 + masterName，遍历Sentinel节点集合，获取一个可用的Sentinel节点，将发送命令sentinel get-master-addr-by-name masterName，然后sentinel返回mster节点信息，获取到mster执行role 或者role replication以进行验证，然后master会返回节点角色信息\n  如何通知：类似于发布订阅模式，客户端订阅某一个频道，假如该频道master变化，客户端将收到通知，与新的master进行连接\n  接入流程：Sentinel地址集合，masterName，不是代理模式而是发布订阅模式\n//不管jedis还是其它实现模式都是一样的，只是封装程度不同\rString masterName =\u0026quot; mymaster\u0026quot; ;\rSet\u0026lt;String\u0026gt; sentinels = new HashSet \u0026lt;String\u0026gt;();\rsentinels. add(\u0026quot;127.0.0.1:26379\u0026quot;);\rsentinels. add(\u0026quot;127.0.0.1:26380\u0026quot;);\rsentinels. add(\u0026quot;127.0.0.1:26381\u0026quot;);\rJedisSentinelPool sentinelPool = new JedisSentinelPool(masterName, SentinelSet, poolConfig, timeout); //本质还是连接master的\rJedis jedis = null;\rtry{\rjedis = redisSentinelPool.getResource();\r//jejedis command\r} catch (Exception e) {\rlogger.error(e.getMessage(, e);\r} finally {\rif (jedis != null){\rjedis.close();\r}\r}4\r     实现原理：\n 故障转移演练：在java程序中循环执行jedis命令，然后将master shutdown  客户端高可用观察：mster宕掉以后，程序开始报错，但是一会儿之后，恢复了正常 服务端日志分析：数据节点和sentinel节点  主节点7000：因为直接kill掉了，日志停止在kill掉的瞬间 从节点7001日志：首先与master失联（不断尝试连接master并失败），收到user request（可以肯定是来自sentinel）希望让它自己成为master，并进行了配置重启，然后发现7002要复制它的数据（说明已经被选为master了），然后开始bgsave，然后去完成复制的过程 从节点7002日志首：首先和7001一样与master失联，然后收到user request希望它slave of 7001，然后复制7001数据的过程 sentinel-26379：（日志量很大，只是大概过程）先有sdown master mymaster 127.0.0.1 7000表示该master下线了（一个人的意见），后有odown\u0026hellip;表示sentinel达成条件（多个人的意见，具体是多少，根据前面的配置）认为它该做下线了。然后是sentinel的选举 +vote-for-leader 尝试去做领导者，然后记录了26380、26381都投票给它，然后选择7001成为master，选择7001成为slave，然后还是用odown\u0026hellip;对7000做下线标识，然后正式标识新的master和slave（应该是会自动更变配置内容）        三个定时任务：为了对redis做失败判定、故障转移，redis sentinel有3个定时任务来作为实现这些过程的基础\n 每10秒每个sentinel对master和slave执行info  发现slave节点 确认主从关系   每2秒每个sentinel通过master节点的channel交换信息(pub/sub)  通过sentinel_ :hello频道交互，类似于发布订阅，准确一点大概是一个广播网络 交互对节点的\u0026quot;看法”和自身信息   每1秒每个sentine|对其他sentinel和redis执行ping    主观下线和客观下线\n#通过命令配置，前面配置文件已经见过了\rsentinel monitor \u0026lt;masterName\u0026gt; \u0026lt;ip\u0026gt; \u0026lt;port\u0026gt; \u0026lt;quorum\u0026gt;\rsentinel monitor myMaster 127.0.0.1 6379 2 #一般配置ceil(n/2)，n是sentinel节点总数（集群一般是单数）\rsentinel down-after-milliseconds \u0026lt; masterName\u0026gt; \u0026lt; timeout\u0026gt;\rsentinel down-after-milliseconds mymaster 30000\r  主观下线：每个sentinel节点对Redis节点失败的\u0026quot;偏见\u0026quot;。slave被主观下线可以直接让其下线，如果是对master主观下线，则对其它所有节点发出命令sentinel is-master-down-by-addr 客观下线：所有sentinel节点对Redis节点失败\u0026quot;达成共识”( 超过quorum个统一)，达成共识的交互手段就是通过命令sentinel is-master-down-by-addr，然后选举出leader控制mster进行客观下线    leader选举\n 原因：只一个sentinel节点来完成故障转移 选举：通过sentinel is-master-down-by-addr命令，是的，这个命令也具有自荐为leader的作用  每个做主观下线的Sentinel节点向其他Sentinel节点发送命令，要求将它设置为领导者 收到命令的Sentinel节点如果没有同意通过其他Sentinel节点发送的命令，那么将同意该请求，否则拒绝 如果该Sentinel节点发现自己的票数已经超过Sentinel集合半数且超过quorum，那么它将成为领导者。 如果此过程有多个Sentinel节点成为了领导者，那么将等待一段时间重 新进行选举 虽然可能某个短时间内几乎同时有多个节点发出命令，但是同意总有先后      故障转移：前提是sentinel leader节点选举完成\n 从slave节点中选出一一个“合适的”节点作为新的master节点  选择slave-priority(slave节点优先级，一般没配置)最高的slave节点，如果存在则返回,不存在则继续 选择复制偏移量最大的slave节点(复制的最完整) ,如果存在则返回，不存在则继续 选择runId最小的slave节点   对上面的slave节点执行slaveof no one命令让其成为master节点。 向剩余的slave节点发送命令, 让它们成为新master节点的slave节点,复制规则和parallel-syncs参数有关。 更新对原来master节点配置为slave ,并保持着对其\u0026quot;关注\u0026quot;，当其恢复后命令它去复制新的master节点。    常见开发运维问题\n 节点运维  节点下线  原因  机器下线：例如过保等情况 机器性能不足：例如CPU、内存、硬盘、网络等 节点自身故障：例如服务不稳定等   主节点：sentinel failover ，手动在某个sentinel上执行命令让该sentinel执行指定master的故障转移 从节点：考虑临时下线还是永久下线，例如是否做一些清理工作（配置、日志、数据、RDB文件等）。还要考虑读写分离的情况，如转移连接该节点的客户端到其它节点等。   节点上线  主节点：sentinel failover  进行替换。 从节点：slaveof即可, sentinel节点可以感知。 sentinel节点：参考其他sentinel节点启动即可     高可用读写分离  JedisSentinelPool的实现：客户端高可用  从构造方法进入，先初始化sentinels，初始化和前面讲过的客户端原理一致，循环sentinel集合，对sentinel发出命令让其根据mastername获取master地址来检验连接，直到找到一个可用的sentinel则跳出循环。 然后去订阅频道，MasterListener（继承了Thread）来监听，连接每一个sentinel，订阅master更变的通道，如果mster更变将重新初始化连接池，完成客户端高可用   从节点的作用  副本:高可用的基础 扩展:读能力   三个\u0026quot;消息\u0026quot;：可以把所有slave看作一个池子，客户端通过监听三个\u0026quot;消息（通道）\u0026quot;，监听到变化则重新初始化redis连接池，完成高可用读写分离  switch-master：切换主节点(从节点晋升主节点) convert-to-slave：切换从节点(原主节点降为从节点) sdown：主观下线   高可用读写分离相对复杂，一般来说真正需要高扩展性的高可用redis集群，都通过redis-cluster（redis集群版本）来完成    总结 Redis Sentinel是Redis的高可用实现方案：故障发现、故障自动转移、配置中心、客户端通知\nRedis Sentinel从Redis2.8版本开始才正式生产可用，之前版本生产不可用\n尽可能在不同物理机上部署Redis Sentinel所有节点，建议放在一个网络中，减少误差\nRedis Sentinel中的Sentinel节点个数应该为大于等于3，且最好为奇数。\nRedis Sentinel中的数据节点与普通数据节点没有区别\n客户端初始化时连接的是Sentinel节点集合，不再是具体的Redis节点，但Sentinel只是配置中心不是代理。\nRedis Sentinel通过三个定时任务实现了Sentinel节点对于主节点、从节点、%其余Sentinel节点的监控。\nRedis Sentinel在对节点做失败判定时分为主观下线和客观下线\n看懂Redis Sentinel故障转移日志对于Redis Sentinel以及问题排查非常有帮助\nRedis Sentinel实现读写分离高可用可以依赖Sentinel节点的消息通知，获取Redis数据节点的状态变化\nRedisCluster  呼唤集群 数据分布 搭建集群 集群伸缩 客户端路由 集群原理 开发运维常见问题  呼唤集群  为什么呼唤集群  1.并发量。redis宣称：10万/每秒。业务需要100万/每秒呢? 2.数据量。机器内存: 16~256G。业务需要500G呢? 3.网络流量。网卡：千兆网卡。业务需要万兆呢   解决方法：  配置\u0026quot;强悍”的机器:超大内存、牛x CPU等，但单机上限远远比不上集群 分布式集群，才是正确的解决方法   集群：规模化需求  并发量: OPS 数据量: \u0026ldquo;大数据 网络流量    数据分布   分布式数据库-数据分区：全量数据→分区规则→子集-1、子集-2\u0026hellip;子集-n\n   分布方式 特点 典型产品     哈希分布 数据分散度高键值分布业务无关无法顺序访问支持批量操作 一致性哈希MemcacheRedis Cluster其他缓存产品   顺序分布 数据分散度易倾斜键值业务相关可顺序访问支持批量操作 BigTableHBase     分序分布（区）：1~100→1~33、34~ 66、67~ 100 哈希分布（例如节点取模）：1~100→hash(key)%3→(3,6\u0026hellip;99 )、(1,4\u0026hellip;100)、( 2,5.. .98)  节点取余：hash(key)%nodes。nodes只节点数。  扩容：扩展节点时对所有数据重新计算，并根据结果将其迁移到应该去的机器（如果结果不属于原来的机器的话）。好像是。。。。。：数据迁移并不是从一个节点直接到另一个节点，而是在计算以后如果应该到新的节点上取，发现没有数据，则会到数据源取，然后再放入新节点，这样就完成了\u0026quot;迁移\u0026rdquo;，其实是一个访问数据源回写的过程。  比如从3个节点到4个节点，会发现数据的迁移率（从原来的节点迁移的另一个节点的数据的比例）较高（计算为80%）。 多倍扩容：3个节点变为6个节点，则只有50%迁移率   建议  客户端分片：哈希+取余，简单、原始，迁移率较大会产生庞大的数据源访问和数据回写到内存，不建议使用 节点伸缩：数据节点关系变化,导致数据迁移 迁移数量和添加节点数量有关：建议翻倍扩容     一致性哈希：见图  客户端分片：哈希+顺时针(优化取余) 节点伸缩：只影响邻近节点，但是还是有数据\u0026quot;迁移\u0026quot; 翻倍伸缩：保证最小迁移数据和负载均衡（因为访问量大的可能一直只是某些段，比如老用户访问少且id较小，新用户访问多而id都再较大数字的段）   虚拟槽：Redis Cluster就是这种分区方式。不同的操由不同的节点管理，计算key得到value将知道属于哪个槽，然后任意分配给集群的一个节点，如果不属于该节点负责的槽，则由该节点返回目标节点给客户端（因为edis cluster中节点之间都有槽信息共享），让客户端去到正确的节点，但这种方式性能不高，节点较多时利用率较低，所以需要让客户端知道所有槽-节点。每个节点负责的槽是固定的，新节点将负责新的槽，不会有数据迁移  预设虚拟槽:每个槽映射一个数据子集, 一般比节点数大 良好的哈希函数:例如CRC16 服务端管理节点、槽、数据:例如Redis Cluster        搭建集群   基本架构\n 单机架构：主从复制，只有主可以写 分布式架构：都可以读写    Redis Cluster架构\n 节点：配置cluster-enabled:yes，是否是集群模式启动 meet：一个命令。节点之间完成通信的基础。A meet B、A meet C，就可以使B和C找到对方，这样就能完成所有节点的相互通信 指派槽：redis cluster指定有16384个slot， 复制：也有主从复制，每个主节点都有从节点，集群中有很多主节点。且无需redis sentinel 高可用 分片    安装\n  原生命令安装：就是按上面架构流程。无需记住，仅用来理解架构，实际生产基本还是使用安装工具安装\n  配置开启节点\nport ${port}\rdaemonize yes\rdir \u0026quot;/opt/redis/redis/data/\u0026quot;\rdbfilename \u0026quot;dump-${port}.rdb\u0026quot;\rlogfile \u0026quot;${port}.log\u0026quot;\rcluster-enabled yes #集群模式启动\r#下面是集群主要配置\rcluster-enabled yes\rcluster-node-timeout 1 5000\rcluster-config-file \u0026quot;nodes.conf\u0026quot;\rcluster-require-full-coverage yes #是否需要集群内所有节点都能提供服务才能认为该集群是正确的，即有一个节点出现问题集群就不可用，默认yes，肯定要改为no\r redis-server redis-7000.conf\rredis-server redis-7001.conf\rredis-server redis-7002.conf\rredis-server redis-7003.conf\rredis-server redis-7004.conf\rredis-server redis-7005.conf\r   meet：cluster meet ip port\nredis-cli -h 127.0.0.1 -p 7000 cluster meet 127.0.0.1 7001\rredis-cli -h 127.0.0.1 -p 7000 cluster meet 127.0.0.1 7002\rredis-cli -h 127.0.0.1 -p 7000 cluster meet 127.0.0.1 7003\rredis-cli -h 127.0.0.1 -p 7000 cluster meet 127.0.0.1 7004\rredis-cli -h 127.0.0.1 -p 7000 cluster meet 127.0.0.1 7005\r   指派槽：cluster addslots slot [slot ..]\nredis-cli -h 127.0.0.1 -p 7000 cluster addslots {0...5461}\rredis-cli -h 127.0.0.1 -p 7001 cluster addslots {5462...10922}\rredis-cli -h 127.0.0.1 -p 7002 cluster addslots {10923...16383}\r   主从：cluster replicate node-id\nredis-cli -h 127.0.0.1 -p 7003 cluster replicate ${node-id-7000}\rredis-cli -h 127.0.0.1 -p 7004 cluster replicate ${node-id-7001}\rredis-cli -h 127.0.0.1 -p 7005 cluster replicate ${node-id-7002}\r   操作\n配置文件\nport 7000\rdaemonize yes\rdir \u0026quot;/opt/soft/redis/data\u0026quot;\rlogfile \u0026quot;7000. log\u0026quot;\rdbfilename \u0026quot;dump-7000.rdb\u0026quot;\rcluster-enabled yes\rcluster-config-file nodes-7000.conf\rcluster-require-full-coverage no\r 快速sed配置文件\nsed 's/7000/7001/g' redis-7000.conf \u0026gt; redis-7001.conf\rsed 's/7000/7002/g' redis-7000.conf \u0026gt; redis-7002.conf\rsed 's/7000/7003/g' redis-7000.conf \u0026gt; redis-7003.conf\rsed 's/7000/7004/g' redis-7000.conf \u0026gt; redis-7004.conf\rsed 's/7000/7005/g' redis-7000.conf \u0026gt; redis-7005.conf\r 启动和查看\nredis-server redis-7000.conf\rredis-server redis-7001.conf\rredis-server redis-7002.conf\rredis-server redis-7003.conf\rredis-server redis-7004.conf\rredis-server redis-7005.conf\rps -ef | grep redis #查看服务\rredis-cli -p 7000 cluster nodes #查看节点信息，这种查看和redis-cli -p 7000客户端先连接，后再执行cluster nodes是一个效果\rredis-cli -p 7000 cluster info #查看集群信息\r meet\nredis-cli -p 7000 cluster meet 127.0.0.1:7001\rredis-cli -p 7000 cluster meet 127.0.0.1:7002\rredis-cli -p 7000 cluster meet 127.0.0.1:7003\rredis-cli -p 7000 cluster meet 127.0.0.1:7004\rredis-cli -p 7000 cluster meet 127.0.0.1:7005\rredis-cli -p 7005 cluster info\r 分配槽：脚本\nvim addslots.sh #vim可以自动创建\r#内容\rstart=$1\rend=$2\rport=$3\rfor slot in `seq ${start} ${end}`\rdo\recho \u0026quot;slot:${slot}\u0026quot; redis-cli -p ${port} cluster addslots ${slot}\rdone\r#执行，3个主节点（现在还不是）\rsh addslots.sh 0 5461 7000\rsh addslots.sh 5461 10922 7001\rsh addslots.sh 10922 16383 7002\r 主从\nredis-cli -p 7000 cluster nodes #查看\rredis-cli -p 7003 cluster replicate 560598cc5f6b13663ee7aaa9ff403e799e7d4918 #主节点id\rredis-cli -p 7004 cluster replicate xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\rredis-cli -p 7005 cluster replicate xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\rredis-cli -p 7000 cluster nodes #查看\rredis-cli -p 7000 cluster slots #查看槽分配信息\rredis-cli -c -p 7000 #客户端连接redis cluster，可以api操作了！\r 主从可以这样设计：左主右从，错开设计，减少机器\n10.0.0.1:7000 10.0.0.2:7003 10.0.0.2:7001 10.0.0.3:7004 10.0.0.3:7002 10.0.0.1:7005\n    官方工具安装：安装工具简单、高效、准确，但是如果真的是几百上千的超大集群，最好还是需要专门的平台来管理\n  官方工具安装提供了Ruby安装脚本，需要准备Ruby环境\n  下载、编译、安装Ruby\nwget https://cache.ruby-lang.org/pub/ruby/2.3/ruby-2.3.1.tar.gz\rtar -xvf ruby-2.3.1.tar.gz\r./configure -prefix=/usr/ocal/ruby\rmake\rmake install cd /usr/local/ruby\rcp bin/ruby/usr/local/bin\r   安装rubygem redis：ruby的一个客户端\nwget http://rubygems.org/ downloads/redis-3.3.0.gem\rgem install -l redis-3.3.0.gem\rgem list --check redis gem\r     安装redis-trib.rb：官方工具安装\n#配置开启Redis\rredis-server redis-8000.conf\rredis-server redis-8001.conf\rredis-server redis-8002.conf\rredis-server redis-8003.conf\rredis-server redis-8004.conf\rredis-server redis-8005.conf\r#一键开启，前3个是主节点，后3个是按序对应的从节点，如果每个主节点需要2个从节点，写6个即可，不符合标准的话会给你返回错误的\r./redis-trib.rb create --replicas 1 127.0.0.1:8000 127.0.0.1:8001 \\127.0.0.1:8002127.0.0.1:8003 127.0.0.1:8004 127.0.0.1:8005\rcp ${REDIS_ HOME}/src/redis-trib.rb /usr/local/bin\r     可视化部署：开发专门的管理平台来进行\n    集群伸缩   伸缩原理：集群伸缩=槽和数据在节点之间的移动\n  扩容集群：主要作用是：为它迁移槽和数据实现扩容，作为从节点负责故障转移\n  手动操作\n  准备新节点\n  集群模式\n  配置和其它节点统一\n  启动后是孤儿节点\nredis-server conf/redis-6385.conf\rredis-server conf/redis-6386.conf\r     加入集群：让集群中的节点去meet这些孤立节点\n127.0.0.1:6379\u0026gt; cluster meet 127.0.0.1 6385\r127.0.0.1:6379\u0026gt; cluster meet 127.0.0.1 6386\r   迁移槽和数据\n  槽迁移计划：一般使平分16383个槽即可\n  迁移数据：非常复杂\n 对目标节点发送：cluster setslot {slot} importing {sourceNodeId}命令，让目标节点准备导入槽的数据。目标节点准备导入槽{slot} 对源节点发送：cluster setslot {slot} migrating {targetNodeId}命令，让源节点准备迁出槽的数据。通知{slot}被目标节点负责 源节点循环执行cluster getkeysinslot {slot} {count}命令，每次获取count个属于槽的健。批量迁移相关键的数据 在源节点上执行migrate {targetIp} {targetPort} key 0 {timeout}命令把指定key迁移。0是对应的数据库，不过redis cluster中只有db 0 没有其它db。获取slot下{count}个健 重复执行步骤3~4直到槽下所有的键数据迁移到目标节点。5:循环迁移键 向集群内所有主节点发送cluster setslot {slot} node {targetNodeId}命令，通知槽分配给目标节点。原节点准备导出槽{slot}  #python伪代码\rdef move_slot(source , target, slot):\r#目标节 点准备导入槽slot\rtarget.cluster(\u0026quot;setslot\u0026quot;,slot,\u0026quot;importing\u0026quot;,source.nodeID) ;\r#目标节点准备全出槽slot\rsource. cluster(\u0026quot; setslot\u0026quot;,slot,\u0026quot;migrating\u0026quot;,target.nodeId);\rwhile true :\r#批量从源节点获取键\rkeys = source. cluster(\u0026quot;getkeysinslot\u0026quot;,slot,pipeline_size);\rif keys .length == 0:\r#键列表为空时，退出循环\rbreak;\r#批量迁移键到目标节点\rsource.call( \u0026quot;migrate\u0026quot;,target.host,target.port,\u0026quot;\u0026quot;,0,timeout,\u0026quot;keys\u0026quot;,keys]);\r#向集群所有主节点通知槽slot被分配给目标节点\rfor node in nodes:\rif node.flag == \u0026quot;slave\u0026quot;:\rcontinue;\rnode. cluster(\u0026quot;setslot\u0026quot;,slot,\u0026quot;node\u0026quot;,target.nodeId);\r   添加从节点\n      官方工具redis-trib.rb操作。官方工具操作时会检测你要加入的节点是否是新节点，能够避免新节点已经加入了其他集群，造成故障。所以一般用官方工具比较好，因为如果将两个集群混合在一起了，可能造成严重后果\n  redis-trib.rb add-node new_host.new_ port existing_ host:existing. port \u0026ndash;slave \u0026ndash;master-id \n  redis-trib.rb add-node 127.0.0.1:6385 127.0.0.1:6379\n  迁移数据\nredis-trib.rb reshard 127.0.0.1: 7000 #迁移数据，7000是要找个主节点，执行过程中会提示要求更多参数，按照提示填即可\r#假如数据源选择了all，则将从7000、7001、7002中各区同等数量的一部分，最终效果则是4个主节点基本平分16383个槽\r       缩容集群：与扩容类似\n  下线迁移槽：迁移槽操作与扩容一致\nredis-trib.rb reshard --from 172d689c3ed7b3721afa71a1ca20450ad0147ebb --to 97ea959862c796988810c2a4f13ee245d318942b --slots 1366 127.0.0.1: 7006 #from 7006的id to 7000的id，迁移1366个槽\rredis-trib.rb reshard --from 172d689c3ed7b3721afa71a1ca20450ad0147ebb --to xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx --slots 1365 127.0.0.1: 7006 #from 7006的id to 7001的id，迁移1366个槽\rredis-trib.rb reshard --from 172d689c3ed7b3721afa71a1ca20450ad0147ebb --to xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx --slots 1365 127.0.0.1: 7006 #from 7006的id to 7002的id，迁移1365个槽\r   忘记节点：让其它节点忘记它。redis-cli\u0026gt; cluster forget {downNodeId}，60s有效，也就是要在60内让所有节点都忘记它，否则有一个节点还保留有它的信息，会让所有节点都记起它\n  关闭节点\n#用工具忘记和关闭一起。先下从节点，再下主节点，7007是从，7006是主\rredis-trib.rb del-node 127.0.0.1:7000 c94d20dedf3d5c365286b733ef5d6bd23c3c33eb #7007的id\rredis-trib.rb del-node 127.0.0.1:7000 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx #7006的id\r     客户端路由   moved重定向：moved表示已经确定不在本节点了，完成式，已经迁移完毕了\n 客户端发送键命令（如set php best）给任意节点 节点根据key计算槽和对应节点（cluster keyslot php可以计算该hash值），如果指向自身就执行命令，否则回复moved异常给客户端 客户端重定向发送命令给目标节点（客户端不会自己发送，需要自己去写这个逻辑）  redis-cli -c -p 7000 #-c集群模式\r127.0.0.1:7000\u0026gt; cluster keyslot hello\r(integer) 866\r127.0.0.1:7000\u0026gt; set hello world\rOK\r127.0.0.1:7000\u0026gt; cluster keyslot php\r(integer) 9244\r127.0.0.1:7000\u0026gt; set php best\r-\u0026gt; Redirected to slot [9244] located at 127.0.0.1:7001 #集群模式下会帮我们自动重定向\rOK\r127.0.0.1:7001\u0026gt; get php\r\u0026quot;best\u0026quot;\rredis-cli -p 7000 #非集群模式连接\r127. 0.0.1:7000\u0026gt; cluster keyslot php\r(integer) 9244\r127.0.0.1:7000\u0026gt; set php best\r(error) MOVED 9244 127.0.0.1:7001 #非集群模式下仅返回moved异常\r   ask重定向：redis正在从源节点到目标节点迁移slot的情况，因为槽迁移是遍历槽中的key逐步执行migrate的过程，这很慢。ask则表示在槽迁移过程中\n 源节点正在与目标节点执行槽迁移 客户端已经从其它节点得到槽属于当前这个源节点，然后发送命令 源节点发现该槽其实已经迁移给目标节点了，然后回复ask转向异常给客户端，意思是这个槽确实本属于源节点，但是已经迁移到目标节点去了 客户端执行asking命令，然后发送键命令给目标节点，也是一个在客户端重定向的过程 目标节点返回    smart客户端\n  smart客户端原理：目标是追求性能。所以尽量不使用代理的模式（在集群前加一层代理，由代理梳理节点、槽、键的关系，客户端连接代理来找到目标节点，每次都要moved或者akd后进行重定向，非常损耗性能。而直连的性能就要高的多，所以需要实现客户端直连目标槽、节点，当然万一碰到moved和ask异常也还是得兼容\n 从集群中选一个可运行节点,使用cluster slots初始化槽和节点映射 将cluster slots的结果映射到本地（比如一个map），为每个节点创建JedisPool. 准备执行命令。key-\u0026gt; slot-\u0026gt; node得关系是知道得，所以可以JedisCluster直接计算然后连接目标节点  如果出现连接出错，就随机发送命令给一个活跃节点，然后回归到moved或者ask那种代理的过程 返回moved或ask（或者直接命中也有可能，但集群中这种可能较小）后获得响应，然后要记得重新初始化slot→node的缓存（更新map） 如果连接出错的过程反复超过了5次，会有Too many cluster redirection!的错误      JedisCluster源码：\n 比如随便选一个set方法：返回了一个new JedisClusterCommand{}.run(key) run方法：判断key是否为null，是则返回一个异常，否则执行runWithRetries方法 runWithRetries方法：参数attempts是一个初始化尝试的次数，默认为5次，attempts小于0就会异常；tryRandomNode表示是否尝试随机一个节点，前面能看到传入的是false；asking表示是否是ask，也是false。判断asking状态和tryRandomNode。都是false，然后这样connection = connectidnHandler. getConnecti onF romSlot(Jedi sClusterCRC16. getSlot(key));拿到连接，connectidnHandler就是在jedis初始化的时候梳理节点和槽的关系，通过key计算槽拿到对应节点连接 然后excute方法执行命令：执行过程忽略，找到异常的处理。  捕获到没有节点可达的异常则直接抛出异常 捕获连接异常，则释放当前连接，attempts\u0026lt;=1时才会connectidnHandler.renewSlotCache来刷新缓存（因为不要轻易刷新缓存，保证效率），然后attempts\u0026ndash;并重新调用runWithRetries JedisRedirectionException重定向异常，然后分别判断moved和ask异常  如果是moved异常会直接connectidnHandler.renewSlotCache来刷新缓存 释放jedis连接 如果ask异常，会设置asking为true，然后重新拿到目标节点连接 调用runWithRetries重试        smart客户端使用: JedisCluster\n  JedisCluster基本使用\nSet\u0026lt;HostAndPort\u0026gt; nodeList = new HashSet \u0026lt;HostAndPort\u0026gt;();\rnodeList.add(new HostAndPort(HOST1, PORT1));\rnodeList.add(new HostAndPort(HOST2, PORT2));\rnodeList.add(new HostAndPort(HOST3, PORT3));\rnodeList.add(new HostAndPort(HOST4, PORT4));\rnodeList.add(new HostAndPort(HOST5, PORT5));\rnodeList.add(new HostAndPort(HOST6, PORT6));\rJedisCluster redisCluster = new JedisCluster(nodeList, timeout, poolConfig);redisCluster.command... //执行命令就好了，归还连接都不需要，jediscluster帮我们做了\r  使用技巧：  保证单例：内置了所有节点的连接池，从节点也有连接，保证故障转移后也有完整连接池。单例保证资源唯一性，并且不至于资源浪费 无需手动借还连接池 合理设置commons- pool      整合spring\npublic class JedisClusterFactory {\rprivate JedisCluster jedisCluster;\rprivate List\u0026lt;String\u0026gt; hostPortList;\rprivate int timeout; //单位是毫秒\rprivate Logger logger = LoggerFactory.getLogger(JedisClusterFactory.class);\r//初始化方法\rpublic void init() {\rJedisPoolConfig jedisPoolConfig = new JedisPoolConfig();//用于设置相关参数\rSet \u0026lt;HostAndPort\u0026gt; nodeSet = new HashSet\u0026lt;HostAndPort\u0026gt;();\rfor(String hostPort : hostPortList) {\rString[] arr = hostPort.split(\u0026quot;:\u0026quot;);\rif (arr.length != 2) {\rcontinue;\r}\rnodeSet.add(new HostAndPort(arr[0], Integer .parseInt(arr[1])));\r}\rtry {\rjedisCluster = new JedisCluster(nodeSet, timeout, jedisPoolConfig) ;\r} catch (Exception e) {\rlogger.error(e.getMessage(), e);\r}\r}\r//销毁方法\rpublic void destroy() {\rif (jedisCluster != null) {\rtry {\rjedisCluster.close();\r} catch (I0Exception e) {\rlogger.error(e.getMessage(), e);\r}\r}\r}\rpublic JedisCluster getJedisClusterO) {\rreturn jedisCluster;\r}\rpublic void setHostPortList(List\u0026lt;String\u0026gt; hostPortList) {\rthis. hostPortList = hostPortList;\r}\rpublic void setTimeout(int timeout) {\rthis. timeout = timeout;\r}\r}\r \u0026lt;bean id= \u0026quot;jedisClusterFactory\u0026quot; class= \u0026quot;com.carlosfu.redis.factory.JedisClusterFactory\u0026quot; init-method= \u0026quot;init\u0026quot; destroy-method=\u0026quot;destroy\u0026quot;\u0026gt;\r\u0026lt;property name= \u0026quot;hostPortList \u0026quot;\u0026gt;\r\u0026lt;list\u0026gt;\r\u0026lt;value\u0026gt;127.0.0.1:7000\u0026lt;/value\u0026gt;\r\u0026lt;value\u0026gt;127.0.0.1:7001\u0026lt;/value\u0026gt;\r\u0026lt;value\u0026gt;127.0.0.1:7002\u0026lt;/value\u0026gt;\r\u0026lt;value\u0026gt;127.0.0.1:7003\u0026lt;/value\u0026gt;\r\u0026lt;value\u0026gt;127.0.0.1:7004\u0026lt;/value\u0026gt;\r\u0026lt;value\u0026gt;127.0.0.1:7005\u0026lt;/value\u0026gt;\r\u0026lt;/list\u0026gt;\r\u0026lt;/property\u0026gt;\r\u0026lt;property name= \u0026quot;timeout\u0026quot; value= \u0026quot;1000\u0026quot; /\u0026gt;\r\u0026lt;/bean\u0026gt;\r\u0026lt;bean id= \u0026quot;jedisCluster\u0026quot; factory-bean= \u0026quot;jedisClusterFactory\u0026quot; factory-method= \u0026quot;getJedisCluster\u0026quot;/\u0026gt;\u0026lt;/bean\u0026gt;\r\u0026lt;bean id= \u0026quot;redisClusterService\u0026quot; class= \u0026quot;xxx.RedisClusterServiceImpl\u0026quot;\u0026gt;\u0026lt;/bean\u0026gt;\r public class RedisClusterServiceImpl implements RedisService { //RedisService省略\rprivate Jedi sCluster jedi sCluster;\rpublic String set(String key, String value) {\rreturn jedisCluster . set(key, value);\r}\rpublic String get(String key) {\rreturn jedisCluster . get(key);\r}\rpublic void setJedisCluster(Jedi sCluster jedisCluster) {\rthis. jedisCluster = jedisCluster;\r}\r}\r //测试类\rpublic class Jedi sClusterSpringTest extends BaseTest {\r@Resource(name = \u0026quot; redi sClusterService\u0026quot; )\rprivate Redi sService redi sClusterService;\r@Test\rpublic void testNotNullO {\rassertNotNul I(redi sClusterService);\rredi sClusterService . set(\u0026quot;hello\u0026quot;, \u0026quot;world\u0026quot;);\rassertTrue(\u0026quot;world\u0026quot;.equals(redisClusterServicel.get(\u0026quot;hello\u0026quot;)));\r}\r}\r 非常简单，无需去用spring data jedis的库\n  多节点命令实现\n//获取所有节点的JeidsPool\r//获取主节点即可，获取到所有主节点连接就可以进行多节点操作了\r//一般来说是try catch处理，这里仅简单演示，写的时候注意用try catch即可\rMap \u0026lt; String, JedisPool\u0026gt; jedisPoolMap = jedisCluster.getClusterNodes0;\rfor (Entry\u0026lt;String, JedisPool\u0026gt; entry : jedisPoolMap.entrySet() {\r//获取每个节点的Jedis连接\rJedis jedis = entry.getValue().getResource();\r//只删除主节点数据\rif (!isMaster(jedis)) { //判断主节点的方法，只需执行一个row（听起来是这个，具体拼写不知道）命令，会返回master还是sleve。如果客户端不支持这个命令，infoReplication中row的字段来判断\rcontinue;\r}\r// finally close\r}\r   批量命令实现：mget mset必须在一个槽，这样的条件很苛刻，将用以下4中方法解决\n 串行mget：for循环遍历所有key，分别操作。n次网络操作，n次网络时间，效率很差 串行IO：做一个聚合，将CRC16hash计算槽，根据槽、节点对应关系，将属于相同节点的key放入同一子集合来mget，多个节点的mget操作可以并行，节点数次网络操作，节点数次网络时间 并行IO：做一个聚合，将CRC16hash计算槽，根据槽、节点对应关系，将属于相同节点的key放入同一子集合来mget，多个节点的mget操作可以多线程并行，使用节点数的网络操作次数，1次网络时间 hash_tag：将key进行hash_tag的包装，{tag}key1、{tag}key2\u0026hellip;{tag}keyN，让所有key都落到一个redis节点上，每次mget就可以只去一个节点取即可     方案 优点 缺点 网络IO     串行mget 编程简单少量keys满足需求 大量keys请求延迟严重O(keys) O(keys)   串行IO 编程简单少量节点满足需求 大量node延迟严重 O(nodes)   并行IO 利用并行特性延迟取决于最慢的节点 (多线程)编程复杂(多线程)超时定位问题难 O(max_slow(node))   hash_tag 性能最高 读写增加tag维护成本tag分布易出现数据倾斜 O(1)          故障转移 故障发现   通过ping/pong消息实现故障发现:不需要sentinel  主观下线：定义:某个节点认为另一一个节点不可用，\u0026ldquo;偏见\u0026rdquo;。节点A定期发送ping给节点B，成功节点B回复PONG，节点A记录与节点B的最后通信时间，如果ping失败了则通信异常断开连接，在下一次执行ping时，如果与节点B的最后通信时间超过了node-timeout则表示节点B为pfail状态，即主观下线 客观下线：定义:当半数以上持有槽的主节点都标记某节点主观下线，只有主节点才有读写和槽维护的工作，从节点只做复制的作用。节点B接收到其它节点发来的ping消息，它包含了pfail消息，会将该主观下线的信息添加到其自身维护的一个故障链表中，该故障链表中包含了当前节点收到的每个节点对其它节点的信息，能知道每个节点对每个节点的看法，链表是有周期的，周期为cluster-node-timeout*2，保证很久之前的故障消息不再生效，保证客观下线的公平性和有效性  尝试客观下线：计算有效下线报告数量，大于持有槽的主节点总数的一般，则更新为客观下线，向集群广播下线的节点的fail消息；否则退出尝试下线方法 下线通知：通知集群内所有节点标记故障节点为客观下线；通知故障节点的从节点触发故障转移流程    故障恢复  资格检查：对多个从节点进行资格检查，在资格审查范围内的从节点才有资格去做故障恢复的工作  每个从节点检查与故障主节点的断线时间。 超过cluster-node-timeout * cluster-slave-validity-factor取消资格。cluster-node-timeout默认15000毫秒，cluster-slave-validity-factor默认10   准备选举时间：为了使偏移量值最大的从节点具备优先成为主节点的条件，因为偏移量最大，保证与原主节点数据一致性最高  offset较大会优先去进行选举，比如offset最大的节点rank=0，第二rank=1，第三rank=2，那么rank=0的节点拥有最小的准备选举时间，延迟1秒就去进行选举，rank=1的节点延迟2秒才去选举，rank=2的节点延迟3秒才去选举   选举投票：让其它非客观下线的主节点进行投票，选票大于主节点一半数即该从节点选举为新的主节点，是否投票的机制与前面主从故障转移是一样的 替换主节点：  1.当前从节点取消复制变为主节点。(slaveof no one)。 2.执行clusterDelSlot撤销故障主节点负责的槽，并执行clusterAddSlot把这些槽分配给自己。 3.向集群广播自己的pong消息,表明已经替换了故障从节点    故障转移演练 1.执行kill -9节点模拟宕机\n2.观察客户端故障恢复时间：大概不到20秒\n3.观察各个节点的日志\n 7000：被kill后没有任何日志，重启后日志记录连接到了新的master 7003：7000原来的从节点  与原来的master7000失联了，很多连接失败的信息 接收到FAIL消息，客观下线 打印offset， 成为新的master 清除7000主节点的一些信息，如FAIL信息 与其它从节点同步   7002：清除7000主节点的一些信息，如FAIL信息；等等，不再多看，有兴趣自己看  开发运维常见问题 集群完整性  cluster-require-full-coverage，默认为yes  集群中16384个槽全部可用：保证集群完整性 如果节点故障或者正在故障转移，将(error) CLUSTERDOWN The cluster is down，整个集群不可用 大多数业务无法容忍，cluster-require-full-coverage建议设置为no    带宽消耗  问题  官方建议: 1000个节点 PING/PONG消息 不容忽视的带宽消耗   三方面：  消息发送频率:节点发现与其它节点最后通信时间超过cluster-node-timeout/2时会直接发送ping消息 消息数据量: slots槽数组(2KB空间)和整个集群1/10的状态数据(10个节点状态数据约1KB) 节点部署的机器规模:集群分布的机器越多且每台机器划分的节点数越均匀,则集群内整体的可用带宽越高。   一个例子：规模，节点200个、20台物理机(每台10个节点)  cluster-node-timeout = 15000，ping/pong带宽为25Mb cluster-node-timeout = 20000，ping/pong带宽低于15Mb   优化  避免\u0026quot;大\u0026quot;集群：避免多业务使用一个集群，一个大业务也可以多集群（比如一个大的推荐服务，根据不同推荐类型使用不同集群，因为不同推荐类型之间没有相关性） cluster-node-timeout：带宽和故障转移速度的均衡尽量均匀分配到多机器上:保证高可用和带宽 尽量均匀分配到多机器上：保证高可用和带宽。可以自己去开发一套分配规则来达到负载的均衡（使用工具）    Pub/Sub广播  问题：publish在集群每个节点广播，加重带宽。对任意节点执行publish发布消息，publish将广播到整个集群 解决：单独\u0026quot;走\u0026quot;一套Redis Sentinel。因为发布订阅的功能本身比较独立  集群倾斜  集群倾斜  数据倾斜:内存不均  节点和槽分配不均，导致数据倾斜  redis-trib.rb info ip:port查看节点、槽、键值分布 redis-trib.rb rebalance ip:port进行自动均衡节点和槽：redis内部自己的算法。谨慎使用，建议自己做计划手动迁移，而不要直接rebalance   不同槽对应键值数量差异较大  CRC16正常情况下比较均匀。 可能存在hash_tag：通常是主要原因 cluster countkeysinslot {slot}获取槽对应键值个数   包含bigkey：  因为数据只能以key为单位存储在某个节点上，比如一个hash、set等非常大，有几百万元素，就会造成数据倾斜 从节点: redis-cli \u0026ndash;bigkeys，发现bigkey，建议在从节点执行 优化：优化数据结构。拆分该大个数据，二次hash拆分等   内存相关配置不一致：我们知道如hash、list、zset等都有一些内存优化的配置参数，比如整数集合的优化等对于redis来说会节省一些内存，假如项目中大量使用了集合、hash的时候，我们做了一些优化，但没有在所有节点做优化，就会出现倾斜；还有假如某个节点的客户端缓冲区比较高，比如节点被执行了moniter命令，也会出现数据倾斜的情况；还有我们知道redis的键值对是存在一个hash表中的，如果key较多，该表也会扩容，扩容如果刚好触发到某一个数值，需要做rehash，hash表也可能会占用很大内存  hash-max- ziplist-value、set-max-intset-entries等 优化：定期\u0026quot;检查\u0026quot;配置一致性     请求倾斜：热点  热点key：重要的key或者bigkey。比如redis某个节点有一个重要的key，比如一个微博大V在重要的时间节点发布了一个重要消息会落在一个重要的key上，就会存在热点问题 优化：后面会讲缓存设计与优化，这里不详细讲  避免bigkey 热键不要用hash_tag 当一致性不高时，可以用本地缓存 + MQ。比如java的本地缓存，没有网络时间，肯定比redis效率高，但就需要考虑gc的问题，还需要达到一致性，就可以使用mq，比如redis中做了更新就去更新本地缓存达到一致性        读写分离  只读连接：集群模式的从节点不接受任何读写请求  如果对从节点请求，它将重定向到负责槽的主节点 readonly命令可以使从节点只读：连接级别命令，即连接断掉以后，需要重新对该从节点执行readonly来连接   读写分离：更加复杂  与单机同样的问题：复制延迟、读取过期数据、从节点故障 需要修改客户端：redis-cluster提供了cluster slaves {nodeId}命令，可以根据主节点id获取其从节点，所以需要实现自己的客户端，很复杂，要维护一个slave的池子，要知道从节点和槽的关系   建议：redis集群使用读写分离成本很高，尽量选择扩展集群规模，而不是利用从节点来实现读写分离。实在没有集群扩展成本，也可以考虑自己实现客户端来实现读写分离  数据迁移   官方迁移工具: redis-trib.rb import\n./redis-trib.rb import --from 127 .0.0.1:6388 --copy 127.0.0.1:7000 #这里copy，也有replace参数。\r#\r  只能从单机迁移到集群 不支持在线迁移：source需要停写，否则源节点在迁移期间的写入的数据可能不会被记录。redis-trib.rb使用的是一个scan的模式，所有被scan到的数据都会被copy，scan期间源节点有新的数据，可能也会正好被scan到，有的数据加入时可能scan的游标已经到更后面了，就不会被scan到 不支持断点续传：迁移过程中断不会记录之前迁移了的过程，只能重新重头迁移 单线程迁移：影响速度。数据较大可能迁移比较慢    在线迁移工具：都是在GitHub开源的\n 唯品会：redis-migrate-tool 豌豆荚：redis-port    集群vs单机  集群限制  key批量操作支持有限：例如mget、mset必须在一 个slot Key事务和Lua支持有限：如果使用事务或者Lua，操作的key必须在一个节点，虽然可以使用hash_tag使它们落在一个节点上，但本质上还是受限的 key是数据分区的最小粒度：不支持bigkey分区 不支持多个数据库：集群模式下只有一个db 0。当然在一般的单机下也不建议使用多db模式（最多16） 复制只支持一层：不支持树形复制结构   思考：分布式Redis不一定好  Redis Cluster：满足容量和性能的扩展性，很多业务”不需要\u0026quot;  大多数时客户端性能会\u0026quot;降低\u0026quot;：比如批量操作再怎么优化也不如单节点原子操作 命令无法跨节点使用：mget、keys、 scan、flush、sinter等 Lua和事务无法跨节点使用。 客户端维护更复杂: SDK和应用本身消耗(例如更多的连接池)。   很多场景Redis Sentinel已经足够好    总结  Redis cluster数据分区规则采用虚拟槽方式(16384个槽) ,每个节点负责一部分槽和相关数据,实现数据和请求的负载均衡。 搭建集群划分四个步骤:准备节点、节点握手、分配槽、复制。redis-trib.rb工具用于快速搭建集群。 集群伸缩通过在节点之间移动槽和相关数据实现。  扩容时根据槽迁移计划把槽从源节点迁移到新节点。 收缩时如果下线的节点有负责的槽需要迁移到其它节点,再通过cluster forget命令让集群内所有节点忘记被下线节点。   使用smart客户端操作集群达到通信效率最大化,客户端内部负责计算维护键-\u0026gt;槽-\u0026gt;节点的映射,用于快速定位到目标节点。 集群自动故障转移过程分为故障发现和节点恢复。节点下线分为主观下线和客观下线,当超过半数主节点认为故障节点为主观下线时标记它为客观下线状态。从节点负责对客观下线的主节点触发故障恢复流程,保证集群的可用性。 开发运维常见问题包括：超大规模集群带宽消耗，pub/sub广播问题，集群倾斜问题，单机和集群对比等  开发规范 键值设计   key设计\n  可读性和可管理性：以业务名(或数据库名)为前缀(防止key冲突) , 用冒号分割，比如业务名:表名:id ,如: ugc:video:1、database:table:1\n  简洁性：保证语义的前提下，控制key的长度，当key较多时，内存占用也不容忽视( redis3：39字节embstr，这里的意思是redis3版本的embstr编码可以很大程度节省内存) , 如 user:{uid}:friends:messages:{mid}简化为 u:{uid}:f:m :{mid}\ntype #对外可能都是string类型\robject encoding key #查看key的编码。内部编码各不相同：int、raw、embstr等，大于39个字节的字符串是raw，embstr则是用于存储小于等于39个字节的字符串。int会有int的优化，embstr也会有一些优化，redis在分配内存的时候，除了给redis对象分配内存，还会给其存储的字符串内容分配内存，embstr则是将对象和其字符串内容进行一次性分配，并且是连续的内存，可以节省分配内存的次数，也能节省一定的空间。在redis4版本之后对redis内部的sds实现做了一些优化，embstr的阈值更变为44个字节了\r Redis3 embstr测试\n   key-value个数 39字节 40字节     10万 15.69M 18.75M   100万 146.29M 176.81M   1000万 1.47G 1.77G   1亿 14.6G 17.7G      不要包含特殊字符。反例:包含空格、换行、单双引号以及其他转义字符\n    value设计\n  拒绝bigkey\n  阈值（并非绝对，只是参考标准）\n string类型控制在10KB以内 hash、list、set、zset元素 个数不要超过5000    反例：一个包含几百万个元素的list、hash等， 一个巨大的json字符串\n  危害：\n 网络阻塞：比如千兆网，最大流量为128m，一个热点key的qps为10w，那么key为10kb，也能差不多瞬间将网络吃满 Redis阻塞：慢查询，hgetall、lrange、 zrange(例如几十万)等全量操作，因为redis单线程，所以会阻塞其它命令 集群节点数据不均衡 频繁序列化：应用服务器CPU消耗    bigkey发现\n  应用异常：报错，如一个bigkey操作，其它命令将阻塞然后time out\n  官方工具：redis-cli \u0026ndash;bigkeys\n  自己实现：scan + debug object\ndebug object key #获取序列化长度。如果bigkey很大，debug object也可能阻塞redis，可以使用zcat、hlen、strlen等，比如长度大于多少来判定是否为bigkey\r   主动报警：网络流量监控、客户端监控\n  改造redis源码内核：内核热点key问题优化，在redis中维护一个堆来记录redis对key大小的变化\n    bigkey删除：删除也可能会阻塞redis\n  阻塞:注意隐性删除(过期、rename等)：也是删除，可能会阻塞redis，且过期、删除的命令不会记录在redis的慢查询当中，redis慢查询只记录客户端的行为，过期、删除只会记录在redis的license（一个记录延迟事件的记录）中，但是这些命令会同步给slave，可以在从节点找到对应慢查询\n  Redis 4.0 : lazy delete (unlink命令)，后台删除，单独开启线程去执行删除，不会阻塞redis了\n  通过scan删除\npublic void delBigHash(String host, int port, String password, String bigHashKey) {\rJedis jedis = new Jedis(host, port);\rif (password != null \u0026amp;\u0026amp; !\u0026quot;\u0026quot; .equals(password)) {\rjedis.auth(password);\r}\rScanParams scanParams = new ScanParams().count(100);\rString cursor = \u0026quot;0\u0026quot;;\rdo {\rScanResult\u0026lt;Entry\u0026lt;String, String\u0026gt;\u0026gt; scanResult = jedis.hscan(bigHashKey,cursor, scan); //不全，不知道对不对\rList\u0026lt;Entry\u0026lt;String, String\u0026gt;\u0026gt; entryList = scanResult. getResult();\rif (entryList != null \u0026amp;\u0026amp; !entryList. isEmpty()) {\rfor (Entry\u0026lt;String, String\u0026gt; entry : entryList) {\rjedis.hdel(bigHashKey, entry . getKey());\r}\r}\rcursor = scanResult . getStringCursor();\r} while (!\u0026quot;0\u0026quot; .equals(cursor));\rjedis.del(bigHashKey);//删除bigkey\r}\r     bigkey预防\n 优化数据结构：例如二级拆分 物理隔离或者万兆网卡：治标不治本 命令优化：例如hgetall-\u0026gt; hmget、hscan 报警和定期优化    bigkey总结\n 牢记Redis单线程特性 选择合理的数据结构和命令 清楚自身OPS 了解bigkey的危害        选择合适的数据结构   实体类型(数据结构内存优化:例如ziplist ,注意内存和性能的平衡)\n  反例 set user:1:name tom; set user:1:age 19; set user:1:favor football;\n  正例：使用hash，前面有讲好处 hmset user:1 name tom age 19 favor football\n  一个例子、三种方案：需求: picId= \u0026gt; userId (100万)\n  全部string：set picId userId。常规方法。使用内存116m\n 优点：编程简单 缺点：浪费内存；全量获取复杂     Key Value     pic:1 user:1   \u0026hellip;\u0026hellip; \u0026hellip;\u0026hellip;   pic:1000000 user:1000000      一个hash：hset allPics picId userId。形成一个bigkey，不合理的设计。使用内存129m\n 优点：无 缺点：浪费内存；形成bigkey     Key Field Value     allPics pic:1\u0026hellip;..pic:1000000 user:1\u0026hellip;..user:1000000      若干个小hash：hset picId/100 picId%100 userId。使用内存26m\n 优点：节省内存 缺点：编程复杂；超时问题；ziplist性能问题     Key Field Value     segment:0 pic:1\u0026hellip;..pic:100 user:1\u0026hellip;..user:100   \u0026hellip;\u0026hellip; \u0026hellip;\u0026hellip;    segment:99999 pic:1\u0026hellip;..pic:100 user:999901\u0026hellip;..user:1000000        内存\n 配置(支持动态修改)：当元素个数少于512、元素value小于64字节时，redis默认使用zplist来存储hash结构  hash-max-ziplist-entries 512 hash-max-ziplist-value 64   ziplist：有好有坏，需要衡量，所以才配置为元素个数较少、元素value较小时使用  连续内存：节省内存 读写有指针位移，最坏O(n2)，影响读写效率 新增删除有内存重分配，影响增删效率      过期设计   键值生命周期：Redis不是垃圾桶，不要什么东西都扔给redis，还不控制缓存时间\n 周期数据需要设置过期时间，object idle time可以找到超出指定闲置时间的垃圾kv，即多久没有使用的kv 过期时间不宜集中：缓存穿透和雪崩等问题，比如每三小时集体过期，并通过数据库重建缓存    命令优化  [推荐] O(N)以上命令关注N的数量：例如，hgetall、Irange、 smembers、zrange、 sinter等并非不能使用,但是需要明确N的值。有遍历的需求可以使用hscan、sscan、 zscan代替。即主要考虑n的大小 [推荐]禁用命令：禁止线上使用keys、flushall、 flushdb等，通过redis的rename机制禁掉命令，或者使用scan的方式渐进式处理。 [推荐]合理使用select：选择redis数据库，可以用redis的db对一些数据进行隔离或测试环境区分等。但redis的多数据库较弱，使用数字进行区分（db 0~15），很多客户端对redis数据库的操作支持较差；注意同时多业务用多数据库实际还是单线程处理，还是会有干扰，频繁切换redis数据库也有一定消耗 [推荐] Redis事务功能较弱，不建议过多使用：Redis的事务功能较弱(不支持回滚)，需要时借助外部来实现，比如java的事务实现等；而且集群版本(自研和官方)要求一次事务操作的key必须在一个slot上(可以使用hashtag功能解决，但也可能造成数据不均匀问题)。使用时不要太过信赖，只是一个辅助功能而已 [推荐] Redis集群版本在使用Lua上有特殊要求：不要过度使用，虽然可以实现很多功能。或者单独开一个redis来做对应的功能，避免一些集群问题  所有key，必须在1个slot上,否则直接返回error，同样通过hashtag可以解决 \u0026lsquo;-ERR eval/evalsha command keys must in same slot\\r\\n\u0026quot;   [建议] 必要情况下使用monitor命令时，要注意不要长时间使用。monitor可以查看redis监控redis执行的命令，但是如果并发量过高，会有大流量打在monitor-client（monitor也是一个redis客户端）上，会造成monitor无法实时消费大量的流量，会导致输出缓冲区暴增，会占用redis内存，撑爆redis内存  客户端优化 Java客户端优化\n  [推荐] 避免多个应用使用一个Redis实例\n 问题  业务之间key冲突，可以通过select redis数据库来解决 单线程redis，业务A的命令会影响到业务B   解决  不相干的业务拆分：不要使用一个redis实列，可以在一个机器上启动多个redis实例合理利用多核机器 公共数据做服务化：有公共数据，比如视频、音频等，不论底层使用redis还是mysql，对外只暴露服务接口即可，如http接口，让其作为单独的微服务应用对外提供服务      [推荐] 使用连接池，标准使用方式\nJedis jedis = null;\rtry {\rjedis = jedisPool,getResource();\r//具体的命令\rjedis. executeCommand()\r} catch (Exception e) {\rlogger.error(\u0026quot;op key {} error: \u0026quot; + e.getMessage(), key, e);\r} finally {\r//注意这里不是关闭连接，在JedisPool模式下，Jedis会被归还给资源池。\rif (jedis != null)\rjedis. close();\r}\r   开发运维常见坑 Redis内存管理 RedisCacheCloud https://github.com/sohutv/cachecloud\nRedis云平台CacheCloud。老师自己在原来公司参与开发的\n Redis规模化运维 快速构建 机器部署 应用接入 用户功能 运维功能  Redis规模化运维  遇到的问题  发布构建繁琐，私搭乱盖 节点\u0026amp;机器等运维成本 监控报警初级   CacheCloud  一键开启Redis。 (Standalone、 Sentinel、 Cluster) 机器、应用、实例监控和报警。 客户端:透明使用、性能上报。 可视化运维:配置、扩容、Failover、机器/应用/实例上下线。 已存在Redis直接接入和数据迁移。   使用规模  300+亿commands/day 3TB Memory Total 1300+ Instances Total 200+ Machines Total   使用场景  全量视频缓存(视频播放API) :跨机房高可用 消息队列同步(RedisMQ中间件) 分布式布隆过滤器(百万QPS) 计数系统:计数(播放数) 其他:排行榜、社交(直播)、实时计算(反作弊)等。    快速构建 https://github.com/sohutv/cachecloud/wiki\n机器部署 应用接入 用户功能 运维功能 ","date":"2020-11-11","permalink":"https://yuanyatianchi.github.io/post/db.kv.redis/","tags":["db","redis"],"title":"Redis"},{"content":"mysql https://www.mysql.com/ ，https://www.mysql.com/cn/\n 3306 sql  DDL，数据定义语言。定义和管理数据对象，如数据库，数据表等。CREATE、DROP、ALTER DML，数据操作语言。用于操作数据库对象中所包含的数据。| NSERT、UPDATE、DELETE DQL，数据查询语言。用于查询数据库数据。SELECT DCL，数据控制语言。用来管理数据库的语言，包括管理权限及数据更改。GRANT、COMMIT、ROLLBACK    client go $ go get -u github.com/go-sql-driver/mysql\r 连接 db/db.go import (\r\u0026quot;database/sql\u0026quot;\r_ \u0026quot;github.com/go-sql-driver/mysql\u0026quot; //mysql驱动，不使用其提供的方法，通过'_'加载其初始化函数即可\r)\rvar (\r/*DB是一个数据库(操作)句柄，代表一个具有零到多个底层连接的连接池，它可以安全的被多个goroutine同时使用。\rsql包会自动创建和释放连接，它也会维护一个闲置连接的连接池。*/\rMyDB *sql.DB\rerr error\r)\rfunc init() {\r/*Open：创建一个DB实例。Open过程只验证参数，不参创建与数据库的连接，自然也不会校验账号密码数据源名称中账号密码等数据正确性*/\rMyDB, err = sql.Open(\u0026quot;mysql\u0026quot;, \u0026quot;root:yuanya@tcp(192.168.31.108:3306)/yuanya\u0026quot;)\rif err != nil {\rpanic(err)\r}\rdefer MyDB.Close()\r/*配置\rMyDB.SetMaxOpenConns(0) //设置最大连接数，默认为0(\u0026lt;=0时无限制)\rMyDB.SetConnMaxLifetime(0) //设置最大闲置连接数，默认为0(\u0026lt;=0时不保留闲置连接)\rMyDB.SetMaxIdleConns(-1) //设置连接池大小，默认为-1(\u0026lt;=0时)*/\r/*尝试与数据库建立连接。将检查数据源的名称是否合法*/\rif err := MyDB.Ping(); err != nil {\rpanic(err.Error())\r}\r}\r 操作 dao/UserDao.go type User struct {\rId int\rUsername string\rPassword string\r}\r/*row：查询一行结果*/\rfunc getById(id int) (user *User, err error) {\rsql := \u0026quot;select * from user where id=?\u0026quot;\r/*sql拼接*/\rrow := db.MyDB.QueryRow(sql, id) //QueryRow返回一行结果\rerr = row.Scan(\u0026amp;user.Id, \u0026amp;user.Username, \u0026amp;user.Password) //Scan将该行查询结果各列分别保存进dest参数指定的值中\rreturn\r}\r/*rows：查询多行结果*/\rfunc listByUsernameLike(usernameLike string) (users []*User, err error) {\rsql := \u0026quot;select * from user where username like ?\u0026quot;\r/*sql拼接\rrows, err := db.MyDB.Query(sql, usernameLike) //Query返回多行结果\rif err != nil {\rfmt.Println(err)\r}*/\r/*sql预处理。任何时候都不应该拼接SQL语句，而是要进行预处理，以防SQL注入(如\u0026quot;or 1=1#\u0026quot;等)*/\rstmt, err := db.MyDB.Prepare(sql)\rif err != nil {\rfmt.Println(\u0026quot;Prepare异常\u0026quot;, err)\r}\rrows, err := stmt.Query(usernameLike) //stmt方法与db基本一致，只是不用再传入sql\rif err != nil {\rfmt.Println(\u0026quot;Query异常\u0026quot;, err)\r}\r/*迭代遍历行*/\rfor rows.Next() {\ruser := User{}\rrows.Scan(\u0026amp;user.Id, \u0026amp;user.Username, \u0026amp;user.Password)\rusers = append(users, \u0026amp;user)\r}\rreturn\r}\r/*增*/\rfunc insert(user *User) (err error) {\rsql := \u0026quot;insert into user(username, password) value(?,?)\u0026quot;\rstmt, err := db.MyDB.Prepare(sql)\rif err != nil {\rfmt.Println(\u0026quot;Prepare异常\u0026quot;, err)\r}\r_, err = stmt.Exec(user.Username, user.Password) //执行\rif err != nil {\rfmt.Println(\u0026quot;Exec异常\u0026quot;, err)\r}\rreturn\r}\r/*事务。db.Begin开启事务，tx.Rollback()回滚事务，tx.Commit()提交事务\r如果数据库具有单连接状态的概念，该状态只有在事务中被观察时才可信。一旦调用BD.Begin,返回的Tx会绑定到单个连接\r当调用事务Tx的Commit或Rollback后，该事务使用的连接会归还到DB的闲置连接池中*/\rfunc tx() {\rtx, err := db.MyDB.Begin() //开启事务\rif err != nil {\rif tx != nil {\rtx.Rollback() //回滚事务\r}\rfmt.Printf(\u0026quot;begin trans failed, err:%v\\n\u0026quot;, err)\rreturn\r}\rsql1 := \u0026quot;Update user set age=30 where id=?\u0026quot;\rret1, err := tx.Exec(sql1, 2)\rif err != nil {\rtx.Rollback()\rfmt.Printf(\u0026quot;exec sql1 failed, err:%v\\n\u0026quot;, err)\rreturn\r}\raffRow1, err := ret1.RowsAffected()\rif err != nil {\rtx.Rollback()\rfmt.Printf(\u0026quot;exec ret1.RowsAffected() failed, err:%v\\n\u0026quot;, err)\rreturn\r}\rsql2 := \u0026quot;Update user set age=40 where id=?\u0026quot;\rret2, err := tx.Exec(sql2, 3)\rif err != nil {\rtx.Rollback()\rfmt.Printf(\u0026quot;exec sql2 failed, err:%v\\n\u0026quot;, err)\rreturn\r}\raffRow2, err := ret2.RowsAffected()\rif err != nil {\rtx.Rollback()\rfmt.Printf(\u0026quot;exec ret1.RowsAffected() failed, err:%v\\n\u0026quot;, err)\rreturn\r}\rfmt.Println(affRow1, affRow2)\rif affRow1 == 1 \u0026amp;\u0026amp; affRow2 == 1 {\rfmt.Println(\u0026quot;事务提交啦...\u0026quot;)\rtx.Commit() //提交事务\r} else {\rtx.Rollback()\rfmt.Println(\u0026quot;事务回滚啦...\u0026quot;)\r}\rfmt.Println(\u0026quot;exec trans success!\u0026quot;)\r}\r CREATE TABLE user(\rid INT PRIMARY KEY AUTO_INCREMENT,\rusername VARCHAR(15) UNIQUE NOT NULL,\rpassword VARCHAR(15) NOT NULL,\r)ENGINE=InnoDB AUTO_INCREMENT=1 DEFAULT CHARSET=utf8mb4;\r java  jdbc  public class JdbcDemo {\rstatic final String DRIVER = \u0026quot;com.mysql.jdbc.Driver\u0026quot;;\rstatic final String URL = \u0026quot;jdbc:mysql://localhost:3306/yuanya_mybatis?useUnicode=true\u0026amp;characterEncoding=utf8\u0026amp;allowMultiQueries=true\u0026quot;;\rstatic final String USERNAME = \u0026quot;root\u0026quot;;\rstatic final String PASSWORD = \u0026quot;root\u0026quot;;\r@Test\rpublic void StatementDemo() {\r//...\r}\r@Test\rpublic void PreparedStatementDemo() {\r//...\r}\r@Test\rpublic void batchDemo() {\r//...\r}\r}\r Statement 无预编译，每次需要经历完整的过程，都较慢\n@Test\rpublic void QueryStatementDemo() {\rConnection conn = null;\rStatement stmt = null;\rList\u0026lt;User\u0026gt; users = new ArrayList();\rtry {\r//STEP 2: 注册mysql的驱动\rClass.forName(DRIVER);\r//STEP 3: 获得一个连接\rconn = DriverManager.getConnection(URL, USERNAME, PASSWORD);\r//STEP 4: 创建一个查询\rString name = \u0026quot;yuanya\u0026quot;;\rString sql = \u0026quot;SELECT * FROM user WHERE name='\u0026quot; + name + \u0026quot;'\u0026quot;; //加'防sql注入\rstmt = conn.createStatement(); //Statement\rResultSet rs = stmt.executeQuery(sql); //执行查询，获得结果集\r//STEP 5: 从结果集中获取数据并转化成bean\rwhile (rs.next()) {\rUser user = new User();\ruser.setId(rs.getInt(\u0026quot;id\u0026quot;));\ruser.setName(rs.getString(\u0026quot;name\u0026quot;));\ruser.setAge(rs.getInt(\u0026quot;age\u0026quot;));\ruser.setDeleteFlag(rs.getString(\u0026quot;delete_flag\u0026quot;));\rusers.add(user);\r}\r// STEP 6: 关闭连接\rrs.close();\rstmt.close();\rconn.close();\r} catch (SQLException se) {\r// Handle errors for JDBC\rse.printStackTrace();\r} catch (Exception e) {\r// Handle errors for Class.forName\re.printStackTrace();\r} finally {\r// finally block used to close resources\rtry {\rif (stmt != null)\rstmt.close();\r} catch (SQLException se2) {\r// nothing we can do\r}\rtry {\rif (conn != null)\rconn.close();\r} catch (SQLException se) {\rse.printStackTrace();\r}\r}\r}\r PreparedStatement 有预编译，所以第一次查询很慢，但是之后很快\n@Test\rpublic void QueryPreparedStatementDemo() {\rConnection conn = null;\rPreparedStatement stmt = null;\rList\u0026lt;User\u0026gt; users = new ArrayList();\rtry {\r// STEP 2: 注册mysql的驱动\rClass.forName(DRIVER);\r// STEP 3: 获得一个连接\rconn = DriverManager.getConnection(URL, USERNAME, PASSWORD);\r// STEP 4: 创建一个查询\rString sql = \u0026quot;SELECT * FROM user WHERE name=? \u0026quot;; //占位符，有预处理，可以避免sql注入\rstmt = conn.prepareStatement(sql); //\rstmt.setString(1, \u0026quot;yuanya or 1=1\u0026quot;);\r/*得到的sql将是\u0026quot;SELECT * FROM user WHERE name='yuanya or 1=1'\u0026quot;而不是\u0026quot;SELECT * FROM user WHERE name=yuanya or 1=1\u0026quot;\r拼接到sql中的字符串变量将作为一个整体'yuanya or 1=1'，从而防止sql注入*/\rResultSet rs = stmt.executeQuery();\r// STEP 5: 从resultSet中获取数据并转化成bean\rwhile (rs.next()) {\rUser user = new User();\ruser.setId(rs.getInt(\u0026quot;id\u0026quot;));\ruser.setName(rs.getString(\u0026quot;name\u0026quot;));\ruser.setAge(rs.getInt(\u0026quot;age\u0026quot;));\ruser.setDeleteFlag(rs.getString(\u0026quot;delete_flag\u0026quot;));\rusers.add(user);\r}\r// STEP 6: 关闭连接\rrs.close();\rstmt.close();\rconn.close();\r} catch (SQLException se) {\r// Handle errors for JDBC\rse.printStackTrace();\r} catch (Exception e) {\r// Handle errors for Class.forName\re.printStackTrace();\r} finally {\r// finally block used to close resources\rtry {\rif (stmt != null)\rstmt.close();\r} catch (SQLException se2) {\r// nothing we can do\r}\rtry {\rif (conn != null)\rconn.close();\r} catch (SQLException se) {\rse.printStackTrace();\r}\r}\r}\r batch操作 批量操作，只连接了一次数据库\n@Test\rpublic void batchDemo() {\rConnection conn = null;\rPreparedStatement stmt = null;\rtry {\r// STEP 2: 注册mysql的驱动\rClass.forName(DRIVER);\r// STEP 3: 获得一个连接\rconn = DriverManager.getConnection(URL, USERNAME, PASSWORD);\r// STEP 4: 启动手动提交。写操作需要用到事务，读操作不需要\rconn.setAutoCommit(false);\r// STEP 5: 创建一个更新\rString sql1 = \u0026quot;UPDATE user SET delete_flag= '1' WHERE name='yuanya'\u0026quot;;\rString sql2 = \u0026quot;UPDATE user SET delete_flag= '1' WHERE name='tianchi'\u0026quot;;\rstmt.addBatch(sql1);\rstmt.addBatch(sql2);\rSystem.out.println(stmt.toString()); //打印sql\rint[] ret = stmt.executeBatch(); //影响行数是一个int[]，对应每个sql\rSystem.out.println(\u0026quot;影响数据库行数: \u0026quot; + ret);\r// STEP 6: 手动提交数据\rconn.commit();\r// STEP 7: 关闭连接\rstmt.close();\rconn.close();\r} catch (SQLException se) {\r// Handle errors for JDBC\rtry {\rconn.rollback();\r} catch (SQLException e) {\r// TODO Auto-generated catch block\re.printStackTrace();\r}\rse.printStackTrace();\r} catch (Exception e) {\rtry {\rconn.rollback();\r} catch (SQLException e1) {\r// TODO Auto-generated catch block\re1.printStackTrace();\r}\re.printStackTrace();\r} finally {\r// finally block used to close resources\rtry {\rif (stmt != null)\rstmt.close();\r} catch (SQLException se2) {\r}// nothing we can do\rtry {\rif (conn != null)\rconn.close();\r} catch (SQLException se) {\rse.printStackTrace();\r}\r}\r}\r  shell #查看最大连接数\rshow variables like '%max_connections%'; #设置全局最大连接数\rset GLOBAL max_connections = 999;\r#列出全局变量\rshow global variable\r#列出系统会话变量\rshow session variable\r#定义变量\rdeclare 变量名1,变量名2... 类型1,类型2... [default 值]\r database  mysql初始database：information_schema、sysql、perfomance_schema  #列出\rshow databases\r#创建\rcreate database 库名\r#删除\rdrop database 库名\r#连接\ruse 库名\r table  操作表之前需要先通过 use 命令选择要操作的数据库  #列出\rshow tables\r#创建信息\rshow create table 表名\r#列信息\rshow columns from 表名\r#索引信息\rshow index from 表名\r#创建\rcreate table 表名(列名1 数据类型(长度) 约束1 约束2, 列名2 数据类型(长度) 约束1 约束2...);\rcreate table `doctor_patient_group` (\r`id` int(11) unsigned NOT NULL AUTO_INCREMENT,\r`created_at` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '创建时间',\r`updated_at` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '更新时间',\rPRIMARY KEY (`id`),\rkey `idx_created_at` (`created_at`)\r) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci COMMENT='hahah';;\r#复制表\rcreate table 表名2 as(select * from 表名1)\r#复制表结构\rcreate table 表名2 like 表名1\r#修改表名\rrename table 旧表名 to 新表名\ralter table 旧表名 rename as 新表名\r#修改表的属性\ralter table 表名 change 旧列名 新列名 数据类型(长度) 约束1 约束2\ralter table 表名 add column 列名 数据类型(长度);\ralter table 表名 drop column 列名;\r#删除\rdorp table 表名\r #查看Mysql数据库管理系统的性能及统计信息\rshow table status like [FROM db_name] [LIKE 'pattern'] \\G;\r 数据类型 MySQL常用数据类型  字符串型 ：VARCHAR(varchar(10)：可变长度的字符串\u0026quot;abc\u0026quot;)、 CHAR(char(10)：固定长度的字符串\u0026quot;abc \u0026ldquo;) 大数据类型：BLOB（存储大的二进制数据）、TEXT（存储海量的文本数据） 数值型：TINYINT 、SMALLINT、INT、BIGINT、FLOAT、DOUBLE 逻辑性 ：BIT 日期型：DATE、TIME、DATETIME、TIMESTAMP  字段约束\n 列名 数据类型 约束1 约束2 非空约束：not null 唯一约束：unique 主键约束：primary key，非空，唯一，alter table tablename drop primary key删除主键 主键自增：auto_increment 外键添加：  列名 类型(长度) [constraint fk_外键名] references 表名2(外键名) [constraint fk_外键名] foreign key(外键名) references 表名2(外键名) slter table 表名 add [constraint kf_外键名] foreign ke(外键名) reference 表名2(外键名)    crud select #查询所有*\rselect * from 表名\r#查询指定列\rselect 列名1, 列名2, 函数名3(列名3)... from 表名\r as #查询字段定义别名as，as可以省略\rselect 列名 as '别名' from 表名\r 聚合函数 #聚合函数。sum()和，avg()均值，count()个数，max()最大值，min()最小值\rselect 列名, 函数名(列名) as '别名' from 表名\r distinct #去重查询distinct。distinct对其后列名去重\rselect distinct 列名 from 表名\r limit #分页查询limit。分页查询，index从0开始\rselect * from 表名 limit index,pageSize\r where #条件查询where\rselect * from 表名 where 条件式\r  where：where 条件式  日期：WHERE date\u0026lt;\u0026lsquo;999-9-9\u0026rsquo;，日期date在999年9月9日之前 and：where num\u0026gt;=3 and num\u0026lt;=9，num在3-9之间 or：WHERE num=10 OR num=30，num为3或者为9 not：WHERE NOT(num\u0026gt;2000)，num不大于2000 between\u0026hellip;and：where sal between3 AND 9，num在3-9之间 in(值1,值2\u0026hellip;)：where num in(3,9\u0026hellip;)，num为3或9 length(列名)：where length(name)=5，名字长度为5    #模糊查询like，_代替一个字符，%代替任意长度字符，转义字符有效\rselect * from 表名 where 列名 like '_xxx%'\r group #分组查询，group by\rgroup by 列名\r#分组查询，group by ...... having\rgroup by 列名 having 条件式\r order #排序查询，order by，默认升序，asc升序，desc降序\rorder by 列名1 desc, 列名2 asc\r 顺序小结 #顺序小结：(S-F-W-G-H-O) select ... from ... where ... group by... having... order by ... ; SELECT id,count(*) AS '个数'\rFROM user\rWHRER name LIKE '_xxx%' #筛选在分组之前\rGROUP BY rank #分组在再筛选之前，因为分组得到的数据count被再筛选使用\rHAVING count(*)\u0026gt;1 #再筛选：having对分组之后的数据进行再筛选\rORDER BY count(*) DESC; #排序在最后，因为筛选完才能排序\r 关联查询 #内连接where，有无外键约束查询都有效，对删改有约束效果\rwhere：select 列名1,列名2... from 表名1,表名2 where 表名1.列名=表名2.列名 and empno=7788\r#内连接inner join\rselect 列名1,列名2... from 表名1 inner join 表名2 on 表名1.列名=表名2.列名 and empno=7788\r#左外连接left outer join。学生表(student)、必修表(required)、选修表(elective)，查询学生的id、name、选修科目数量、必修科目数量、科目总数\rselect s.student_id,s.student_name, ifnull(r.rCount,0) as rCount, ifnull(e.eCount,0) as eCount, ifnull(r.rCount,0)+ifnull(e.eCount,0)*1 as amount from student as s left join ( select student_id, count(1) as rCount from required group by student_id ) as r on s.student_id = r.student_id left join (\rselect student_id,count(1) as eCount from elective group by student_id ) e on p.student_id = e.student_id where r.rCount\u0026gt;0 or e.eCount\u0026gt;0 order by activity desc limit 0,9;\r#右外连接：lright outer join\r#全外连接：full outer join(mysql不支持)\r 嵌套查询 外层的查询块称为父查询，内层的查询块称为子查询\n关联子查询 子查询不可以单独运行，依赖于福查询中的数据\n#exists。exists(子查询)返回true或false，为true则查询符合子查询条件的父查询内容\rselect * from 表1 where exists(select * from 表名2 where 表1.外键名=外键名)\r 非关联子查询 子查询可以单独运行\n#单行单列子查询：子查询结果返回的值只有一个，\u0026lt; 小于，\u0026gt; 大于，\u0026lt;= 小于等于，\u0026gt;=大于等于，=等于，!=或\u0026lt;\u0026gt;不等于\rselect 列名1 from 表名1 where 列名\u0026lt;(select 函数名(列名) from 表名2 where 条件式; );\rselect student_id from score where count(course_i)\r#单列多行子查询：子查询结果返回的值有多个。any、all、in、not in\rselect 列名1 from 表名1 where 列名 \u0026gt; any (select 函数名(列名) from 表名2 where 条件式; );\rselect 列名1 from 表名1 where 列名 \u0026lt; all (select 函数名(列名) from 表名2 where 条件式; );\rselect 列名1 from 表名1 where 列名 in (select 函数名(列名) from 表名2 where 条件式; );\r#查询参加算计考试且不参加英语和数学考试的学生的所有信息\rselect t\rwhere id in(\rselect stu_id\rfrom scor\rwhere c_name='计算机' and stu_id not in(\rselect stu_id\rfrom score\rwhere c_name='英语' or c_name='数学'\r)\r)\r#多行多列子查询：子查询的结果是一个表\r 合并查询 #合并查询：union(去重合并)，union all(无去重合并)\rselect 列名1,列名3 from 表1 union select 列名2,列名4 from 表2\r insert  存在的判断，需要插入内容包含主键或唯一索引（字段只要被UNIQUE修饰就有唯一索引），且3种操作无论是否成功插入都会使自增的主键+1  #如果已存在则报错，如果不存在则插入\rinsert into 表名(列名1, 列名2...) values (值1,值2,...),(值1,值2,...);\r#已存在行则忽略，不存在行则插入\rinsert ignore into ...\r#已存在行则替换，不存在行则插入\rreplace into ...\r update update 表名 set 列名1=值1, 列名2=值2... where 条件式\r delete delete from 表名 where 条件式\r 视图 一个或多个表的整个或部分的映射，一般只用来查询\n#创建\rcreate view 视图名 as 查询语句\r 存储过程 无返回值，但有输出参数，call调用\n#创建函数(in，out，inout)\rcreate procedure 函数名( in 输入参数名 varchar(18), out 输出参数名 varchar(18) )\rbegin\rdeclare 变量名1 varchar(18);\rdeclare 变量名2 varchar(18);\rset 变量名1='值'; #赋值，无set为判断相等\rselect 列名1,列名2 into 变量名1,变量名2 from 表名 where 列名='值' #从表中查询然后赋值给变量\rselect 变量1; #输出\rif 条件式 then .......;\relseif 条件式 then .......;\relse 条件式 then .......;\rend if;\rcase 变量名\rwhen 值1 then ......;\rwhen 值2 then ......;\rend case;\rdeclare i int default 9\rrepeat #循环\rset num=num-1;\runtll num\u0026lt;1 end repeat;\rwhile i\u0026gt;0 do\r......;\rend while\r标签名:while(true) do\rif 条件式 then iterate 标签名; #leave相当于continue\rif 条件式 then leave 标签名; #leave相当于break\rend while\rend\rcall 函数名(); #执行\rdrop procedure 存储; #删除函数\r 函数 select 列名1，if (列名2='值1','值1时显示值','非值1显示值') 称呼 from 表名; #根据不同值输出不同显示值\rselect 列名1，case 列名2 when '值1' then '显示值1' when '值2' then '显示值2' then ' ' from 表名; #根据不同值输出不同显示值\rselect ifnull('值1','值2') ; #值1为null则返回值2，否则返回值1\rselect nullif('值1','值2'); #值1=值2返回值1，否则返回null\rselect concate('值1','值2','值3'); #拼接字符串\rconcate_ws(sep,s1,s2...,sn); #将s1,s2...,sn连接成字符串，并用sep字符间隔\rsubstring（被截取字段，从第几位开始截取，截取长度）\rTRIM(str) #去除字符串首部和尾部的所有空格\rUUID() #生成具有唯一性的字符串\rLASTINSERTID() #返回最后插入的id值\rCURDATE()或CURRENT_DATE() #返回当前的日期\rCURTIME()或CURRENT_TIME() #返回当前的时间\rDATE_ADD(date,INTERVAL int unit) #返回日期date加上间隔时间int的结果(int必须按照关键字进行格式化),如：SELECT DATE_ADD(CURRENT_DATE,INTERVAL 6 MONTH);\rDATE_FORMAT(date,fmt) #依照指定的fmt格式格式化日期date值，如：select DATE_FORMAT(CURDATE(),'%Y-%m-%d')\rDATE_SUB(date,INTERVAL int unit) #返回日期date减去间隔时间int的结果(int必须按照关键字进行格式化),如：SELECT DATE_SUB(CURRENT_DATE,INTERVAL 6 MONTH);\rNOW() #返回当前的日期和时间\r 自定义函数\nCREATE FUNCTION sp_name ([param_name type[,...]])\rRETURNS type -- 定义返回值类型\rBEGIN\rroutine_body\rEND\r#删除\rDROP function [IF EXISTS] sp_name;\r#查看\rSHOW CREATE FUNCTION sp_name;\r#使用\rSELECT db_name.sp_name;\r 触发器 #为表创建在 增/删/改 之前或之后 执行的触发器\rcreate trigger 触发器名 before/after insert/delete/update 表名 for each ROW\rBEGIN\r#触发器内容，例插入数据时检验输入性别是否正确，无效数据将性别设置为女\rif new.student_age\u0026lt;0 and new.student_age\u0026gt;150 then\rset new.student_age=old.student_age;\rend if;\rEND\rinsert into student VALUES('student013','小十三',13,'男男女女')\r 条件处理器 declare [continue/exit/undo] handler for 条件\r#条件\rmysql_error_code | SQLSTATE [VALUE] sqlstate_value\r| condition_name | SQLWARNING | NOT FOUND | SQLEXCEPTION\r 游标 -- 根据课程号查询不及格名单(用游标)\rcreate procedure pro (in couid)\rbegin\rdeclare stuid varchar(18);\rdeclare score varchar(18);\rdeclare flag int default false;\rdeclare cur cursor for select * from score where score\u0026lt;60 and course_id=couid; -- 定义游标\rdeclare continue handler for not found set flag=true; -- 定义处理器\ropen cur; -- 打开游标\rw:while true DO\rif flag then\rleave w\rend if\rfetch cur into stuid,couid,score;\rselect stuid,couid,score;\rend while w;\rclose cur; -- 关闭游标\rend\r 事务 BEGIN #显式地开启一个事务；\rSTART TRANSACTION #显式地开启一个事务；\rCOMMIT #也可以使用COMMIT WORK，不过二者是等价的。COMMIT会提交事务，并使已对数据库进行的所有修改称为永久性的；\rROLLBACK #有可以使用ROLLBACK WORK，不过二者是等价的。回滚会结束用户的事务，并撤销正在进行的所有未提交的修改；\rSAVEPOINT identifier #SAVEPOINT允许在事务中创建一个保存点，一个事务中可以有多个SAVEPOINT；\rRELEASE SAVEPOINT identifier #删除一个事务的保存点，当没有指定的保存点时，执行该语句会抛出一个异常；\rROLLBACK TO identifier #把事务回滚到标记点；\rSET TRANSACTION #用来设置事务的隔离级别\r#方式一：（用 BEGIN, ROLLBACK, COMMIT来实现）\rBEGIN #开始一个事务\rROLLBACK #事务回滚\rCOMMIT #事务确认\r#方式二：（直接用 SET 来改变 MySQL 的自劢提交模式）\rSET AUTOCOMMIT=0 #禁止自劢提交\rSET AUTOCOMMIT=1 #开吭自劢提交\r 备份 #备份\rmysqldump -u userName -p [arguments] \u0026gt; file_name.sql\r#备份服务器上所有数据库\rmysqldump -u userName -p --all-databases \u0026gt; file_name.sql\r#备份指定数据库\rmysqldump -u userName -p --databases \u0026gt; file_name.sql\r#还原\rmysql -u userName -p \u0026lt; file_name.sql\r 性能 指标 TPS  TPS：TransactionsPerSecond（每秒传输的事物处理个数），这是指服务器每秒处理的事务数，支持事务的存储引擎如InnoDB等特有的一个性能指标。只适用于InnoDB，因为MyiISAM没有事务 TPS = COM_COMMIT + COM_ROLLBACK) /UPTIME，（事务的提交次数+回滚次数）/mysql server运行时长，运行时长在mysql server重启后会刷新  use information_schema;\rselect VARIABLE_VALUE into @num_com from GLOBAL_STATUS where VARIABLE_NAME='COM_COMMIT';\rselect VARIABLE_VALUE into @num_roll from GLOBAL_STATUS where VARIABLE_NAME='COM_ROLLBACK' ;\rselect VARIABLE_VALUE into @uptime from GLOBAL_STATUS where VARIABLE_NAME='UPTIME';\rselect (@num_com+@num_ro11)/@uptime;\r 注：从mysql5.7.6开始information_schema.global_status已经开始被舍弃，为了兼容性，此时需要打开 show_compatibility_56。https://blog.csdn.net/itwxming/article/details/97897589\nQPS  QPS: Queries Per Second（每秒查询处理量）同时适用与InnoDB和MyISAM引擎 QPS=QUESTIONS/UPTIME，每秒查询数量 等待时间：执行Sql等待返回结果之间的等待时间  use information_schema;\rselect VARIABLE_VALUE into @num_queries from GLOBAL_STATUS where VARIABLE_NAME='QUESTIONS';\rselect VARIABLE_VALUE into @num_roll from GLOBAL_STATUS where VARIABLE_NAME='COM_ROLLBACK' ;\rselect VARIABLE_VALUE into @uptime from GLOBAL_STATUS where VARIABLE_NAME='UPTIME';\rselect @num_queries/@uptime;\r 压测 MySqlSlap   MySqlSlap：mysql提供的官方压测工具\n  安装：MySQLSlap是从MySQL的5.1. 4版开始就开始官方提供的压力测试工具。创建schema、table、 test data；运行负载测试，可以使用多个并发客户端连接；测试环境清理(删除创建的数据、表等，断开连接)\n  参数\n \u0026ndash;create-schema=name：指定测试的数据库名，默认是mysqlslap \u0026ndash;engine=name：创建测试表所使用的存储引擎，可指定多个 \u0026ndash;concurrency=N：模拟N个客户端并发执行。可指定多个值，以逗号或者 \u0026ndash;number-of-queries=N：总的测试查询次数(并发客户数×每客户查询次数)，比如并发 是10，总次数是100，那么10个客户端各执行10个 \u0026ndash;iterations=N：迭代执行的次数，即重复的次数（相同的测试进行N次，求一 个平均值），指的是整个步骤的重复次数，包括准备数据、测 试load、清理 \u0026ndash;commit=N：执行N条DML后提交一次 \u0026ndash;auto-generate-sql, -a：# 自动生成测试表和数据，表示用mysqlslap工具自己生成的 SQL脚本来测试并发压力。 \u0026ndash;auto-generate-sql-load-type=name：# 测试语句的类型。代表要测试的环境是读操作还是写操作还是两者混合的。# 取值包括：read (scan tables), write (insert into tables), key (read primary keys), update (update primary keys), or mixed (half inserts, half scanning selects). 默认值是：mixed. \u0026ndash;auto-generate-sql-add- auto-increment：对生成的表自动添加auto_increment列 \u0026ndash;number-char-cols=name 自动生成的测试表中包含N个字符类型的列，默认1 \u0026ndash;number-int-cols=name：自动生成的测试表中包含N个数字类型的列，默认1 \u0026ndash;debug-info：打印内存和CPU的信息    案例：直接到bin目录中执行即可\n  1000个客户端，重复10次，自动生成SQL语句，总共1000个查询：\n./mysqlslap -uroot -proot \u0026ndash;concurrency=1000 \u0026ndash;iterations 10 -a \u0026ndash;auto-generate-sql-add-autoincrement \u0026ndash;engine=innodb \u0026ndash;number-of-queries=1000\n  1, 50，100， 200个客户端， 每一个测试3次， 并打印内存，CPU信息 ./mysqlslap -uroot -proot \u0026ndash;concurrency=1,50,100,200 \u0026ndash;iterations=3 \u0026ndash;number-char-cols=5 \u0026ndash;number-int-cols=5 \u0026ndash;auto-generate-sql \u0026ndash;auto-generate-sql-add- autoincrement \u0026ndash;engine=myisam,innodb \u0026ndash;create -schema=\u0026lsquo;enjoytest1\u0026rsquo; \u0026ndash;debug-info\n  500个客户端，分别使用myisam,innodb两种存储引擎，比较效率：\n./mysqlslap -uroot -proot \u0026ndash;concurrency=500 \u0026ndash;iterations=3 \u0026ndash;number-char-cols=5 \u0026ndash;number-int-cols=5 \u0026ndash;auto-generate-sql \u0026ndash;auto-generate-sql-add-autoincrement \u0026ndash;engine=myisam,innodb \u0026ndash;create-schema=\u0026lsquo;enjoytest1\u0026rsquo; \u0026ndash;debug-info\n    逻辑架构 这里是部分架构\n连接层  当MySQL启动（MySQL服务器就是一个进程），等待客户端连接 每一个客户端连接请求，服务器都会新建一个线程处理（如果是线程池的话，则是分配一个空的线程），每个线程独立，拥有各自的内存处理空间，如果这个请求只是查询，没关系，但是若是修改数据，显然，当两个线程修改同一块内存是会引发数据同步问题的 连接到服务器，服务器寻需要对其进行验证，也就是IP、账户、密码验证，一旦连接成功，还要验证是否具有执行某个特定查询的权限（例如，是否允许客户端对某个数据库某个表的某个操作）  SQL处理层   主要功能有：SQL语句的解析、优化；缓存的查询；MySQL内置函数的实现；跨存储引擎功能（所谓跨存储引擎就是说每个引擎都需提供的功能（引擎需对外提供接口），例如:存储过程、触发器、视图等。\n  如果是查询语句(select语句)，首先会查询缓存是否已有相应结果，有则返回结果，无则进行下一步（如果不是查询语句，同样调到下一步）\n  解析查询，创建一个内部数据结构（解析树），这个解析树主要用来SQL语句的语义与语法解析;\n  优化：优化SQL语句，例如重写查询，决定表的读取顺序，以及选择需要的索引等。这一阶段用户是可以查询的，查询服务器优化器是如何进行优化的，便于用户重构查询和修改相关配置，达到最优化。这一阶段还涉及到存储引擎，优化器会询问存储引擎，比如某个操作的开销信息、是否对特定索引有查询优化等。\n  缓存：如果缓存中有就执行缓存中的计划（如果开启了数据缓存则直接返回结果）\n 缓存sql（及其执行计划），默认开启 缓存数据，默认不开启。  数据缓存是否开启的参数：show variables like \u0026lsquo;%query_cache_type%'。一般不开启，而是用redis等专业的缓存 数据缓存大小：show variables like \u0026lsquo;%query_cache_size%'，修改大小SET GLOBAL query_cache_size=11111111;或者在mysql的配置文件my.ini中修改      查询解析器：解析成mysql识别的东西，见图7\n FROM：笛卡尔积 ON：主表保留 JOIN：不符合ON也添加。WHERE：非聚合；非SELECT别名 GROUP BY：改变对表引用 HAVING：只作用分组后 SELECT：DISTINCT ORDER BY：可使用SELECT别名 LIMIT：rows；offset    查询优化器：explan查看优化结果，即执行计划。例如执行下面两个sql可以发现它们执行计划是完全一样的，where 1=1被查询优化器优化排除了\nexplain select * from user where 1=1\rexplain select * from user\r   存储引擎 #看mysql提供的存储引擎\rshow engines;\r#看mysql当前默认存储引擎\rshow variables like '%storage_engine%';  MyISAM   MyISAM是mysql5.5之前默认的存储引擎，MyISAM存储引擎由frm（存储表结构，任何存储引擎都有）、MYD（数据文件）、MYI（索引文件）文件组成，数据与索引分开存储即非聚集索引\n  特性:\n 并发性与锁级别-表级锁 支持全文检索 支持数据压缩：bin/myisampack.exe，命令myisampack -b -f user.MYI。压缩后旧文件会变成.OLD文件，如果删除.OLD文件，查询可以正常查询，但是增删改可能会出问题。  查看是否有问题：CHECK table product info; 恢复：REPAIR table product info;      适用场景:\n 非事务型应用(数据仓库，报表，日志数据) 只读类应用，查询快 空间类应用(空间函数，坐标)，详见文档mysl5空间扩展    InnoDB MySq| 5.5以及以后版本默认存储引擎。\n  innodb_ file_ per_ table：\n  ON:独立的表空间: tablename.ibd，\n  OFF:系统表空间: ibdataX\n  mysql5.6以前默认为系统表空间\n  系统表空间：无法简单的收缩文件大小，系统表空间会产生I0瓶颈（所有innodb表共用一个数据文件）。只有对应schame文件夹下只有一个frm文件，索引和数据将存放在data/目录下的idata文件中，是一个系统级的数据文件\n  独立表空间：可以通过sql语句 optimize table user 收缩系统文件，独立表空间可以同时向多个文件刷新数据。会在对应schame文件夹下生成frm和idb（索引+数据，聚合索引）两个文件\n删除大量数据，再执行OPTIMIZE TABLE user可以发现idb文件大小变小了很多，类似于磁盘整理，这就是收缩系统文件\nDELETE user WHERE id!=1\rOPTIMIZE TABLE user\r   建议: Innodb使用独立表空间\n    Innodb是一种事务性存储引擎，完全支持事务得ACID特性，Redo Log和Undo Log，Innodb支持行级锁(并发程度更高)，适用场景：Innodb适合于大多数OLTP应用\n  对比\n   对比项 MyISAM InnoDB     主外键 不支持 支持   事务 不支持 支持   行表锁 表锁，即使操作一条记录 也会锁住整个表\n不适合高并发的操作 行锁,操作时只锁某一行， 不对其它行有影响\n适合高并发的操作   缓存 只缓存索引，不缓存真实 数据 不仅缓存索引还要缓存真 实数据，对内存要求较高，而且内存大小对性能有决定性的影响   表空间 小 大   关注点 性能 事务   默认安装 Y Y      CSV  组成  数据以文本方式存储在文件  .csv文件存储内容 .csm文件存储表得元数据如表状态和数据量 .frm表结构     特点  以csv格式进行数据存储 所有列都不能为null 不支持索引(不适合大表，不适合在线处理) 可以对数据文件直接编辑(保存文本文件内容，每一行要以回车\\n结尾)：需要flush tables; 刷新表    Archive  组成  以zlib对表数据进行压缩，磁盘I/O更少  .ARZ 数据存储在ARZ为后缀的文件中 .frm表结构     特点:  只支持insert和select操作 只允许在自增ID列上加索引   使用场景  日志和数据采集应用：当然如果用到了mongodb就放在mongodb即可    Memory  Memory存储引擎表：在内存中，所有连接有效，重启mysql就没了  文件系统存储特点：也称HEAP存储引擎，所以数据保存在内存中 支持HASH索引和BTree索引 所有字段都是固定长度varchar(10) = char(10) 不支持Blog和Text等大字段 Memory存储引擎使用表级锁 最大大小由max_ heap_ table_ _size参 数决定   使用场景：在mysql自己中就有在使用  hash索引用于查找或者是映射表(邮编和地区的对应表) 用于保存数据分析中产生的中间表 用于缓存周期性聚合数据的结果表 memory数据易丢失，所以要求数据可再生   临时表：也是在内存中，但是这种表只在一个连接中有效  系统使用临时表：由系统自己维护的  超过限制使用Myisam临时表 未超限制使用Memory表   create temporary table tname{\u0026hellip;}，建立的临时表    Ferderated show engine查看，默认不开启，需要手动开启，在my.ini中加上ferderated=1也可以开启\nCREATE TABLE local_fed ( --local_fed要与下面remote_fed表结构一致\r`id` int(11) NOT NULL AUTO_ INCREMENT,\r`c1` varchar (10) NOT NULL DEFAULT '',\r`c2` char(10) NOT NULL DEFAULT '',\rPRIMARY KEY (`id`)\r) ENGINE=federated CONNECTION ='mysq1:/ / root:root@127.0.0.1:3306/remote/remote_fed'\r  特点  提供了访问远程MySQL服务器上表的方法 本地不存储数据，数据全部放到远程服务器上 本地需要保存表结构和远程服务器的连接信息   使用场景  偶尔的统计分析及手工查询    锁  MySQL中的锁：MySQL的锁机制比较简单，其最显著的特点是不同的存储引擎支持不同的锁机制。比如MyISAM和MEMORY存储引擎采用的是表级锁(table-level locking)；InnoDB存储引擎既支持行级锁(row-level locking)，也支持表级锁，但默认情况下是采用行级锁。  表级锁:开销小，加锁快;不会出现死锁:锁定粒度大，发生锁冲突的概率最高,并发度最低。 行级锁:开销大，加锁慢;会出现死锁:锁定粒度最小，发生锁冲突的概率最低,并发度也最高。 页面锁:开销和加锁时间界于表锁和行锁之间:会出现死锁:锁定粒度界于表锁和行锁之间，并发度一般。 仅从锁的角度来说（很难笼统地说哪种锁更好，只能就具体应用的特点来说哪种锁更合适）  表级锁更适合于以查询为主，只有少量按索引条件更新数据的应用，如OLAP系统 行级锁则更适合于有大量按索引条件并发更新少量不同数据，同时又有并发查询的应用，如一些在线事务处理(OLTP) 系统。      MyISAM MyISAM只支持表锁，MySQL的表级锁有两种模式、\n  表锁\n  表共享读锁(Table Read Lock)：一个session对一个table的读操作会导致 表共享读锁（手动上锁：lock table 表名 read），。表读锁，即对表的读操作导致的锁，因为该读锁是存在读共享的，所以被称为共享\n  其它session操作被锁table：读无阻塞共享，写会等待阻塞\n  上锁session操作被锁table：读无阻塞，写err\n  上锁session操作其它table：上锁session被锁在表中，对其它表执行任何读写操作都将err（注意：被锁表取别名也将被识别为其它表）\nlock table user Read; --上表共享读锁\rupdate user set id=2 where id=1; --报错\rupdate user_info set id=2 where id=1; --对另一张表执行写操作也报错，是session写 被关在表中了\rselect * user; --成功，读无阻塞共享\rselect u.* user fom user u; --如果是别名也会报错，a会被识别为非user表\rlock table user as u Read; --如果非要用别名，那也必须要用同名别名来上锁\r user被读锁锁住期间，在另一个session中执行写操作，不会报错但是会等待，直到user释放锁则成功，否则阻塞时间过长将超时\n--另一个session\rupdate user set id=2 where id=1; --等待\r     表独占写锁(Table Write Lock)：一个session对一个table的写操作会导致 表独占写锁（手动上锁：lock table 表名 write）。写锁，即对表的写操作导致的锁，因为读写都是独占的，所以被称为独占\n 其它session操作被锁table：被独占，读写均等待阻塞 上锁session操作被锁table：独占，读写均可成功 上锁session操作其它table：上锁session被锁在表中，对其它表执行任何读写操作都将err（注意：被锁表取别名也将被识别为其它表）      InnoDB MySQL的InnoDB引擎支持行锁和表锁\n  行锁：不一定是一行，可能是多行。如页锁 where id\u0026gt;3 and id\u0026lt;9；如间隙锁 where id=3 or id=9。提交或回滚事务可以释放锁。\n数据库使用锁是为了支持更好的并发，提供数据的完整性和一致性。InnoDB是一个支持行锁的存储引擎，锁的类型有：共享锁（S）、排他锁（X）、意向共享（IS）、意向排他（IX）。为了提供更好的并发，InnoDB提供了非锁定读：不需要等待访问行上的锁释放，读取行的一个快照。该方法是通过InnoDB的一个特性：MVCC来实现的。\n  锁类型\n  共享锁（读锁）：共享锁又称读锁。一个事务对某些行上读锁\n 其它事务操作被锁行：读无阻塞共享，写会等待阻塞，不允许给这些行上排它锁，但允许上共享锁  --关闭自动提交\rbegin --开启事务\rselect * from user where id=1 lock in share mode; --上共享锁\rcommit; --提交或回滚事务可以释放锁\r   排它锁（写锁）：排它锁又称写锁。一个事务对某些行上写锁\n 其它事务操作被锁行：读无阻塞共享，写会等待阻塞。不允许上任何锁  select from user where id=1 for update; --上排它锁\r     行锁锁算法：https://www.oschina.net/question/4154815_2315824，https://www.cnblogs.com/zhoujinyi/p/3435982.html\n Record Lock：单个行记录上的锁。 Gap Lock：间隙锁，在索引记录之间的间隙上的锁。GAP锁的目的，是为了防止同一事务的两次当前读，出现幻读的情况。 Next-Key Lock（临键锁）：1+2，锁定一个范围，并且锁定记录本身。对于行的查询，都是采用该方法，主要目的是解决幻读的问题。      表锁：与MyISAM区别不大。\nlock table user write; --表独占写锁\runlock tables; --释放所有表锁\rbegin; --在同该session中开启一个新事务也会释放表锁\r   注意：\n 两个事务不能锁同一个索引。 insert、delete、update操作在事务中都会自动默认加上排它锁。 行锁必须有索引才能实现，否则会自动锁全表，那么就不是行锁了。但是，为了效率考量，MySQL做了优化，对于不满足条件的记录，会在判断后放锁，最终持有的，是满足条件的记录上的锁    面试题：系统运行一段时间，数据量已经很大，这时候系统升级，有张表A需要增加个字段，并发量白天晚上都很大，请问怎么修改表结构。面试考点：修改表结构会导致表锁,数据量大修改数据很长，导致大量用户阻塞，无法访问!\n 首先创建一个和你要执行的alter操作的表一样的空的表结构 执行我们赋予的表结构的修改，然后copy原表中的数据到新表里面。 在原表上创建一个触发器，在数据copy的过程中，将原表的更新数据的操作全部更新到新的表中来。 copy完成之后，用rename table新表代替原表，默认删除原表。    物理结构修改-pt-online-schema-change，一个表结构修改工具\n 下载安装 perl 环境：http://www.perl.org/get.html 下载 percona-toolkit 工具集合：https://www.percona.com/doc/percona-tookit ppm install DBI：依赖 ppm install DBD::mysql：安装mysq|驱动依赖 修改表结构（其实就是完成了上面面试题答案的步骤）：pt-online-schema-change h=127.0.0.1,u=root,D=database_name,t=table_name \u0026ndash;alter \u0026ldquo;modify colunm_name varchar(150) not null default ' ' \u0026quot; -execute    事务 现在的很多软件都是多用户，多程序，多线程的，对同一个表可能同时有很多人在用，为保持 数据的一致性，所以提出了事务的概念。 A给B要划钱，A的账户-1000元，B 的账户就要+1000元，这两个update语句必须作为一一个整体 来执行，不然A扣钱了，B没有加钱这种情况很难处理。\nshow engines，mysql中只有只有innodb存在事务\n1.查看数据库下面是否支持事务( InnoDB支持) ? show engines; 2.查看mysql当前默认的存储引擎? show variables like \u0026lsquo;%storage_ _engine%'; 3.查看某张表的存储引擎? show create table表名; 4.对于表的存储结构的修改? 建立InnoDB表: Create table \u0026hellip; type=InnoDB; Alter table table_ name type=InnoDB;\n事务的特性 事务应该具有4个属性:原子性、- -致性、隔离性、持久性。这四个属性通常称为ACID特性。 ◆原子性(atomicity) 。-一个事务是一个不可分割的工作单位(最小单元)，事务中包括的诸操作要么都做，要么都不做。一个人转给另一个人100块，A-100和B+100是一个一个整体必须都发生 ◆一致性(consistency)。事务必须是使数据库从一个\u0026ndash;致性状态变到另一个\u0026ndash;致性状态。一致性与原子性是密切相关的。A-100，B必须只能+100，不能出现如B+100后系统卡顿，没有得到响应，又让B+100。说简单一点就是要与事务所期望的数据结果完全一致 ◆隔离性(isolation) 。一个事务的执行不能被其他事务干扰。即一个事务内部的操作及使用的数据对并发的其他事务是隔离的，并发执行的各个事务之间不能互相干扰。 ◆持久性(durability) 。持久性也称永久性( permanence)，指一个事务- -旦提交，它对数据库中数据的改变就应该是永久性的。接下来的其他操作或故障不应该对其有任何影响。持久性不能完全通过数据库本身解决，需要做如主从、容灾等（几地几中心）\n  事务并发问题\n 脏读：一个事务读取到了其它事务修改前的数据。问题源于其它事务对数据的并发修改 不可重复读：一次事务中重复读取同一数据，多次读取之间数据不一致，违背了事务一致性状态，因此不可重复读。问题源于其它事务对数据的并发修改。行锁可以解决问题 幻读：一个事务中年重复读取一些数据，非第一次读取时读到了之前没有返回的记录，如幻影一般。问题源于其它事务对数据的并发增删。几个解决思路如下  next key lock：等于record Lock + gap Lock，锁定记录本身并锁定一个范围，可以完美控制当前读的幻读问题 表锁：简单粗暴 MVCC：https://blog.csdn.net/w2064004678/article/details/83012387。Multi-Version Concurrency Control，多版本并发控制，类似于乐观锁的一种实现方式。通过保存数据在某个时间点的快照，以快照读的方式读取数据，快照读从根本上就不存在幻读问题，但并不能阻止其它事务对表进行写操作，等于自欺欺人      事务隔离级别（重点）：事务隔离级别越高，越能保证数据的完整性和一致性，但是对并发性能的影响也越大，对于多数应用程序，可以优先考虑把数据库系统的隔离级别设为ReadCommitted,它能够避免脏读取，而且具有较好的并发性能。\nshow variables like '%tx_isolation%'; --查看当前事务隔离级别mysq|默认的事务隔离级别为repeatable-read\r--修改全局隔离级别可以通过配置文件\rset SESSION TRANSACTION ISOLATION LEVEL READ UNCOMMITTED; --修改当前session隔离级别\r  READ UNCOMMITED：读未提交。一个事务可以读取其它事务未提交的数据。存在问题：脏读、不可重复度、幻读  读未提交：如事务B修改了一行数据，还未提交，随之事务A成功读取到B未提交的修改过的数据，即读未提交 脏读：但是A读取到B修改过的数据之后，B回滚了数据，A读到的数据与数据库真实数据不符，该数据被称为脏数据，产生脏读   READ COMMITED：读已提交。一个事务可以读取其它事务已经提交的数据。存在问题：不可重复读、幻读。  读已提交：如A事务将对同一行数据执行2次读取，但是A读了一次之后，事务B修改了该行数据并完成提交，那么事务A第二次读取到的数据是事务B已提交的新数据，即可以读取其它事务已经提交的数据 不可重复读：因为上面两次读取到的数据不一致，不满足事务的一致性状态，即不可重复读   REPEATABLE READ：可重复读。存在问题：幻读。  可重复度：如事务A将对同一行数据执行2次读取，但是A读了一次之后，事务B修改了该行数据并完成提交，事务A第二次读取到的数据仍然将与第一次的数据一致，而读取不到B提交的新数据，满足了事务的一致性状态，即可重复读； 幻读：会话A开启事务A→会话B开启事务B→事务A修改数据,并查询到2条数据(A的读取到的第二条数据是A添加的数据)→事务B添加一条数据,并查询到2条数据(B的读取到的第二条数据是B添加的数据)→事务A提交→事务B提交→会话A再次查询数据发现有3条记录，就像幻觉→会话B再次查询数据发现有3条记录，就像幻觉。A和B均产生幻读 产生锁：事务隔离级别为可重复读时  行锁\u0026amp;页锁：如果where涉及索引（包括主键索引），以索引列为条件更新数据，会存在间隙锁间、行锁、页锁的问题，从而锁住一些行 表锁：如果where条件不涉及索引，更新数据时会锁住整张表 行锁升级表锁：索引失效     SERIALIZABLE：序列化，串行化。事务序列化串行执行。不存在任何问题  锁  表锁：事务隔离级别为串行化时，读写数据都会锁住整张表        事务操作语法\n  事务自动提交关闭\nset autocommit=0 --或者修改配置文件my.ini\r   事务开启\nbegin\rbegin work\rstart transaction --推荐\r   事务回滚\nrollback --回滚整个事务\rrollback to savepoint sp_name --回滚到某个还原点\r   事务提交\nconmmit\r   事务还原点设置：还原到某个点\ninsert into user values(1,1,1) --添加第1条记录\rsavepoint sp1 --设置还原点sp1\rinsert into user values(2,2,2) --添加第2条记录\rsavepoint sp2 --设置还原点sp2\rinsert into user values(3,3,3) --添加第2条记录\rsavepoint sp3 --设置还原点sp3\rselect * from user --表中有3条记录\rrollback to savepoint sp1 --回滚到还原点sp1\rselect * from user --表中有1条记录\r     业务设计 逻辑设计 范式设计   数据库设计三大范式：除了第一大范式，其它每个范式都是建立在前一个范式基础之上的\n  第一范式（1NF）：列的原子性，最小属性不可再分化。数据表的每一列，必须是不可拆分的最小单元\n  错误示范\n user    id name-age     1 yuanya-23        正确示范\n user    id name age     1 yuanya 23          第二范式（2NF）：满足1NF的前提下。行的唯一性，非主键列完全依赖主键列，不是部分依赖关键字\n  错误示范：一个订单有多个产品\n order    id product_id time     1 1 2020-02-02   1 2 2020-02-02        正确示范\n  order\n   id time     1 2020-02-02      order_product\n   id order_id product_id     1 1 1   2 1 2          第三大范式：满足1NF的前提下。非主键列直接依赖主键列，不是间接依赖。数据库表中不包含已在其它表中已包含的非主关键字信息\n  错误示范\n order_product（这非常不利于增改，增改都要多考虑一个列，但是其实有时候为了查询方便会设计这样的冗余字段，这是一种反范式设计）    id order_id product_id product_name     2 1 1 飞机   2 1 2 大炮            例子\n 用户表：用户名 密码 手机号 姓名 注册时间 在线状态 出生日期。符合三大范式 商品表：ID 商品名称 分类名称 出版社名称 图书价格 图书表述 作者。不符合，一个图书通常有多种分类，应该设计成多对多的形式 出版社表：出版社名称 地址 电话 联系人 银行账号。符合 出版社表：出版社名称 地址 电话 联系人 银行账号 银行支行。不符合，因为 银行账号、银行支行 之间存在关联关系 订单表：订单编号(pK) 下单用户名 下单日期 订单金额 订单商品分类 订单商品名(pk) 订单商品单价 订单商品数量 支付金额 物流单号。有多个业务主键，不符合第二范式；订单商品单价、订单数量、订单金额 存在传递依赖关系，不符合第三范式。这样计算得到的订单金额会随着商家升降价改变，这是不被允许的，所以可见完全遵循三大范式有时候并不可行    订单\n  表设计\n 订单表：订单编号、下单用户名、下单日期、支付金额、物流单号 订单商品关联表：订单编号、商品分类ID、订单商品数量 商品信息表：商品名称、出版社名称、图书价格、图书表述、作者 商品分类关联表：商品分类ID、商品名称、分类名称 商品分类信息表：分类名称、分类描述 供应商信息表：出版社名称、地址、电话、联系人、银行账号 用户表：用户名、密码、手机号、姓名、注册时间、在线状态、出生日期    sql\n  编写SQL查询出每一个用户的订单总金额\nSELECT a.单用户名, sum(d.商品价格 * b.商品数量)\rFROM 订单表 a\rJOIN 订单分类关联表 b ON a.订单编号 = b.订单编号\rJOIN 商品分类关联表 c ON c.商品分类ID = b.商品分类ID\rJOIN 商品信息表 d ON d.商品名称 = c.商品名称\rGROUP BY a.下单用户名\r   编写SQL查询出下单用户和订单详情\nSELECT a.订单编号, e.用户名, e.手机号, d.商品名称, c.商品数量, d.商品价格\rFROM 订单表 a\rJOIN 订单分类关联表 b ON a.订单编号 = b.订单编号\rJOIN 商品分类关联表 c ON c.商品分类ID = b.商品分类ID\rJOIN 商品信息表 d ON d.商品名称 = c.商品名称\rJOIN 用户信息表 e ON e.用户名 = a.下单用户\r     问题：完全符合范式化的设计有时并不能得到良好得SQL查询性能，大量的表关联非常影响查询的性能\n    优点：\n 可以尽量得减少数据冗余 范式化的更新操作比反范式化更快 范式化的表通常比反范式化的表更小    缺点：\n  对于查询需要对多个表进行关联\n  更难进行索引优化\n    反范式设计   反范式设计：所谓得反范式化就是为了性能和读取效率得考虑而适当得对数据库设计范式得要求进行违反。允许存在少量得冗余，换句话来说反范式化就是使用空间来换取时间。主要是将一些经常多表关联查询的字段在被查表中做冗余\n  表设计：\n  商品\n ID 商品名称 分类名称 出版社名称 图书价格 图书表述 作者 分类信息：商品名称、分类名称    订单\n 订单表：订单编号 下单用户名 下单日期 支付金额 物流单号 订单商品关联表：订单编号 订单商品数量 订单商品名 订单商品分类 订单单价    sql\n  编写SQL查询出每一个用户的订单总金额\nSELECT 下单用户名, sum(订单金额)\rFROM 订单表\rGROUP BY 下单用户名;\r   编写SQL查询出下单用户和订单详情\nSELECT a.订单编号, a.用户名, a.手机号, b.商品名称, b.商品单价, b.商品数量\rFROM 订单表 a\rJOIN 订单商品关联表 b ON a.订单编号 = b.订单编号\r       优点：\n 可以减少表的关联 可以更好的进行索引优化    缺点\n 存在数据冗余及数据维护异常 对数据的修改需要更多的成本    物理设计  物理设计  定义数据库、表及字段的命名规范 选择合适的存储引擎 为表中的字段选择合适的数据类型 建立数据库结构    命名规范   数据库、表、字段的命名要遵守可读性原则 使用大小写来格式化的库对象名字以获得良好的可读性 例如：使用custAddress而不是custaddress来提高可读性。\n  数据库、表、字段的命名要遵守表意性原则 对象的名字应该能够描述它所表示的对象 例如： 对于表，表的名称应该能够体现表中存储的数据内容；对于存储过程 存储过程应该能够体现存储过程的功能。\n  数据库、表、字段的命名要遵守长名原则 尽可能少使用或者不使用缩写\n  存储引擎选择    对比项 MyISAM InnoDB     主外键 不支持 支持   事务 不支持 支持   行表锁 表锁，即使操作一条记录也会锁住整个表不适合高并发的操作 行锁,操作时只锁某一行，不对其它行有影响适合高并发的操作   缓存 只缓存索引，不缓存真实数据 不仅缓存索引还要缓存真实数据，对内存要求较高，而且内存大小对性能有决定性的影响   表空间 小 大   关注点 性能 事务   默认安装 Y Y    数据类型选择   当一个列可以选择多种数据类型时\n 优先考虑数字类型 其次是日期、时间类型 最后是字符类型 对于相同级别的数据类型，应该优先选择占用空间小的数据类型    浮点类型\n   列类型 存储空间 是否精确类型     FlOAT 4个字节 否，存在精度丢失   DOUBLE 8个字节 否，存在精度丢失   DECIMAL 每4个字节存9个数字，小数点占1个字节 是，如财务数据优先考虑      时间类型\n   类型 大小（字节） 范围 格式 用途 时区     DATETIME 8 1000-01-01 00:00:00 ~ 9999-12-31 23:59:59 YYYY-MM-DD HH:MM:SS 混合日期和时间值 时区无关，修改时区无改变   TIMESTAMP 4 1970-01-01 00:00:01 UTC ~ 2038-01-19 03:14:07 UTC YYYY-MM-DD HH:MM:SS 混合日期和时间值，时间戳 时区有关，修改时区会改变   DATE 3 1000-01-01 ~ 9999-12-31 YYYY-MM-DD     TIME 3 -838:59:59 ~ 838:59:59 HH:MM:SS     YEAR 1 1901 ~ 2155 YYYY-        慢查询 慢查询定义及作用 慢查询日志，顾名思义，就是查询慢的日志，是指mysql记录所有执行超过long_query_time参数设定的时间阈值的SQL语句的日志。该日志能为SQL语句的优化带来很好的帮助。默认情况下，慢查询日志是关闭的，要使用慢查询日志功能，首先要开启慢查询日志功能。\n配置 set global slow_query_log=1 --单位秒,超过1秒的操作将被记录日志\rshow variable like '%slow_query_log%'\r   常用配置\n slow_query_log 启动停止技术慢查询日志 slow_query_log_file 指定慢查询日志得存储路径及文件（默认和数据文件放一起，mysql/data目录下） long_query_time 指定记录慢查询日志SQL执行时间得伐值（单位：秒，默认10秒） log_queries_not_using_indexes 是否记录未使用索引的SQL log_output 日志存放的地方【FILE,TABLE】，不要用table，用file即可    记录符合条件得SQL\n 查询语句 数据修改语句 已经回滚得SQL    解读\n# User@Host: root [root] @ localhost [127.0.0.1] Id: 10 --用户名 、用户的IP信息、线程ID号\r# Query_time: 0.001042 --执行花费的时间【单位：毫秒】\r#Lock_time: 0 .000000 --执行获得锁的时间\r#Rows_sent: 2 --获得的结果行数\r#Rows_examined: 2 --扫描的数据行数\rSET timestamp=1535462721; --这SQL执行的具体时间\rSELECT * FROM myarchive LIMIT 0，1000; --具体的SQL语句\r   分析 常用的慢查询日志分析工具\n mysqldumpslow：mysql/bin目录下的exe文件，登录到mysql服务端才能访问  汇总除查询条件外其他完全相同的SQL，并将分析结果按照参数中所指定的顺序输出。 语法  mysqldumpslow -s r -t 10 /slow-mysql.log  -s order (c,t,l,r,at,al,ar) c:总次数 t:总时间 l:锁的时间 r:总数据行 at,al,ar :t,l,r平均数 【例如：at = 总时间/总次数】   -t top 指定取前面几条作为结果输出     pt_query_digest：详细内容见扩展阅读  per1 .\\pt-query-digest \u0026ndash;explain h=127.0.0.1, u=root,p=password /slow-mysql.log。需要per1环境 汇总的信息【总的查询时间】、【总的锁定时间】、【总的获取数据量】、【扫描的数据量】、【查询大小】 结果解析  Response: 总的响应时间。 time: 该查询在本次分析中总的时间占比。 calls: 执行次数，即本次分析总共有多少条这种类型的查询语句。 R/Call: 平均每次执行的响应时间。 Item : 查询对象   还有执行计划    索引与执行计划 索引  索引是什么  MySQL官方对索引的定义为：索引（Index）是帮助MySQL高效获取数据的数据结构。可以得到索引的本质：索引是数据结构。   索引得分类  普通索引：即一个索引只包含单个列，一个表可以有多个单列索引 唯一索引：索引列的值必须唯一，但允许有空值 复合索引：即一个索引包含多个列 聚集索引：就是索引与数据块顺序对应，比如id主键。索引键值的逻辑顺序与索引所服务的表中相应行的物理顺序相同的索引，被称为聚集索引，反之为非聚集索引，索引一般使用二叉树排序索引键值的，聚集索引的索引值是直接指向数据表对应元组的，而非聚集索引的索引值仍会指向下一个索引数据块，并不直接指向元组，因为还有一层索引进行重定向，所以非聚集索引可以拥有不同的键值排序而拥有多个不同的索引。而聚集索引因为与表的元组物理顺序一一对应，所以只有一种排序，即一个数据表只有一个聚集索引。  聚簇索引(聚集索引)：并不是一种单独的索引类型，而是一种数据存储方式。具体细节取决于不同的实现，InnoDB的聚簇索引其实就是在同一个结构中保存了B-Tree索引(技术上来说是B+Tree)和数据行。 聚集索引一般是表中的主键索引，如果表中没有显示指定主键，则会选择表中的第一个不允许为NULL的唯一索引，如果还是没有的话，就采用Innodb存储引擎为每行数据内置的6字节ROWID作为聚集索引   非聚簇索引：不是聚簇索引，就是非聚簇索引  show global variables like \u0026ldquo;%datadir%\u0026quot;;     基础语法  查看索引：SHOW INDEX FROM table_name\\G 创建修改索引：创建过多索引，会占用更多空间，并且虽然查询很快，但是增删改的效率都会收到影响，因为维护数据的同时还要维护索引。一般来说一个表索引不能超过5个  CREATE [UNIQUE ] INDEX indexName ON mytable(columnname(length)); ALTER TABLE 表名 ADD [UNIQUE ] INDEX [indexName] ON (columnname(length))   删除索引：DROP INDEX [indexName] ON mytable;   什么情况建索引：  某一列相对来说较唯一 经常用来查询显示的列 经常用来关联的列，where条件中用到的列，以及join on用到的列   问题  MySQL中myisam与innodb的区别? redo和undo干什么用的? hash索弓|是什么，什么存储弓|擎支持?有什么优缺点? btree和b + tree有什么样的区别，对于范围检索来说，b+ tree好在哪里? 全文索引是怎么回事? MySQL中InnoDB支持的四种事务隔离级别是什么?有什么区别 MYSQL中的间隙锁是怎么回事，有几种方式产生间隙锁? 能谈谈mysq|实现读写分离的原理吗，和存储弓|擎有什么关系?    执行计划   什么是执行计划\n 执行计划是什么 使用EXPLAIN关键字可以模拟优化器执行SQL查询语句，从而知道MySQL是如何处理你的SQL语句的。分析你的查询语句或是表结构的性能瓶颈    语法 Explain + SQL语句\n  执行计划的作用\n 表的读取顺序 数据读取操作的操作类型 哪些索引可以使用 哪些索引被实际使用 表之间的引用 每张表有多少行被优化器查询    执行计划详解\n  id：select查询的序列号,包含一组数字，表示查询中执行select子句或操作表的顺序\n id相同，执行顺序由上至下 id不同，如果是子查询，id的序号会递增，id值越大优先级越高，越先被执行 id相同不同，同时存在    select_type：查询的类型，主要是用于区别 普通查询、联合查询、子查询 等的复杂查询\n  SIMPLE：简单的 select 查询，查询中不包含子查询或者UNION\nexplain select * from t1\r   PRIMARY：查询中若包含任何复杂的子部分，最外层查询则被标记为PRIMARY\nexplain select t1.*, (select t2.id from t2 where t2.id = 1 ) from t1\r   SUBQUERY：在SELECT或WHERE列表中包含了的子查询被标记为SUBQUERY\nexplain select t1.*, (select t2.id from t2 where t2.id = 1 ) from t1\r   DERIUED：在FROM列表中包含的子查询被标记为DERIVED(衍生)，MySQL会递归执行这些子查询, 把结果放在临时表里。\nexplain select t1.* from t1 , (select t2.* from t2 where t2.id =1 ) s2 where t1.id = s2.id --s2是衍生\r   UNION：若第二个SELECT出现在UNION之后，则被标记为UNION； 若UNION包含在FROM子句的子查询中,外层SELECT将被标记为：DERIVED\nexplain select * from t1 UNION select * from t2\r   UNI0N RESULT：从UNION表获取结果的SELECT\nexplain select * from t1 UNION select * from t2\r     table：显示这一行的数据是关于哪张表的\n  type：type显示的是访问类型，是较为重要的一个指标，结果值从最好到最坏依次是\n  system \u0026gt; const \u0026gt; eq_ref \u0026gt; ref \u0026gt; fulltext \u0026gt; ref_or_null \u0026gt; index_merge \u0026gt; unique_subquery \u0026gt; index_subquery \u0026gt; range \u0026gt; index \u0026gt; ALL\n  重点：system\u0026gt;const\u0026gt;eq_ref\u0026gt;ref\u0026gt;range\u0026gt;index\u0026gt;ALL\n  system：表只有一行记录（等于系统表），这是const类型的特列，平时不会出现，这个也可以忽略不计\n  const：表示通过索引一次就找到了。const用于比较primary key或者unique索引。因为只匹配一行数据，所以很快。如将主键置于where列表中，MySQL就能将该查询转换为一个常量\n  eq_ref：唯一性索引扫描，对于每个索引键，表中只有一条记录与之匹配。常见于主键或唯一索引扫描\nEXPLAIN SELECT * from t1, t2 where t1.id=t2.id --通过id进行关联，id是索引且唯一，找id时出现eq_ref\r   ref：优化最多基本就到这里。非唯一性索引扫描，返回匹配某个单独值的所有行。本质上也是一种索引访问，它返回所有匹配某个单独值的行，然而，它可能会找到多个符合条件的行，所以他应该属于查找和扫描的混合体\n  range：最少优化到这里。只检索给定范围的行,使用一个索引来选择行。key 列显示使用了哪个索引 一般就是在你的where语句中出现了between、\u0026lt;、\u0026gt;、in等的查询。这种范围扫描索引扫描比全表扫描要好，因为它只需要开始于索引的某一点，而结束语另一点，不用扫描全部索引。\n  index：当查询的结果全部是索引列时，也是全表扫描，会扫面整个索引文件，但不扫描非索引数据\n  ALL：Full Table Scan，将遍历全表以找到匹配的行。即全表扫描\n    possible_keys：可能用到的索引\n  key：实际使用的索引。如果为NULL，则没有使用索引\n 查询中若使用了覆盖索引，则该索引和查询的select字段重叠  --除了id，有2个联合索引index_col1_col2、index_col1_col2_col3\rEXPLAIN select col1, col2 from t1 --possible_keys为null，key为index_col1_col2\rEXPLAIN select col1, col2 from t1 where col1=1 --possible_keys为index_col1_col2、index_col1_col2_col3，key为index_col1_col2。可见possible_keys会将包含有col1的所有索引列入\r   key_len\n  表示索引中使用的字节数，可通过该列计算查询中使用的索引的长度。在不损失精确性的情况下，长度越短越好\n  key_len显示的值为索引字段的最大可能长度，并非实际使用长度，即key_len是根据表定义计算而得，不是通过表内检索出的。如varchar(255)，即使只是用了1个字符，key_len也是255\n  key_len表示索引使用的字节数，根据这个值，就可以判断索引使用情况，特别是在组合索引的时候，判断所有的索引字段是否都被查询用到。\n  char和varchar跟字符编码也有密切的联系，latin1占用1个字节，gbk占用2个字节，utf8占用3个字节。（不同字符编码占用的存储空间不同）\n  字符串类型：CHAR和VARCHAR类型类似,但它们保存和检索的方式不同。它们的最大长度和是否尾部空格被保留等方面也不同。在存储或检索过程中不进行大小写转换。这里我们只需要考虑CHAR、VARCHAR，因为不太可能用TEXT、BLOB来建立索引，大字段建索引想崩了？\n   类型 大小 用途     CHAR 0-255字节 定长字符串   VARCHAR 0-65535字节 变长字符串   TINYBLOB 0-255字节 不超过255个字符的二进制字符串   TINYTEXT 0-255字节 短文本字符串   BLOB 0-65 535字节 二进制形式的长文本数据   TEXT 0-65 535字节 长文本数据   MEDIUMBLOB 0-16 777 215字节 二进制形式的中等长度文本数据   MEDIUMTEXT 0-16 777 215字节 中等长度文本数据   LONGBLOB 0-4 294 967 295字节 二进制形式的极大文本数据   LONGTEXT 0-4 294 967 295字节 极大文本数据    explain select * from s2 where name= 'enjoy' ; --比如 utf8 下 name char(10)，其它编码计算方法一致，把3换成对应字节数即可\r  索引字段为char类型+不可为Null时：key_len=3*10=30 索引字段为char类型+允许为Null时：key_len=3*10+1=31，1个字节记录该字段可为null 索引字段为varchar类型+不可为Null时：key_len=3*10+2=32，varchar是可变长度的，2个字节记录varchar实际使用了多少字节 索引字段为varchar类型+允许为Null时：key_len=3*10+2+1=32，varchar是可变长度的，2个字节记录varchar实际使用了多少字节，1字节记录该字段可为null    数值类型：key_len=类型字节数+可为null标记等\n   类型 大小 范围(有符号) 范围(无符号) 用途     TINYINT 1字节 (-128, 127) (0,255) 小整数值   SMALLINT 2字节 (-32 768，32 767) (0，65535) 大整数值   MEDIUMINT 3字节 (-8388608,8388607) (0, 16777 215) 大整数值   INT或INTEGER 4字节 (-2147483648，2147 483 647) (0，4294 967 295) 大整数值   BIGINT 8字节 (-9 233 372036 854775 808，9223 372036 854 775 807) (0, 18446 744 073709 551 615) 极大整数值   FLOAT 4字节 (-3.402 823 466E+38 , -1.175 494 351E-38)，0, (1.175 494351 E-38，3.402 823466 351 E+38) 0，(1.175 494 351 E-38，3.402 823 466E+38) 单精度浮点数值   DOUBLE 8字节 (-1.797 693 134 8623157 E+308 , -2.225073 858507201 4 E-308), 0, (2.225 073858 507201 4 E-308 ,1.797 693 134 862 3157 E+308) 0, (2.225 073 858507 201 4 E-308 ,1.797 693 134 8623157 E+308) 双精度浮点数值      时间类型：\n   类型 大小(字节) 范围 格式 用途     DATE 3 1000-01-01~9999-12-31 YYYY-MM-DD 日期值   TIME 3 -838:59:59~838:59:59 HH:MM:SS 时间值或持续时间   YEAR 1 1901~2155 YYYY 年份值   DATETIME 5.6版本及以后为5字节，之前为8字节 1000-01-01 00:00:00~9999-12-31 23:59:59 YYYY-MM-DDHH:MM:SS 混合日期和时间值   TIMESTAMP 4 1970-01-01 00:00:00~2037年某时 YYYYMMDDHHMMSS 混合日期和时间值,时间戳      总结：NOT NULL=字段本身的字段长度，NULL=字段本身的字段长度+1(因为需要有是否为空的标记，这个标记需要占用1个字节)\n 变长字段需要额外的2个字节（VARCHAR值保存时只保存需要的字符数，另加一个字节来记录长度(如果列声明的长度超过255，则使用两个字节)，所以VARCAHR索引长度计算时候要加2），固定长度字段不需要额外的字节。 而NULL都需要1个字节的额外空间,所以索引字段最好不要为NULL，因为NULL让统计更加复杂并且需要额外的存储空间。 复合索引有最左前缀的特性，如果复合索引能全部使用上，则是复合索引字段的索引长度之和，这也可以用来判定复合索引是否部分使用，还是全部使用。      ref：显示索引的哪一列被使用了，如果可能的话，是一个常数。哪些列或常量被用于查找索引列上的值\n const：及表示常量，如where name=\u0026ldquo;yuanya\u0026rdquo; 索引名：格式为 schema_name.table_name.column_name，如yuanya.user.id    rous：根据表统计信息及索引选用情况，大致估算出找到所需的记录所需要读取的行数。同一个sql，有无索引，扫描的行数明显将不一样，有索引可以扫描行数更少，扫描行数越少即执行效率越高\n  Extra：包含不适合在其他列中显示但十分重要的额外信息\n  Using filesort：说明mysql会对数据使用一个外部的索引排序，而不是按照表内的索引顺序进行读取。 MySQL中无法利用索引完成的排序操作称为“文件排序\u0026rdquo;\nEXPLAIN select cl from tl whe re c1='ac' order by c3 --索引是c1_c2和c1_c2_c3，没有用到索引排序，将Using filesort\rEXPLAIN select cl from tl whe re c1='ac' order by c2,c3 --优化，将用到c1_c2_c3索引排序\r   Using temporary：使了用临时表保存中间结果，MySQL在对查询结果排序时使用临时表。常见于排序 order by 和分组查询 group by\nEXPLAIN SELECT coll FROM tl WHERE col1 IN ('ac', 'ab', 'aa' ) GROUP BY c2 --Using temporary\rEXPLAIN SELECT coll FROM tl WHERE col1 IN ('ac', 'ab', 'aa' ) GROUP BY c1, c2 --优化，最左前缀原则\r   USING index：是否用了覆盖索引。表示相应的select操作中使用了覆盖索引(Covering Index)，避免访问了表的数据行，效率不错！如果同时出现using where，表明索引被用来执行索引键值的查找;\n 聚集索引（主键索引）：聚集索引就是按照每张表的主键构造一颗B+树，同时叶子节点中存放的即为整张表的记录数据。聚集索引的叶子节点称为数据页，聚集索引的这个特性决定了索引组织表中的数据也是索引的一部分。 辅助索引（二级索引）：非主键索引，叶子节点=键值+书签。Innodb存储引擎的书签就是相应行数据的主键索引值。 覆盖索引（索引覆盖）  就是select的数据列只用从索引中就能够取得，不必从数据表中读取，换句话说查询列要被所使用的索引覆盖 索引是高效找到行的一个方法，当能通过检索索引就可以读取想要的数据，那就不需要再到数据表中读取行了。如果一个索引包含了（或覆盖了）满足查询语句中字段与条件的数据就叫 做覆盖索引。 是非聚集组合索引的一种形式，它包括在查询里的Select、Join和Where子句用到的所有列（即建立索引的字段正好是覆盖查询语句[select子句]与查询条件[Where子句]中所涉及的字段，也即，索引包含了查询正在查找的所有数据）。 不是所有类型的索引都可以成为覆盖索引。覆盖索引必须要存储索引的列，而哈希索引、空间索引和全文索引等都不存储索引列的值，所以MySQL只能使用B-Tree索引做覆盖索引      Using where：表明使用了where过滤\n  Using join buffer：使用了连接缓存，即使用join on连接查询，连接查询会使用join buffer\n  Impossible where：where子句的值总是false，不能用来获取任何元组\n      sql优化 假设联合索引 index_c1_c2_c3\n  尽量全值匹配：即尽量使联合索引中更多的列被使用\nEXPLAIN SELECT * FROM staffs WHERE c1 = 'July'; --根据索引第一个列找到后就在该值下全扫描了\rEXPLAIN SELECT * FROM staffs WHERE c1 = 'July' AND c2 = 25; --第一个列找到后继续folow索引第二个列\rEXPLAIN SELECT * FROM staffs WHERE c1 = 'July' AND c2 = 25 AND c3 = 'dev'; --同理继续第三个列\r   最佳左前缀法则：如果索引了多列，要遵守最左前缀法则。指的是查询从索引的最左前列开始并且不跳过索引中的列。最左前缀原则其实就是防止索引失效的原则\n--没有问题，c1 c2 c3依序索引生效，and连接的条件是无序的，谁前谁后都不影响索引\rEXPLAIN SELECT * FROM user where c1=\u0026quot;xxx\u0026quot; and c2=\u0026quot;xxx\u0026quot; where c3=\u0026quot;xxx\u0026quot;\r--c1被砍掉了，等同于失去head的链表无从循迹，失去火车头的火车跑不起来，索引失效\rEXPLAIN SELECT * FROM user where c2=\u0026quot;xxx\u0026quot; where c3=\u0026quot;xxx\u0026quot;\r--c1仍然可以索引生效，但是没有c2，c3也无从生效\rEXPLAIN SELECT * FROM user where c1=\u0026quot;xxx\u0026quot; where c3=\u0026quot;xxx\u0026quot;\r   不在索引列上做任何操作（计算、函数、(自动or手动)类型转换），会导致索引失效而转向全表扫描\n--c1仍然生效，c2做了操作，将失效，c3自然也失效\rEXPLAIN SELECT * FROM user where c1=\u0026quot;xxx\u0026quot; and left(c2,3)=23 where c3=\u0026quot;xxx\u0026quot;\r   范围条件放最后：存储引擎不能使用索引中范围条件右边的列。in查询是范围查询的一种\n--c1仍然生效，查询c2为23的过程c2是作为索引生效了的，因为b+tree的结构，在c1=\u0026quot;xxx\u0026quot;上c2是有序的，索引到23之后，开始转为扫描c2\u0026gt;23所有数据，c2开始失效，c3则完全失效\rEXPLAIN SELECT * FROM user where c1=\u0026quot;xxx\u0026quot; and c2\u0026gt;23 where c3=\u0026quot;xxx\u0026quot;\r   覆盖索引尽量用：尽量使用覆盖索引（只访问索引的查询，即索引列和查询列一致），减少select *。覆盖索引可以仅遍历索引就获得数据，过程中不需要取访问非索引数据内容\nEXPLAIN SELECT c1, c2, c3 FROM user where c2=23\r   不等于要慎用：mysql 在使用不等于(!= 或者\u0026lt;\u0026gt;)的时候无法使用索引会导致全表扫描\nEXPLAIN SELECT c1, c2, c3 FROM c1, c2, c3 where c2!=23 --但是覆盖索引可以使使用!=的语句仍使用索引\r   Null/Not Null对索引可能有影响：\nEXPLAIN SELECT * FROM user where c1 is null --如果c1的定义是可以为null，那么索引生效，如果c1的定义是not null那么，索引不生效\rEXPLAIN SELECT * FROM user where c1 is not null --索引失效\rEXPLAIN SELECT c1, c2, c3 FROM use where c1 is not null --覆盖索引可以使使用null/Not Null的语句仍索引生效\r   Like查询要当心：like以通配符开头('%abc\u0026hellip;')mysql索引失效会变成全表扫描的操作\nEXPLAIN SELECT * FROM user where c1 like \u0026quot;%asd%\u0026quot;; --失效\rEXPLAIN SELECT c1, c2 FROM user where c1 like \u0026quot;%asd%\u0026quot;; --覆盖索引可使索引生效\rEXPLAIN SELECT * FROM user where c1 like \u0026quot;asd%\u0026quot;; --生效，b+tree是有序的，从前往后的\r   字符类型加引号：字符串不加单引号索引失效\nEXPLAIN SELECT * FROM user where c1=917; --失效。覆盖索引。。。算了不说了\rEXPLAIN SELECT * FROM user where c1='917'; --生效\r   OR改UNION效率高\nEXPLAIN SELECT * FROM user where c1='x' or c1=\u0026quot;xxx\u0026quot;; --失效。覆盖索引……\rEXPLAIN SELECT * FROM user where c1='x' UNION SELECT * FROM user where c1=\u0026quot;xxx\u0026quot;; --生效。大概in查询也可以这么玩？如果in中数据很多？\r   insert语句优化   提交前关闭自动提交\n  尽量使用批量insert语句\n  可以使用MyISAM存储引擎\n  例：有一个sql文件，里面几百万insert语句，用java dbc写入，读取sql文件可以\n  读一行插入一行，效率极低\n  使用batch，关闭自动提交，每几千行执行一次这样，效率稍高，但是batch实际上还是一条一条执行的\n  将数据库改为MyISAM存储引擎，将sql拼接成如下形式，可以极大节省效率，同样几千行执行一次即可，执行完后再将数据库改回innodb，注意仅导入数据时这么做，生产环境一定还是不能MyISAM\ninsert into user(c1,c2) value(1,2)(2,3)(3,4)\r   LOAD DATA INFLIE：使用LOAD DATA INFLIE ,比一般的insert语句快几十倍不止，几百万数据也就几秒完成\nselect * into OUTFILE 'D:\\\\product.txt' from t1; --导出t1到D:\\\\product.txt\rcreate table t2 select * from t1 where 1=2; --仅拷贝表结构，如果1=1或者不加where则包含数据\rload data INFILE 'D:\\\\product.txt' into table t2; --导入D:\\\\product.txt到t2\r     最后一题\n100w数据，索引是date_str，25秒左右\nSELECT a.date_str, a.shopCode, a.add_car_pv\rFROM dp_car_copy a\rWHERE 1=1\rAND (\r(\ra.date_str \u0026gt;= '2018-07-01'\rAND a.date_str \u0026lt;= '2018-08-30'\r)\r)\rORDER BY a.date_str, a.shopCode, a.add_car_pv desc\r  索引覆盖，将3个列建为联合索引，15秒左右 查看执行计划，发现type已经是range了，但是extra中using filesort，所以删除desc，使用索引本身的顺序，1秒左右 如果确实需要desc，现在可能会想到索引反着建，但是如果下次又要正着查询呢，所以还是选择再动索引，而是在后台代码中处理即可，因为返回的是一个list，所以倒着取list不就好了。这里主要要学会变通，sql当然需要满足需求，但是不要忽视后台代码或者其它因素  limit 10000 10：他不会只扫描10000-10010，而是扫描前10010条数据，所以当数据很多时，取后面的数据效率很低，这时候就要通过其他方式解决，如假如id是自增无断缺的，那么可以where id\u0026gt;9999 and id\u0026lt;10011 limit 0,10\nmysql 事务 set autocommit=0; --关闭自动提交\rcommit; --提交事务\r 任何数据库层面的优化都抵不上应用系统的优化\n  Client：基于不同的语言不同的脚本都可以实现，甚至可以写socket直接去连接Server\n  Server：即我们通常所说的MySQL。架构见图01、02\n  SQL_Layer\n 初始化模块：Server启动时，加载默认参数，进行初始化。 连接管理模块：启动完成后server将监听请求 连接进程模块：请求进来之后分发到连接进程模块（connection pool，有任务进来了，有没有线程活跃，有则去服务这个连接，没有就创建一个新的连接。连接池不止是数据库外的Client有，Server内也有），完成数据库连接 用户模块：鉴权，校验令牌，是否有权限 命令分发器：辨别请求（请求有两种，Query、commond），如果发现查询缓存模块种有，那么就直接返回结果了，不会前往到下面的模块。没有缓存则继续往下交给命令解析器解析后分发 查询缓存模块：query cache，它类似于一个hashmap，把Sql语句和参数做一个hash作为key，value就是结果值，这就是首次查询比重复查询慢的多（查询都有时间报告，可以注意到）。所以调大cache也是优化的一种，只对查询有效 日志记录模块： 命令解析器（parser）：解析完之后，分发到不同的模块处理 以下是被分发的模块  查询优化器：被分发select这类请求。这里的select包括crud 表变更模块：被分发dml这类请求 表维护模块：ddl 复制模块：rep，主从复制等 状态模块：status   访问控制模块：上面所有被分发模块最终都到访问控制模块 表管理模块： 存储引擎接口：关键。与Storage Engines打交道 还有独立的两个模块：  核心API：内存管理、小IO、数字及字符串等，类似于jvm或是一个manager的一个功能 网络交互：网络监听、交互协议处理等      Storage Engines。很多，主要关注innodb和myisam这两个存储引擎\n 文件存储形式：每一个schama（mysql种即database）都有一个文件夹，不同的引擎创建的文件格式和数量都不一样，innodb创建的一个表是两个文件，user.frm、user.ibd(inno database dater)两个文件格式，myisam是frm、MYD、MYI格式共3个存储文件     inno db MySIAM     存储文件 .frm表定义文件\n.ibd数据文件（索引和数据文件集在一起。聚集索引，基于主键展开的b+tree） SYWWA.frm表定义文件.myd数据文件.myi索引文件（也是一个索引tree，每一个索引都有一个指向，就像一个文件系统一样，指向来快速定位数据）   锁 表锁、行锁 表锁   事务 ACID 不支持   CRDU 读、写 读多   count 扫表 专门存储的地方，每个表中有多少行是被专门存储下来的，   索引结构 B+TREE B+TREE        性能\n 影响性能的因素  人为因素：需求，是否是不是一定要这么去做  count(*)：论坛分页需要用到，数据小于100w这样的数据，count(*)还ok，但是如果是1000w上e，可能count(*)就会成为一个瓶颈。这时候就要考虑数据是：实时、准实时、可以有误差。我们知道MySIAM每个表中有多少行是被专门存储，count(*)只需要直接取出来就ok，那么我们也可以学习它专门找一个地方来存储，如果数据只需要准实时、或者可以有误差，就可以这么做   程序员因素：比如太过面向对象  有一个相册、相册里有一个相片，相片有评论数。要看到相册里前三个照片的评论总数。可能会这么做：方案1，在相片中limit出来前n，然后再遍历这n个pohoto_id去评论中count出来，这很面向对象，但进行了1+n次数据库io；方案2，limit出来前n，再通过pohoto_id的集合去评论中做一次 count(*) group by pohoto_id集合，无论n是多少都是2次io，要好一些；   cache：  server内部的查询cache：最多也就放大一点，不怎么管得到。 外部有redis、menmerycache等，如果设计的不够好，所有的请求都打到数据库层面，也会有性能问题   可扩展：过度追求，如过度设计冗余字段等  先看一个合理的扩展设计：如一个user_id给另一个user_id发了一个msg，那么就是两个id和一个msg内容 就是表结构，因为我们在msg外部界面 消息列表 只需要知道谁给谁发了消息，列表可能很多，msg内容可能是一个大字段，只是看一个简略列表就要连带到这么多大字段内容，很影响性能，那么为了点进去才需要知道msg的具体内容，msg内容就可以再拆出来一个表，之前的表就变成两个userid和一个msgid，需要看消息内容再根据id去查 过度：如订单表，首先一般是有userid的，要不要冗余一个用户姓名，可能会展示订单的时候更方便，这就属于没有必要，因为查看订单详情的时候连带查询一个用户信息并不是很耗费性能的事情   表范式 应用场景：  OLTP：On-Line Transaction Processioning 链接事务处理。一般的普通系统基本都是  特点  数据量大 每次访问数据比较少 数据离散 活跃数据占比不大   优化  活跃数据占比不大：扩大内存容量将活跃数据cache住 IO频繁 IOPS（per second）：频繁，一般单次数据量就不会很大，Not 吞吐量，不需要关注吞吐量 并发大：CPU要强劲 与客户端交互频繁：网络设备扛流量的能力不能差     OLAP：On-Line Analysis Processioning 链接分解处理。一般是数据仓库，数据分析的系统  优化  数据量大 并发不高 单次检索数据量多 数据访问集中 没有明显的活跃数据   优化  磁盘单位容量要大 单次检索数据量多：关注IO吞吐量，Not IOPS 并发少：CPU要求没那么高 计算量大时间长、并行要求高：做集群，集群同步会网络通讯要求高。这就是为什么大数据都是集群\u0026hellip;         提高性能：  索引：一种数据结构，高效定位数据。select * from table where id =1，如果没有索引，就会去数据文件轮询每一条数据，对比得到，没有索引第一个读到的不一定是1，因为物理磁盘上的数据存储不是逻辑上那么连续的，所以就需要索引。如文件系统(柱面，磁道，扇区)：我们去找文件的时候，我们的机械硬盘磁头去找到文件，是我们文件系统有记录，通过柱面、磁道、扇区定位到文件在磁盘哪个地方哪个扇区，磁头就可以直接去到文件位置读取。索引table.ibd也是类似 索引。衡量索引，主要考虑IO渐进复杂度，即IO越来越多，索引是否能还是那么高效。命名好习惯：idx_作为索引命名前缀，还有如唯一约束以uni_开头等  种类  Hash：有冲突，只能做等值查询无法做范围查询如where id\u0026gt;1 Full Text：做全文搜索 前缀索引：如一个string，截取其前面几个字符做索引 R-Tree：空间索引，如3公里以内的商店。替代方案GEOHash B+Tree：红黑树高度不可控，那么查询就非常耗时  联合索引：（id,age）作为索引，且遵循最左前缀匹配的规则，先从左边id开始寻找索引，如果where age=10 and id=1，这样是找不到索引的。联合索引还有一个值得注意的点，B+Tree下，因为id相同的索引是聚集一起的一定区域，在id相同的情况下，第二列age也是是排序的，这和mysql中B+Tree插入联合索引的设计有关，那么这个时候我们通过where id=1 order by age，得到的结果是不用经过排序直接取出来的，因为本身就是按序的。这就是索引对分组排序的效率音响的点     pros  提高检索效率 降低排序成本：排序分组主要小号的是内存和cpu资源   cons  更新索引的IO量 调整索引所致的计算量 存储空间   是否创建索引  较频繁的作为查询条件的字段应该创建索引 唯一性太差的字段不适合单独创建索引 更新非常频繁的字段不适合创建索引 不会出现在where子句中的字段不该创建索引            锁  row-level：  pros  粒度小   cons  获取、释放所做的工作更多 容易发生死锁：如果事务A、B的第一个操作同时执行，导致t1和t2的id=1同时被行锁  事务A：update table1 where id=1，t1的id=1行锁了，update table2 where id=1，要等待t2的id=1解锁 事务B：update table2 where id=1，t2的id=1行锁了，update table1 where id=1，要等待t1的id=1解锁 相互等待构成死锁     实现Innodb的锁，以下锁都是系统底层将帮我们做，以下只是现实演示，实际中不会用这些sql的  共享锁：  读锁：lock table user read;上读锁，读可以无阻塞共享，只有写需要等待阻塞，unlock tables释放所有锁 写锁：lock table user write;，只有写可以无阻塞同时进行，   排他锁 间隙锁：通过在指向数据记录的第一个索引键之前和最后一个索引键之后的空域空间上标记锁定信息来实现的。是一个范围的行锁，如update user set nick name = \u0026ldquo;Xxx\u0026rdquo; where id \u0026gt;1 and id\u0026lt;4;将锁住 1-4之间的行(假如id是递增的) 锁优化  尽可能让所有的数据检索都通过索引来完成 合理设计索引 减少基于范围的数据是检索过滤条件 尽量控制事务的大小 业务允许的情况下，尽量使用较低级别的事务隔离       table-level：  pros  实现逻辑简单 获取、释放快 避免死锁：因为直接获取不到整张表。。。没讲清楚，好像是两个表都锁了的情况下，先去另一个表的请求获取不到表直接out不会wait，它之前锁的表就解锁了，另一个事务的后一个请求就可以继续操作了   cons：粒度太大，并发不够高 实现MyISAM   页锁：一个表很大是会分为多个page，所以page是table的一部分，包含大于1个row。innodb不支持page锁      共享锁(S) 排他锁(X) 意向共享锁(IS) 意向排他锁(IX)     共享锁(S) 兼容 冲突 兼容 冲突   排他锁(X) 冲突 冲突 冲突 冲突   意向共享锁(IS) 兼容 冲突 兼容 兼容   意向排他锁(IX) 冲突 冲突 兼容 兼容    优化   原则\n 永远用小结果集驱动大结果集  join表   只取出自己需要的columns  数据量 排序占用空间：max length for sort data   仅仅使用最有效的过滤条件：key length 尽可能避免复杂的join和子查询：会锁资源    QEP：query excution plan，查询执行计划，由查询优化器选择得到的查询最佳路径\n 使用：在select语句前面加个explain就可以查看该sql的执行计划  如explain SELECT * FROM user order by user.id 如果是update user where id=5，只需要换成select语句即可，explain select * from user where id=5，因为修改也是要先找到才修改嗷 字段：  ID: Query Opt imizer所选定的执行计划中查询的序列号，一个计划的唯一标识符，一个计划可能有多行组成（比如join的查询），所以id是可重复的 select_type：查询类型，类型很多具体百度对照  DEPENDENT SUBQUERY: 子查询中内层的第一个SELECT,   table：当前行执行的表是哪个表，同一个计划多行中涉及的表可能也不同（比如join的查询），一般会有一个驱动表，驱动表即第一个要操作查询的表，这是查询优化器帮我们选出来的，也是满足小结果集驱动大结果集，如计划中涉及一个table有100个数据， 另一个table有1w的数据，那么第一个table是被选作驱动表的，在计划中也是第一行，除了第一行计划的多行并不是按顺序的 type：重中之重。对表所使用的访问方式，类型很多，具体介绍百度一下或者官网看看。依次从好到差: System、const、eq_ref、ref、fulltext、ref or null、unique_subquery , index_subquery , range、index_merge、index、ALL possible_ keys：重点。可能命中的索引有哪些 key：最终用到的是哪些索引，多个则是组合索引，满足最左前缀的点 key_len：用到的索引长度，将选key_len最短的 ref：过滤形式 rows：该计划行查询数据所读取的行数，这就是为什么要小表驱动大表，小表100行，那么计划第一行最多读取100行就能完成计划第一行筛选，如果大表1w行作为驱动，那么计划第一行最多可能要1w读取1w行才能完成第一部分筛选 filtered： Extra：用到了的资源，如where关键词、索引、排序、临时表之类的，如两表关联order by，两表需要关联并拷贝到一个临时表中进行排序        profiling\n 先set profiling=1;开启， 然后执行任意查询语句select * from user order by age， 然后再执行show profiles，可以看到一个表，是我们最近一次查询语句执行查询的过程操作查询，这些操作数据行都有id， 可以通过id来执行最后的show profile cpu,block io for query 75，75即我们要查操作行的id，可以看到该操作的每一个过程状态所持续的时间，如初始化、排序之类的    join：如A.id=B.id，A表是驱动表（是底层查询优化器自己选出来的），那么则遍历A筛选出来的这些A.id，到B中又遍历去找到对应的B.id值，即一个双层for循环，然后拼凑出结果到临时表。小结果集驱动大结果集，如果A是小表只筛选出来100条，那么只需要轮询B100次，如果A是大表筛选出来1w条，那么要轮询B1w次，虽然m*n和n*m是一样的，但是对B表的读取扫描次数是不一样的。show variables like \u0026lsquo;ioin_ %';查看\n Nested Loop Join 优化  永远用小结果集驱动大的结果集，这是查询优化器筛选的，我们只能改变强制使用某些索引，来一定程度影响筛选，筛选还是不可控的 保证被驱动表上的Join条件字段已经被索引：这样每次扫描都会更快，也会放大小结果集驱动大结果集的优化效果 Join Buffer：join_buffer_size，当join表时，一些中间结果是缓存在Join Buffer中的，如三表join，A和Bjoin得到一个结果缓存到Join Buffer形成一个中间结果表，中间表再与C表join得到结果集，Join Buffer的使用是由底层决定的，并不是多表join一定会用到，调大join_buffer_size是一种预优化，给可能用到容量缓存的时候准备。因为如果Join Buffer容量不够就会缓存到磁盘分段，产生io      order by\n 实现  有序，命中索引：因为B+tree索引是有序的结构，所以根据索引order by，执行计划的Extra中将不会出现用到排序的信息，因为有序直接拿出来就完了，不进行排序 无序，未命中索引：show variables like \u0026lsquo;%sort%\u0026rdquo; ;可以找到sort_buffer_size。下面两种方式是底层选择的，当sort_buffer_size足够承载要返回的数据，那么则选用第二种，否则第一种。这也是为什么取数据尽量只取需要的Colum，而不要用select *，当然这只是一个点  一：只把要排序的字段和指针copy到sort buffer中去排序，这一列指针指向数据表所在行，做完排序再根据指针去拿到数据表中的数据copy到结果集。共两次磁盘io 二：直接copy所有要返回的字段和指针到sort buffer，之后又做一次拆分，将要排序的字段和指针copy出来，这时候指针就是指向copy出来的那些行了，之后与第一种一样。这样除了第一次copy的一次io，之后都在内存中操作了。节省io，但是耗费内存 ，空间换时间     优化  索引顺序致的话不需要再排序：可以看到索引是最主要的，可以直接索引没有排序后面的优化都不需要了 加大max length for sort data从而使用第二种排序方法（排序只针对需要排序的字段） 内存不充足时去掉不必要的返回字段 增大sort buffer size：减少在排序过程中对需要排序的数据进行分段      group by：基于order by，先排序后分组，所以适用于order by的优化也适用于group by\n  distinct：基于group by，先排序后分组再去重，所以。。。不说了\n  limit：当offset很大时，很慢。因为limit执行取出的数据不是size条，而是offset+size条\n 自增无空缺的id可以SELECT * FROM user where id\u0026gt;10000 limnit 10;，总之就是根据业务通过其它方式筛选后再limit    slow sql\n  配置\n[mysqld]\rslow_query_log=1\rslow_query_log_file=/path/to/file\rlong_query_time=0.2\rlog_output=FILE\r   show full processlist;，然后slow sql来定位sql，最后explain查看分析\n    建索引的几大原则\n 最左前缀匹配原则，非常重要的原则, mysq|会直向右匹配直到遇到范围查询(\u0026gt;、\u0026lt;、 between、 like)就停止匹配，比如a= 1 andb= 2andc\u0026gt; 3 andd = 4如果建立(a,b,c,d)顺序的索引, d是用不到索引的，如果建立(a,b,d,c)的索引则都可以用到，a,b,d的顺序可以任意调整。 =和in可以乱序，比如a= 1 andb= 2andc= 3建立(a,b,c)索引可以任意顺序, mysql的查询优化器会帮你优化成索引可以识别的形式 尽量选择区分度高的列作为索引,区分度的公式是count(distinct co)/count(*)，表示字段不重复的比例,比例越大我们扫描的记录数越少，唯一键的区分度是1 ，而一些状态、性别字段可能在大数据面前区分度就是0 ,那可能有人会问，这个比例有什么经验值吗?使用场景不同，这个值也很难确定,一般需要join的字段我们都要求是0.1以上，即平均1条扫描10条记录 索引列不能参与计算,保持列\u0026quot;干净”, 比如from_ unixtime(create_ time) =’2014-05-29\u0026rsquo; 就不能使用到索引,原因很简单，b+树中存的都是数据表中的字段值，但进行检索时, 需要把所有元素都应用函数才能比较,显然成本太大。所以语句应该写成create_ time = unix_ timestamp(\u0026rsquo; 2014-05-29\u0026rsquo; ); 尽量的扩展索引,不要新建索引。比如表中已经有a的索引,现在要加(a,b)的索引，那么只需要修改原来的索引即可    ","date":"2020-11-11","permalink":"https://yuanyatianchi.github.io/post/db.sql.mysql/","tags":["db","mysql"],"title":"redis"}]