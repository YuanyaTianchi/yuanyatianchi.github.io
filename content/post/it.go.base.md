## channel 函数调用栈

#### 函数调用过程

https://www.bilibili.com/video/BV1hv411x7we?p=5 ，

- **虚拟地址空间**：栈、堆、（只读）数据段、代码段
- **代码段**：我们按照编程语言的语法定义的函数，会被编译器编译为一堆堆**机器指令**，写入可执行文件，程序执行时，可执行文件被加载到内存，这些机器指令对应到虚拟地址空间中，位于代码段
- 如果在一个函数A中调用另一个函数B，编译器就会对应生成一条 call 指令，程序执行到这条指令时，就会跳转到被调用函数入口处开始执行，而每个函数的最后都有一条 ret 指令。负责在函数结束后跳回到调用处，继续执行

![](./img/1.png)

- **栈**：函数执行时需要有足够的内存空间，供它存放局部变量、参数等数据，这段空间对应到虚拟地址空间的栈
- 栈只有一个口可供进出，先入栈的在底，后入栈的在顶，最后入栈的最早被取出
- 运行时栈上面是高地址，向下增长，分配给函数的栈空间被称为**函数栈帧**，栈底通常称为**栈基**（bp），栈顶又叫**栈指针**（sp）
- go语言中，函数栈帧布局是这样的，先是调用者**栈基地址**，接下来是**局部变量**，然后是**调用函数的返回值**，最后是**调用函数的参数** 
- call 指令只做两件事
  - 第一，将下一条指令的地址入栈，这就是返回地址，被调用函数执行结束后会跳回到这里；
  - 第二，跳转到被调用函数入口处执行，这后面就是被调用函数的栈帧了。

- 所有的函数栈帧布局都遵循统一的约定。所以，被调用者是通过栈指针加上偏移来定位到每个参数和返回值的

![](./img/2.png)



- 程序执行时，cpu用特定的寄存器，来存储运行时栈基与栈指针，同时也有指令指针寄存器，用于存储下一条要执行的指令地址。
- 如果接下来要执行这条指令，cpu读取后会将指令指针移向下一条指令，然后栈指针向下移动，汝栈数字3，继续下一条指令，再次移动栈之针，入栈数字4
- 不过构语言中函数栈帧不是这样逐步扩张的，而是一次性分配，也就是在分配栈帧时，直接将栈指针移动到所需最大栈空间的位置，然后通过栈指针加偏移植这种相对选址方式使用函数栈帧。例如这里，sp+16byte 处存储 3，sp+8byte 处存储4，诸如此类。

![](./img/3.png)



- 之所以一次性分配，主要是为了避免栈访问越界。就像这里三个goroutine初始分配的栈空间只有这么大。如果g2栈用到这里了，接下来要执行的函数要用这么大的空间。若函数栈是逐步扩张的，执行期间就可能发生栈访问越界，由于函数栈帧的大小可以在编译时期确定，对于栈消耗较大的函数，go语言的编译器会在函数头部插入检测代码，如果发现需要进行栈增长，就会另外分配一段足够大的栈空间，并把原来栈上的数据拷过来，原来的这段栈空间就被释放了

![](./img/4.png)

- 接下来我们看看 call 指令和 ret 指令，是怎样实现函数跳转与返回的？一个函数 a 在 a1 处调用 b1 处的函数 b，跳转前寄存器和栈的情况是这样的。
- 然后到 call 指令，这里它的作用有两点
  - 第一，把返回地址 a2 入栈保存起来
  - 第二，跳转到指令地址 b1 处，call 指令就结束了，函数b开始执行
- 先把sp向下移动24字节（sp-24）为自己分配足够大的栈帧，所以栈指针挪到s7这里。
- 接下来是b2这条指令，要把调用者栈基s1，存到 sp+16byte 的地方，也就是s5这里，接下来是b3，sp+16byte 处，即也是s5，就是函数b的栈基，把它存入bp寄存器
- 接下来，就是执行函数b剩下的指令了，在 ret 指令之前，编译器还会插入两条指令
  - 第一条指令恢复调用者a的栈基地址，它之前被存储在 sp+16byte 这里
  - 第二条，释放自己的栈帧空间，分配时向下移动多少，释放时就向上移动多少
- 然后就到 ret 指令了，他的作用也有两点
  - 第一，弹出 call 指令压栈的返回地址，即s4处
  - 第二，跳转到这个返回地址，ok，现在可以从a2这里继续执行了
- 简单来说，函数通过 call 指令实现跳转。而每个函数开始时会分配栈帧。结束前又会释放自己的栈帧， ret 指令又会把栈，恢复到 call 之前的样子

![](./img/5.png)

- 通过这些指令的配合，能够实现函数层层嵌套。如果一个函数a调用函数b，b调用c，c又调用d，就会形成这样的栈。如果每次调用的都是a。就是地规调用栈了构语言函数，栈帧布局与跳转就到这里。

![](./img/6.png)    ![](./img/7.png)

#### 参数和返回值

https://www.bilibili.com/video/BV1hv411x7we?p=6

- 继续函数调用栈，接下来我们就把有参数和返回值的情况捯一捯。
- 先来看看有参数的情况，这里有一个 swap 函数，接收两个整形参数。main函数，要通过 swap 来交换两个局部变量的值，但是失败了。我们通过函数调用栈，看看问题出在哪
- 假设 main 函数栈帧分配在这里，先分配局部变量存储空间，a等于1，b等于2，这里调用的函数没有返回值，所以局部变量后面，就是给被调用函数传入的参数，需要传入两个整形参数。传参就是值拷贝，参数是整形，所以拷贝整形变量值。注意，参数入栈顺序，由右至左，先入栈第二个参数，再入栈第一个参数，返回值也是一样。
- 这样，被调用函数通过 sp 加偏移选址时就比较方便了。调用者栈帧后面是 call 指令存入的返回地址，再下面分配的，就是 swap 函数栈帧了。
- 当 swap 数执行到这里，要交换两个参数的值，它的参数在这里，把值交换一下，现在交换失败的原因找到了，调用者的局部变量 a 和 b 在这，交换的并不是他们。

![](./img/8.png)

- 再来个例子，依然要交换两个整形变量的值，但是参数类型改为整形指针，这一次交换成功了，我们通过函数调用栈看看和上一次有什么不同。
- main 函数栈帧，先分配局部变量，然后分配参数空间，参数是指针，传参都是值拷贝。这里拷贝的就是 a 和 b 的地址，依然由右至左，先入占b的地址，再入栈a的地址。
- 再后面是返回地址，以及 swap 函数栈帧，swap 执行到这里时，交换的是这两个指针指向的数据，也就是这两个地址的数据，所以这一次能够交换成功。

![](./img/9.png)

- 接下来，看看返回值，通常我们认为返回值，是通过寄存器传递，但是 go 语言支持多返回值，所以在栈上分配返回值空间更合适，来看一个有返回值的例子。
- 这里 main 函数调用 incr 函数，然后赋给局部变量b。
- 来看看函数调用栈的情况，main 函数栈帧，先是局部变量，a等于零，b等于零，go语言函数栈帧布局中，返回值在参数之上，所以 incr 的返回值分配在这，初始化为类型零值
- 然后是参数空间，传参，值拷贝，到 incr 函数栈帧这里，保存调用者 main 的栈基地址后，初始化局部变量b，执行到这里，要把参数a自增1，而参数a在这，下一步把参数a赋给局部变量b。
- 到return这里，必须要明确一个关键问题，我们说过，函数最后，由编译器插入的指令，负责释放函数栈帧，恢复到调用者栈，但在这之前，要给返回值赋值，并执行 defer 函数，那谁先谁后？答案是**先赋值后defer**。所以执行到这里，会先把局部变量b的值拷贝到返回值空间。也就是这儿，然后再执行注册的defer函数，defer函数里，这一步，a再次自增一，下一步，局部变量b也自增1，然后 incr 结束，返回值为1，赋给 main 函数的局部变量b，所以到这里会输出0和1。这是匿名返回值的情况。

![](./img/10.png)

- 再来个例子，其他都不变，只把这里的局部变量b，改成命名返回值，看看有什么不同。
- main 函数栈帧，与上个例子完全相同，到 incr 函数栈帧这里，没有局部变量，当执行到这一步时，参数a自增1，return这里，先把参数a赋给返回值b，注意返回值在这，然后执行 defer 函数。这一步参数a再次自增1，下一步返回值b也自增1，然后 incr 结束，返回值最终为2，所以m的局部变量b赋值为2，最终输出0和2

![](./img/11.png)

- 了解了函数栈帧的布局，以及返回值被赋值的时机，就不会搞不清楚这两种情况了。

![](./img/12.png)

- 最后再来看一个小问题，如果一个函数a调用了两个函数b和c。但是，这两个函数的参数和返回值占用的空间并不相同。我们知道go语言的函数栈帧是一次性分配的，如果局部变量占这么大，这后面还要**以最大的参数加返回值空间为标准来分配，才能满足所有被调用函数的需求**。b的参数和返回值可以把这里占满，没有问题，但是b结束后调用c时，它的参数和返回值只会占用下面这段空间，虽然上面空出了一块，但是被调用者通过栈指针，相对选址自己的参数和返回值时会比较方便

![](./img/13.png)

## 闭包

go语言中，函数是头等对象，可以作为参数传递，可以做函数返回值，也可以绑定到变量，go语言程这样的参数、返回值、变量为Function Value。

函数的指令在编译期间生成，而 Function Value 本质上是一个指针，但是并不直接指向函数指令入口，而是指向一个 runtime.funcval 结构体，这个结构体里只有一个地址 fn，就是这个函数指令的入口地址

```go
type funcval stract {
    fn uintptr
}
```

下面来看一个完整的例子，函数a被赋值给f1和f1两个变量。这种情况，编译器会做出优化，让f1和f2共用一个 funcval 结构体。

编译阶段，会在**只读数据段**分配一个 funcval 结构体，fn 指向函数 a 指令的入口地址，而 funcval 本身的起始地址，会在执行阶段赋给f1和f2。

通过f1来执行函数，就会通过他存储的地址，找到对应的 funcval 结构体，拿到函数入口地址，然后跳转执行函数A，参数为一1，自增一下，输出2。f2的调用完全相同。

既然只要有函数入口地址就能调用，为什么要通过一个funcval 结构体包装这个地址，然后使用一个二级指针来调用呢？这里主要是为了处理闭包的情况

维基百科这样定义闭包，这里有两个关键点。其一必须要有在函数外部定义，但在函数内部引用的自由变量；其二，脱离了形成闭包的上下文，闭包也能照常使用这些自由变量。

```go
func A(i int) {
    i++
    fmt.Println(i)
}
func B() {
    f1:=A
    f1(1)
}
func C() {
    f2:=A
    f2(1)
}
```

就像下面这个例子，函数 create 的返回值是一个函数，但这个函数内部使用了外部定义的变量c。 

即使create执行结束，通过 f1 和 f2 依然能够正常调用这个闭包函数，并使用定义在 create 函数内部的局部变量c，所以这里符合闭包的定义。通常称这个变量c为捕获变量。

闭包函数的指令自然也在编译阶段生成，但因为每个闭包对象都要保存自己的捕获变量，所以要到执行阶段才创建对应的闭包对象。

到执行阶段，main 函数栈帧有两个局部变量，然后是返回值空间，到 create 函数栈帧这里，有一个局部变量c=2，create 函数会在堆上分配一个 funcval 结构体，fn 指向闭包函数入口。

除此之外还有一个捕获列表，这里只捕获了一个变量c，然后，这个结构体的起始地址（假设为addr2）就作为返回值，写入返回值空间，所以 f1 被赋值为 addr2。

下面再次调用 create 函数，它就会再次创建一个 funcval 结构体，同样捕获变量c，然后这个起始地址（假设为addr3）作为返回值写入，最终 f2 被赋值为 addr3

通过 f1 和 f2 调用闭包函数，就会找到各自对应的 funcval 结构体，拿到同一个函数入口，使用的也是各自的捕获列表。这就是称闭包为有状态函数的原因。

```go
func main() {
    f1 := create()
    f2 := create()
    fmt.Println(f1())
    fmt.Println(f2())
}
func create() func() int {
    c := 2
    return func() int {
        return c
    }
}
```

闭包函数是如何找到对应的捕获列表呢？go语言中通过一个 funcval 调用函数时，会把对应的 funcval 结构体地址存入特定寄存器（例如amd64平台使用的是dx寄存器）

这样，在闭包函数中，就可以通过寄存器取 funcval 结构体的地址，然后加上相应的偏移来找到每一个被捕获的变量，所以go语言中闭包就是有捕获列表的 funcval

而没有捕获列表的 funcval，直接忽略这个寄存器的值就好



最后来看看这个捕获列表，它可不是拷贝变量值这么简单，被闭包捕获的变量，要在外层函数与闭包函数中表现一致，好像它们在使用同一个变量，为此go语言的编译器针对不同情况做了不同的处理

最简单的情况就像上面这个例子，被捕获的变量，除了初始化赋值外，在任何地方都没有被修改过，所以直接拷贝值到捕获列表中就ok了，但是如果除了初始化赋值外还被修改过，那就要再做细分。



在下面这个例子中，被捕获的是局部变量i，而且除了初始化赋值外还被修改过，来看看这种情况会怎么处理。

闭包函数指令入口地址 addrf

main函数栈帧中，局部变量 fs 是一个长度为 2 的 funcval 型数组。

到 create 函数栈帧，由于被闭包捕获，局部变量 i 会改为**堆**分配，在栈上只存一个地址 &i。第一次 for 循环，在堆上创建 funcval 结构体（堆addr0）捕获 i 的地址，这样，包函数就和外层函数操作同一个变量了，返回值第一个元素存储 addr0。第一次 for 循环执行结束，i 自增 1，第二次 for 循环开始，再次堆分配一个 funcval（堆addr1），捕获变量 i 的地址，返回值第二个元素存储 addr1，第二次循环结束 i 再次自增 1。此时满足循环退出条件，create 函数结束

回到man栈帧上，把返回值拷贝到局部变量 fs

通过 fs[0] 调用函数时，把 fn 的值 addr0 存入寄存器 dx，找到其 funcval 闭包对象，闭包函数通过寄存器存储的地址+偏移，找到捕获变量 i 的地址；

通过 fs[1] 调用时，把 addr1 存入寄存器，找到其 funcval 闭包对象，闭包函数找到捕获列表

fs[0] 和 fs[1] 中被捕获的地址，都指向堆中的 i，所以 for 循环中每次都会打印 2

```go
func main() {
    fs := create()
    for i := 0; i < len(fs); i++ {
        fs[i]()
    }
}
func create() (fs [2]func()) {
    for i := 0; i < 2 ; i++ {
        fmt.Println(i)
	}
    return
}
```



闭包导致的局部变量堆分配，也是变量逃逸的一种场景。



如果修改并被捕获的是参数，涉及到函数原型，就不能像局部变量那样处理了，参数依然通过调用者栈帧传入，仍然保存参数值而不是地址，但是编译器会把栈上这个参数拷贝到堆上一份，然后外层函数和闭包函数都使用堆上分配的这一个，即捕获变量仍是地址值，指向堆中的这份参数



如果被捕获的是返回值，处理方式就又有些不同，调用者栈帧上依然会分配返回值空间，不过闭包的外层函数会在堆上也分配一个，外层函数和闭包函数都使用堆上这一个，但是在外层函数返回前，需要把堆上的返回值拷贝到栈上那个返回值空间



处理方式虽然多样，但是目标只有一个，就是保持捕获变量在外层函数与b包含数中的一致性。



## 方法

如果我们定义一个类型 A，并给他关联一个方法 Name，然后就可以通过这个类型A的变量a来调用这个方法了

下面我们来看看方法调用的情况。main 函数栈帧上，局部变量a只包含一个string类型的成员，字符串内容在数据段，地址addr1，字节数目为4，返回值空间在局部变量后面，参数空间在返回值后面，都是string类型。go语言中传参值拷贝，所以，局部变量a被拷贝到参数空间。

执行到这里方法Name中时，修改的是 main 函数栈帧上的参数，参数指向 string 的结构体，让data指向新的字符串内容，len也要修改为 8。

main 中局部变量a是值接收者，通过它调用方法是修改的是拷贝过去的参数，而不是它自己，要想修改变量a还是要用指针接收者

```go
func main() {
    a := A{name: "eggo"}
	fmt.Println(a.Name())
	fmt.Println(A.Name(a))
}
type A struct {
	name string
}
func (a A) Name() string {
    a.name = "hi! " + a.name
	return a.name
}
```

`a.Name()` 这种调用方式其实是语法糖，实际上和调用这个函数 `A.Name(a)` 是一样的

这里 `a.Name()`  中的变量a就是所谓的方法接收者，它会作为方法Name的第一个参数传入，这一点，我们可以通过代码验证一下

go语言中函数类型只和参数与返回值相关，所以 t1、t2 这两个类型值相等，就能够证明方法本质上就是普通的函数，而接收者就是隐含的第一个参数

```go
func main() {
    t1 := reflect.TypeOf(A.Name)
    t2 := reflect.TypeOf(NameOfA)
    fmt.Println(t1 == t2) // ture
}
func NameOfA(a A) string {
    a.name = "hi! " + a.name
	return a.name
}
```



我们把上面方法 Name 的接收者改为指针类型，然后用变量 pa 来调用方法 Name。同样，通过函数调用栈，看看有何不同。

main 函数栈帧上，除了变量 a，还有一个 a 的指针 pa，`pa.Name()` 会被转换为这样的函数调用 `(*A).Name(pa)`。

返回值同样为 string 类型，但是参数变成 a 的指针。传参值拷贝，参数空间拷贝的是局部变量 a 的地址

执行到 Name 方法内时，要修改 pa 所指向地址处的变量，也就是局部变量a，它的data指向新的字符串内容，len 修改为8。拷贝返回值时，拷贝的是局部变量a的成员。

这就是指针接收者调用方法的过程，同样要把接收者作为第一个参数传入，同样是参数值拷贝。但是指针接受者拷贝的是地址，因此实现了对局部变量a的修改。

```go
func main() {
    a := A{name: "eggo"}
    pa := &a
	fmt.Println(pa.Name())
}
type A struct {
	name string
}
func (pa *A) Name() string {
    pa.name = "hi! " + a.name
	return a.name
}
```

下面我们再做些修改，这里既有值接收者的方法，又有指针接收者的方法

我们已经了解了两种接受者调用方法的基本过程，但是这里通过值调用指针接受者的方法，通过指针调用直接受者的方法，也能正常运行是几个意思？

其实若没有涉及到接口的话，这些也是语法糖，编译阶段，`pa.GetName()` 会转换为这种形式 `(*pa).GetName()` ，而 `a.SetName()` 也会转换为这种形式 `(&a).SetName()`。

不过，既然这种语法糖，是在编译期间发挥作用的，像这种编译期间，不能拿到地址的字面量调用 `A{Name: "eggo"}.SetName` ，也就不能借助语法糖来转换了。因此并不能通过编译

```go
func main() {
    a := A{name: "eggo"}
    pa := &a
	fmt.Println(pa.GetName()) // 指针调用直接受者的方法
	fmt.Println(a.SetName())  // 值调用指针接受者的方法
}
type A struct {
	name string
}
func (a *A) GetName() string {
	return a.name
}
func (pa *A) SetName() string {
    pa.name = "hi! " + a.name
	return a.name
}
```

最后来看一下把一个方法赋给一个变量是怎么回事。

我们已经知道，go 语言中函数作为变量、参数和返回值时，都是以 funcval 的形式存在的。也知道闭包只是有捕获列表的 funcval 而已。

如果像这样把一个类型的方法赋给变量 f1，f1 就是一个方法表达式，这实际上等价于这段代码 `f1 := GetName; f1(a)`，所以 f1 本质上也是一个 funcval，也就是一个 funcval 结构体的指针，而 fn 指向 A.GetName 的函数指令入口。因为前面我们已经验证了这两个方法的等价性。所以通过 f1 执行方法时，需要传入 A 类型的变量 a 作为第一个参数。

而 f2 以这样的方式复制，它被称为方法变量，理论上讲，方法变量也是一个 funcval 。而且它会捕获方法接收者，形成闭包。但是这里 f2 仅作为局部变量，它与a的生命周期是一致的，所以变译器会做出优化，把它转换为类型 A 的方法调用，并传入a作为参数，即 `A.GetName(a)`。

```go
func main() {
    a := A{name: "eggo"}
    f1 := A.GetName // 方法表达式
    f1(a)
    f2 := a.GetName // 方法变量
    f2()
}
type A struct {
	name string
}
func (a A) GetName() string {
	return a.name
}
func GetName(a A) string {
	return a.name
}
```

我们可以看一个方法变量作为返回值的例子，对比一下。这里 f2 与上个例子相同，它会被编译器优化为这样的函数调用 `A.GetName(a)`，所以会输出 main 函数的局部变量 a。

而下面的 f3 被复制为 GetFunc 函数的返回值，返回的是一个方法变量，这等价于 GetFunc2 中的代码。通过它，我们可以清晰的看到闭包是如何形成的。所以这里的 f3 就是一个闭包对象，捕获了 GetFunc 函数的局部变量 a。所以这里 f3 执行时，会输出 "eggo in GetFunc"。

因此，从本质上来讲，方法表达式和方法变量都是 funcval 。

```go
func main() {
    a := A{name: "eggo in main"}
    f2 := a.GetName // 方法变量
    fmt.Println(f2())
    f3 := GetFunc
    fmt.Println(f3())
}
type A struct {
	name string
}
func (a A) GetName() string {
	return a.name
}
func GetFunc() (func() string) {
    a := A{name: "eggo in GetFunc"}
	return a.GetName
}
func GetFunc2() (func() string) {
    a := A{name: "eggo in GetFunc"}
	return func() string {
        return A.GetName(a)
    }
}
```



## defer

### 1.12

关于 defer ，我们知道它会在函数返回之前倒叙执行。像这样的一段代码编译后的为止令是这样的。defer指令对应到两部分内容，deferprock负责把要执行的函数信息保存起来，我们称之为defer注册。deferpro砍树会返回零这个分支和panic，recover有关，先忽略对应，要跳转到的，这里也先忽略。现在程序正常执行的逻辑就更清晰了。defer注册完成后，程序会继续执行后面的逻辑，直到返回之前通过deferreturn执行注册的 defer 函数。正是因为先注册后调用，才实现了 defer 延迟执行的效果。一份信息会注册到一个列表，而当前执行的勾如镜，持有这个链表的头指针。每个勾入厅在运行时都有一个对应的结构体制，其中有一个字段指向敌方练表头。 defer 链表练起来的是一个一个 defer 结构体，新注册的 defer 会添加到链表头，执行时也是从头开始。所以，蒂芬尔才会表现为倒叙执行。展开 defer 结构体之前，先看一个例子。这里函数a注册了一个def函数a一来看函数调用栈。的栈帧，首先是两个局部变量，a等于一b等于二然后就要注册 defer 函数a一了。deferpock函数原形只有两个参数，第一个是def函数a，一的参数加返回值共占用多大空间？a一没有返回值，只需要一个整形参数，64位下要占八字阶。

第二个参数是一个方格身歪流，前面我们介绍过没有不会列表的方格式歪流在编译阶段会做出优化。就是在只读数据段分配一个共用的funk，value结构体。这是指向函数a一指令入口的funk，value，所以deferpock的第二个参数就是它的地址。要用它之前，我们先把底缝结构体展开来看一下。第一个字段记录底缝函数的参数与返回值共占多少资金。这段空间会直接分配在底分结构体后面。用于在注册时保存参数，并在执行时拷贝到调用者参数与返回值空间。第二个字段标记几分？是否已经执行？sp记录的是注册这个 defer 的函数栈指针通过它函数可以判断自己注册的 defer 是否已经执行完了？而pc就是deferpock的返回地址。fn是要注册的方身value，最后的link自然是要练到前一个注册的底分结构体。剩下的和panic有关暂时先不管。deferprock函数调用时，编译器会在他自己的两个参数后面。开辟一段空间用于存放 defer 函数的返回值和参数，这一段空间会被直接拷贝到 defer 结构题的后面。a一只有一个参数放在deferpock函数自己的两个参数之后。deferpock函数执行时需要堆分配一段空间用于存放def结构体以及后面si，z大小的参数与返回值。第一个字段参数加返回值共占八字街，started等于falls，调用着栈指针指向这里，返回地址是他。

被注册的functionvalvaddr二d。four结构体后面的这八字节用来存放传给a，e的参数a等于一。然后，这个底分结构体就被添加到底分练表头，底分prok注册结束。实际上，构语言会预分配不同规格的dfer池，执行时从空闲dfer中取一个出来用。没有空闲的或者没有大小合适的再进行堆分配，用完以后再放回空闲及分持。这样可以避免频繁的堆分配与回收。回到这里，执行到这一步，局部变量a被置为三下一步输出局部变量a等于三b等于二。然后就到defer，return，执行defer列表了。从当前勾入t，拿到列表头上的这个 defer 结构体，通过fn找到方c，value，拿到函数入口地址。要用a，一时会把 defer 后面的参数与返回值整个拷贝到a一的调用者栈上。然后a一开始执行，这里输出参数值一。这里的关键是敌缝函数的参数，在注册时拷贝到堆上，执行时又拷贝到栈上。既然deferprock注册的是一个function，value，下面就来看看有补货列表时是什么情况。这个例子中，一份函数不只要传递局部变量b做参数，还捕获了外层函数的局部变量a形成b包。假如这个b包函数的指令在这直行阶段，会使用这个入口地址创建b包对象。由于捕获变量a除了初始化副职外还被修改过，所以局部变量a改为堆分配。

栈上存储它的地址还有个局部变量b等于二。然后创建臂包对象，对分配一个方块，外流结构体，不获列表中存储a的地址。deferp执行时，defer结构体中的fn保存的就是这个方块结构体的起始地址。除此之外，还要拷贝参数b的值到后面，然后把这个底分结构体添加到底分链表头，底分prock结束。执行到这一步，a被置为三注意a，在这里，下一步自然输出a等于三b等于二。然后就到底峰return了。从底分链表头拿到这个底分结构体，执行注册的底缝函数时，把参数b拷贝到栈上的参数，空间。还记得b包函数，怎样找到不会列表吗？通过寄存器存储的方扣按钮地址加上偏移，找到不货变量a的地址。执行到这一步，是，b等于二a等于三a加b等于五所以下一步会输出a等于五b等于二。这里最关键的是分清几份传参与臂包捕获变量的实现机制。现在就很容易解释形如这样的问题了，这里def注册的函数是a。敌方链表相存储的也是a的方cv六指针，因为注册时需要保存a的参数，就要拿到b的返回值。既然明确了b会在底分注册时执行，也就不会困惑于这个参数a的取值了。注册时a等于一def注册保存的参数值92所以def直行时，函数a会输出三。最后来看一个几份签套的例子，这一次抛开所有细节，只看几份列表，随着a的执行会怎样变化？首先，函数a注册两个底缝，简单用函数明标记下。

到a返回前，执行 defer return时，会判断 defer 链表头上的 defer 是不是a注册的。方法就是判断def结构体记录的s，p是否等于a的栈指针。保存函数调用的相关信息后，把它从敌方列表中移除，然后执行函数a二。用注册两个 defer 即为b一和b二。埃尔返回前，同样去执行 defer 链表，同样判断是否是自己注册的 defer 函数，然后第二执行。同样的流程比一直行。此时，埃尔仍然不知道自己注册的 defer 已经执行完了，直到下一个底分点sp不等于自己的栈指针。然后a二就可以结束了。再次回到a的d分执行流程执行a一a一结束后d分列表为空函数a结束。这里的关键是了解敌方链表注册时添加链表象，执行时移除链表象的用法。到这里够1。12版本的地方，基本设计思路就算梳理完了。这一版本的底分比较明显的问题就是，慢。第一个原因是 defer 结构体堆分配。即使有预分配的deferpool也需要去堆上获取与释放，而且参数还要在堆栈间来回拷贝。第二个原因是使用练表注册 defer 信息，而练表本身操作比较慢。所以，够在1。13和1。14中分别做了不同的优化，这些内容下次继续。

### 1.13、1.14

继续构语言底份，先来看这样一段代码，在一个函数a中有一个底方函数b。这在1。12版本中编译后的为指令是这样的。同样一段代码在1。13中对应的边以后为止令是这样的。我们暂且只关注正常执行流程，所以先忽略掉这些和panic，recover相关的部分。下面就来看看1。13做出了怎样的优化。1。12中，通过deferprock注册底份函数信息，底份结构体分配在堆上。在1。13中，通过在编译阶段增加这样的局部变量，把底份信息保存到当前函数栈帧的局部变量区域。再通过defer。prok。stack把栈上这个defer结构体注册到底封链表中。一份1。13的优化点主要在于减少底份信息的堆分配。之所以说减少。是因为像这样的显示循环或这样的隐视循环中的底份依然需要使用1。12版本的处理方式在堆上分配。为此，底说结构体中增加了一个字段，用于标识是否为对分配。所以这里的局部变量地64位下参数加返回值共占八字节。hp为boss，其他字段都与1。12版本相同，底附函数的参数也同样放在底附结构体后面。到敌方执行时，依然是通过敌方return实现的。也同样要在底份函数直行时拷贝参数，不过不是在堆栈舰，而是从栈上的局部变量空间拷贝到参数空间。1。13的几份官方提供的性能提升是30%那1。14版本又有什么不一样的优化策略呢？

这一次，我们一部分一部分的看，这里是函数a边，以后的为指令，在最后，这里我们略区一部分与cover相关的内容。函数a有两个底分，先看a，一。这里把底缝函数a一需要的参数定义为局部变量。然后在函数返回前直接调用底分函数a，一。用这样的方式省去了构造底缝链表象并注册到链表的过程也同样实现了底缝函数延迟执行的效果。不过a二就不能这样简单处理了，他要到执行阶段才能确定是否需要被调用。报语言用一个标识变量d。f来解决这个问题，d，f里每一位对应标识一个底分函数是否要被执行？例如这里第一位对应几幅函数a，一a一需要执行，所以通过货运算把d，f第一位至为一。底座函数调用，这里也要修改一下，先判断底座标识位是否唯一。执行前还要把d，f对应的标识位置为零避免重复执行，然后直接调用a一就好。同样的方式，到df，a二这里到程序执行阶段，就会根据具体条件判断d，f，第二个标识位是否要被置为一。对应的函数返回前也要依据第二个标识位来决定是否要调用函数a，二。勾1。14的底缝就是通过在编译阶段插入代码，把底缝函数的直行逻辑展开在所属函数内。从而免于创建底份结构体，而且不需要注册到底份链表，不语言称这种方式为open。cod的底份。但是，同1。131样，他依然不适用于循环中的底分。

所以，在这两个版本中，1。12版本的处理方式是一直保留的。通过性能测试，三个版本的表现如下。可以看到，1。13版本性能提升了25%左右，与官方提供的数据出入不大。而1。14版本的性能几乎提升了一个数量级。但是这并非没有代价，我们一直在梳理的都是程序正常执行的流程。如果在这里发生panic，或者调用run。time点ox的函数，后面这些代码根本执行不到，就要去执行底附列表了。而这些open。cod的方式实现的地方并没有注册到列表，需要额外通过占扫描的方式来发现。所以，1。14版本中的份结构体在1。13版本的基础上又增加了几个字段。借助这些信息，可以找到未注册到列表的底附函数，并按照正确的顺序执行。所以实际上，1。14版本中迪弗尔的确变快了，但panic变得更慢。不过既然够语言选择，做出这样的优化定然始终和考量了整体性呢，毕竟panic发生的几率要比底分低。好了，不语言底份就这样。



## 类型系统

如果我们自定义一个结构体类型T，并且给他关联一个方法f1。这个方法调用，之前我们也介绍过方法，本质上就是函数，只不过在调用时，接收者会作为第一个参数传入。

这在编译阶段自然行得通，但是到了执行阶段，反射、接口动态排发、类型断言 这些语言特性或机制，又该如何动态的获取数据类型信息呢？接下来我们就来捯一捯这个问题

```GO
func main() {
    t := T{name: "eggo"}
    t.F1()
}
type T struct {
    name string
}
func (t T) F1() {
    
}
```

首先，要理清楚在go语言中，int、byte、string、slice、func、map等，这些属于内置类型，而我们自己通过下面这些方式定义的类型都属于自定义类型。

```go
type T int
type T struct {
    name string
}
type T interface {
    Name() string
}
```

给内置类型定义方法是不被允许的，而接口类型是无效的方法接收者，所以我们不能像类型T这样给内置类型和接口定义方法。

数据类型虽然多，但是不管是内置类型还是自定义类型，都有对应的类型描述信息，称为它的**类型元数据**。

而且，每种类型的元数据都是全局唯一的，这些类型元数据共同构成了go语言的类型系统。

而类型元数据这里，像类型名称、大小、对其边界、是否为自定义类型等，是每个类型元数据都要记录的信息，所以被放到了 runtime._time 结构体中，作为每个类型元数据的head。

```go
type _type struct {
    size       uintptr
    ptrdata    uintptr
    hash       uint32
    tflag      tflag
    align      uint8
    fieldalign uint8
    kind       uint8
    ......
}
```

在 `_time` 之后，存储的是各种类型额外需要描述的信息，例如 slice 的类型元数据在 `_time` 结构体后面，记录着一个 `*_type` ，指向其存储的元素的类型元数据。如果是 string 类型的 slice ，这个指针就指向 string 类型的元数据

```go
type slicetype struct {
    typ  _type
    elem *_type
}
```

如果是自定义类型。这后面还会有一个 uncommontype 结构体，pkgpath 记录类型所在的包路径，mcount 记录了该类型关联到多少个方法，moff 记录的是这些方法元数据组成的数组，相对于这个 uncommontype 结构体偏移了多少字节。

```go
type uncommontype {
    pkgpath nameOff
    mcount  uint16
    _       uint16
    moff    uint32
    _       uint32
}
```

例如，我们基于 []string 定一个新类型 myslice ，它就是一个自定义类型，可以给他定一两个方法 Len 和 cap

myslice 的类型元数据：首先是 []string 的类型描述信息 slicetype，然后在后面加上 uncommontype 结构体，

注意通过 uncommontype 这里记录的信息，我们就可以找到给 myslice 定义的方法元数据在哪了。

如果按 uncommontype 的地址为 addra，加上 moff 字节的偏移，就是 myslice 关联的方法元数据数组。

![](./img/14.png)

接下来，我们可以利用类型元数据，来解释下面这两种写法的区别。

`type MyType1 = int32` 这种写法，叫做给类型 int32 取别名，实际上 MyType1 和 int32 会关联到同一个类型元数据，属于同一种类型，rune 和 int32 就是这样的关系

而 `type MyType2 int32` 这种写法，属于基于已有类型创建新类型，MyType2 会自立门户，拥有自己的类型元数据。即使 MyType2 相对于 int32 来说，并没有做任何改变，它们两个对应的类型元数据也已经不同了。

```go
type MyType1 = int32
type MyType2 int32
```

既然每种类型都有唯一对应的类型元数据，而类型定义的方法能通过类型元数据找到。那么很多问题就变得好解释了，例如接口。



## 接口

我们先来看看空接口长什么样子。空接口类型可以接收任一类型的数据，它只要记录这个数据在哪，是什么类型的，就足够了。

这个 `_type` 就指向接口的动态类型元数据，`data` 就指向接口的动态值。

```go
type eface struct {
    _type *_type
    data  unsafe.Pointer
}
```

一个空接口类型的变量e，在它被赋值以前，`_type` 和 `data` 都为nil。

现在我们有一个 `*os.File` 类型的变量 f。了解类型系统之后，我们知道， `*os.File` 对应的类型元数据 `_type...uncommontype`。

如果把 f 赋值给 e，因为 f 本身就是个指针，所以这个 e 的 data 就等于 f ，而`_type` 就指向`*os.File` 的类型元数据。

我们已经知道，类型元数据这里，可以找到`*os.File` 的方法元数据数组，里面就有我们常用的 Read 和 Write 这些方法的描述信息。

好了，这就是空接口类型变量赋值前后的变化，

```go
var e interface{}
f, _ := os.Open("yuanya.txt")
e = f
```

下面来看看非空接口。非空接口就是有方法列表的接口类型，一个变量要想赋值为一个非空接口类型，必须要实现该接口要求的所有方法才行。

与空接口类型一样，它的 data 字段指向接口的动态值，所以，接口要求的方法列表，以及接口动态类型信息，一定存储在这个 itab 结构体里。

第一个字段指向 interface 的类型元数据，接口要求的方法列表就记录在 mhdr 这里。

第二个字段指向接口的动态类型元数据。

hash 是从动态类型元数据中拷贝来的类型哈希值，用于快速判断类型是否相等时使用。

fun 记录的是这个动态类型实现的那些接口要求的方法地址。

```go
type iface struct {
    tab  *itab
    data unsafe.Pointer // 接口动态值
}
type itab struct {
    inter *interfacetype // 接口类型元数据
    _type *_type         // 接口动态类型元数据
    hash  uint32         // 从动态类型元数据中拷贝来的类型哈希值
    _     [4]byte
    fun   uintptr        // 该动态类型实现的那些接口要求的方法地址
}
type interfacetype struct {
    typ     _type     // 接口类型元数据
    pkgname name
    mhdr    []imethod // 接口要求的方法列表
}
```

如果我们声明一个 io.ReadWriter 类型的变量 rw，它被赋值以前，data为nil，tab也为nil。

下面我们把一个 `*os.File` 类型的变量 f，f 赋值给 rw，此时 rw 的动态值就是 f，而它的 tab 会只像一个 itab 结构体。它的接口类型为 io.ReadWriter，动态类型为 `*os.File` 。同时要注意itab这里的fun，它会从动态类型元数据中拷贝接口要求的那些方法的地址，以便通过rw快速定位到方法，而无需再去类型元数据那里查找。

![](./img/15.png)

这就是非空接口的结构。关于itab，还要额外关注一点，我们知道，一旦接口类型确定了，动态类型也确定了，那么itab的内容就不会改变，所以，这个 itab 结构体是可复用的，

实际上，go语言会把用到的 itab 结构体缓存起来。并且以接口类型和动态类型的组合为key，`<inter.typ,_type>`，以 itab 结构体指针为value，构造一个哈希表，用于存储与查询 itab 缓存信息，

这里的哈希表（runtime.itabTableType）和map底层的哈希表不同，是一种更为简便的设计。需要一个itab时，会首先去这里查找，

key的哈希值，是这样计算的，用接口类型的类型哈希值，与动态类型的类型哈希值，进行异或运算，如果已经有对应的 itab 指针，就直接拿来使用。

若 itab 缓存中没有，就要创建一个 itab 结构体，然后添加到这个哈希表中。

![](./img/16.png)

ok，明确了空接口和非空接口的数据结构，理解了接口动态值与动态类型在赋值前后的变化。接下来，就可以看看类型断言了。



## 类型断言

我们知道接口可以分为空接口和非空接口两类，相对于接口这种**抽象类型**。int、string、slice、map、struct......都可以被称为**具体类型**。

类型断言作用在接口值之上，可以是空接口，或非空接口。而断言的目标类型可以是具体类型，或非空接口类型。

这样，就组合出了四种类型断言，接下来我们就逐一看看他们究竟是怎样断言的。



先来看第一种`空接口.(具体类型)`，只需要比较 `_type`。`e.(*os.File)` 是要判断 e 的动态类型是否为`*os.File`。这只需要确定e的`_type`是否指向`*os.File`的类型元数据就好。

反正我们已经介绍过go语言里每种类型的类型，元数据都是全局唯一的。

```go
var e interface{}
r, ok := e.(*os.File)
```

如果像这样给 e 赋值，e 的动态值 data 就是 f，动态类型就是`*os.File`，所以断言成功。ok为true，r 被赋值为 e 的动态值，

```go
var e interface{}
f, _ := os.Open("yuanya.txt")
e = f
r, ok := e.(*os.File)
```

而如果像这样赋值，e的动态类型就是string，类型断言就会失败，所以ok为false，r 就会被赋值为 `*os.File` 的类型零值nil。

```go
var e interface{}
f := "yuanya"
e = f
r, ok := e.(*os.File)
```



下面来看第二类`非空接口.(具体类型)`，只需要比较 itab。`rw.(*os.File)` 是要判断 rw 的动态类型是否为`*os.File`。

前面我们介绍过程序中用到的 itab 结构体都会缓存起来，可以通过接口类型和动态类型组合起来的 key 查找到对应的 itab 指针。

所以这里的类型断言只需要一次比较就能完成，只要看 rw 的 tab 是否指向缓存中 `<io.ReadWriter,*os.File>` 为 key 对应的 itab 结构体就好。

```go
var rw io.ReadWriter
r, ok := rw.(*os.File)
```

如果rw这样赋值，它的动态值就是 f，动态类型就是`*os.File`。

所以它的 tab 指向缓存中由 io.RaedWriter 与 *os.File 参与组成 itab 结构体，类型断言成功，ok为 true，r 被赋值为rw的动态值。

然而，如果rw动态类型不是`*os.File`。此时tab就指向其它的 itab 结构体，所以类型断言就会失败，ok为false，而r会被置为 `*os.File` 的类型零值 nil。

```go
var e interface{}
f := "yuanya"
e = f
r, ok := e.(*os.File)
```



下面再来看看第三位 `空接口.(非空接口)`，需要**直接或间接判定是否实现对应接口所有方法**。`e.(io.ReadWriter)`是要判断 e 的动态类型是否实现了 io.ReadWriter 接口。

```go
var e io.ReadWriter
rw, ok := e.(io.ReadWriter)
```

当然，我们已经介绍过类型关联的方法列表，该去哪里找了。如果 e 像这样赋值，它的动态值就是 f，动态类型就是`*os.File`。

虽然 `*os.File` 类型元数据后面，可以找到类型关联的方法元数据数组，但也不必每次都去检查这里是否有对应接口要求的所有方法。

不是有itap缓存吗？可以先去 itab 缓存中查找一下，若没有`<io.ReadWriter,*os.File>` 为 key 对应的 itab 结构体，再去检查 `*os.File` 的方法列表。

值得强调的是，就算能够从缓存中查找到对应的 itab 指针，也要进一步判断 itab.fun[0] 是否等于0。

这是因为，断言失败的类型组合，其对应的 itab 结构体也会被缓存起来，只是会把 itab.fun[0] 置为零，用以标识这里的动态类型并没有实现对应的接口。

这样以后再遇到同种类型断言时，就不用再去检查方法列表了，可以直接断言失败。

我们这个例子中，类型断言是成功的，所以 ok 为 true，rw就是一个 io.ReadWriter 类型的变量，其动态值与 e 相同，而 tab 就指向 `<io.ReadWriter,*os.File>` 对应的 itab 结构体，

```go
var e io.ReadWriter
f, _ := os.Open("yuanya.txt")
e = f
rw, ok := e.(io.ReadWriter)
```

如果 e 被赋值为一个字符串，它的动态类型就是 string。并没有实现要求的 Read 和 Write 方法，所以对应的 itab 中fun[0]=0，并且会被添加到itab缓存中。

这里断言失败，ok为false。rw为 io.ReadWriter 的类型零值 nil。

```go
var e io.ReadWriter
f := "yuanya"
e = f
rw, ok := e.(io.ReadWriter)
```



最后来看看第四类类型断言，`非空接口.(非空接口)` ，需要判断**动态类型**是否相同。`w.(io.ReadWriter)` 是要判断 w 存储的动态类型，是否实现了 io.ReadWriter 。

接口 w 是 io.Writer 类型，接口要求一个 Write 方法，io.ReadWriter 接口要求实现 Read 和 Write 两个方法。

```go
var w io.Writer
rw, ok := w.(io.ReadWriter)
```

如果w像这样赋值，其动态值就是 f。tap 指向 `<io.Writer, *os.File>` 对应的 itap 结构体。

要确定 `*os.File` 是否实现了 io.ReadWriter 接口。同样，会先去 itab 缓存里查找 `<io.ReadWriter, *os.File>` 这个组合对应的 itab 指针。

若存在且 itab.fun[0]!=0 则断言成功；若不存在，再去检查 `*os.File` 的方法列表，并缓存 itab 信息

这里断言成功，ok为 true。rw 为 io.ReadWriter 类型的变量，动态值与 w 相同。而 tab 指向 `<io.ReadWriter, *os.File>` 对应的 itab 结构体，

```go
var w io.Writer
f, _ := os.Open("yuanya.txt")
w = f
rw, ok := w.(io.ReadWriter)
```

如果我们自定义一个 eggo 类型。并且，`*eggo` 类型只实现了 io.Writer 接口，并没有实现 io.ReadWriter 接口。

若把一个 `*eggo` 类型的变量赋给 w，此时 w 的动态类型为 `*eggo` ，并没有实现指定接口，fun[0]=0，这个 itab 结构体被缓存起来，类型断言失败，ok为false，

而 w 的 tab 和 data 均为 nil 。

```go
{
    var w io.Writer
    f, _ := eggo{name: "yuanya"}
    w = f
    rw, ok := w.(io.ReadWriter)
}

type eggo struct {
    anme string
}
func (e *eggo) Write(b []byte) (n int, err error) {
    return len(e.name), nil
}
```

所以，类型断言的关键，是明确接口的动态类型以及对应的类型实现了哪些方法，而明确这些的关键，还是类型元数据、空接口、非空接口的数据结构。



## 反射

反射的作用就是把类型元数据暴露给用户使用。其实，在了解了类型系统和接口以后。反射所做的事情就没什么神奇的了。

我们已经介绍过runtime包中，类型元数据、空接口、非空接口这些结构。但是，由于这些类型都是未导出的，所以，reflect包中又定义了一套，这些类型定义在两个包中是保持一致的。

reflect包提供 TypeOf 函数，用于获取一个变量的类型信息，他接收一个空接口类型的参数，并返回一个 reflect.Type 类型的返回值。

 reflect.Type 是一个非空接口，提供了一系列方法，供用户获取类型各方面的信息。例如，对其边界、方法、类型名称、包路径、是否实现制定接口、是否可比较，等等等等。

```go
type Type interface {}
```



如果我们在 eggo 包中定一个 Eggo 类型，在 main 包中使用这个类型，并且想通过反射，看看这个类型有多少个可导出的方法。

从函数调用栈来看，main 函数的栈帧中有两个局部变量，Eggo 类型的 a，reflect.Type 类型的 t，然后是返回值空间，最后是参数。

go 语言中传参都是值拷贝，参数空间，这里本应该拷贝 a 的直过来，但是不行，因为参数是空接口类型，它需要的是一个地址；难道要拷贝a的地址过来？也不行，因为按照传参值拷贝的语义，被调用函数使用的应该是 a 的拷贝，也就是说，无论它对参数做什么样的修改，都不应该作用到原变量a的身上，如果我们直接拷贝 a 的地址过来，就不符合这样的语意了，

既然不能拷贝a，又不能拷贝a的地址，那该拷贝谁？实际上编译阶段会增加一个临时变量（main的局部变量空间中）作为a的拷贝，然后在参数空间这里使用这个临时变量的地址。

现在，TypeOf 函数使用的就是 a 的拷贝，这样既符合传参值拷贝的语意，又满足了空接口类型的参数只能接收地址的需求。

所有参数为空接口类型的情况，都要像这样通过传递拷贝后变量的地址，来实现传值的语意。

```go
package eggo
type Eggo struct {
	Name string
}
func (e Eggo) A() {
    println("A")
}
func (e Eggo) B() {
    println("B")
}
```

```go
func mian() {
    a := eggo.Eggo{Name: "eggo"}
    t := reflect.TypeOf(a)
    println(t.Name, t.NumMethod()) // Eggo 2
}
```

我们继续看 TypeOf 函数。接下来，他会把这个 runtime.eface 类型的参数 i，转换成 reflect.emptyinterface 类型，并赋给变量 eface，

reflect.emptyinterface 与 runtime.eface 这两个类型的结构是一致的，转换以后方便 reflect 包来操作内部元素。因为星 `*rtype` 类型实现了 Type 接口。

所以 TypeOf 函数接下来要做的就是把 eface.typ 包装成 reflect.Type 类型的返回值，TypeOf 的任务就完成了。

返回的 reflect.Type 是个非空接口，还记得非空接口的结构吗，tab 中接口类型自然是 reflect.Type ，动态类型是 `*rtype` ，data 就等于 eface.typ 也就是反射变量的类型元数据地址。

而这里它的 tab.fun 中对应的那些方法，也不过是去 eface.typ 指向的类型元数据那里读取各种信息罢了。

回到这个例子，返回值长什么样子？一个 reflect.Type 和 `*rtype` 组合对应的 itab 指针，一个 Eggo 类型元数据的地址 data=&Eggotype。

所以我们通过 reflect.TypeOf 拿到的就是这样一个非空接口变量，包含  `data=&Eggotype` 和 `tab=itab指针`。

接下来，通过 t 调用这些方法，就会去 Eggo 的类型元数据里查找相关信息。

```go
func TypeOf(i interface{}) Type {
    eface := *(*emptyInterface)(unsafe.Pointer(&i))
    return toType(eface.typ)
}
```

```go
type emptyinterface struct {
    typ  *rtype
    word unsafe.Pointer
}
```

ok，搞定了反射获取类型信息的方式，再来看看通过反射修改变量值是怎么回事。这就要用到 reflect.Value 类型了，这是一个结构体类型。

第一个字段存储反射变量的类型元数据指针；第二个字段存储数据地址；第三个字段是一个未标示符，存储反射值的一些描述信息，例如是否为指针，是否为方法，是否只读等等。

通常会用 reflect.ValueOf 来拿到一个reflect.Value。

注意，这个函数的参数也是空接口类型，所以和 TypeOf 参数处理方式一样。除此之外，ValueOf 函数会显式的通过 escapes 函数把参数指向的变量逃逸到堆上。

```go
type Value struct {
    typ  *rtype
    ptr  unsafe.Pointer
    flag
}

func ValueOf(i interface{}) Value {
    if i == nil{
        return Value{}
    }
    escapes(i)
    return unpackEface(i)
}
```

来看一个例子，这里想通过反射修改一个 string 类型的变量 a。main 函数栈帧中有一个 string 类型的局部变量 a，还有一个 Value 类型的局部变量 v。

同 TypeOf 一样的是，编译阶段会增加一个临时变量作为 a 的拷贝；同 TypeOf 不一样的是，这个临时变量会被显式的逃逸到堆上，栈上只留它的地址。

后面是调用 ValueOf 函数的返回值空间以及参数空间，

参数是一个空接口，包含 `_type` 和 data。`_type` 指向 string 类型元数据，`_type=&stirngtype` ；data 指向 a 的拷贝，data=&(copy of a)

返回值类型 Value 是一个非空接口，typ 就等于参数的第一个字段 `_type` ，ptr就等于参数的第二个字段 data ，再把flag处理好，ValueOf 的任务就完成了。

所以，返回值拷贝到局部变量 v，接下来调用 v.SetString 时，因为 ptr 指向 a 的拷贝，而不是 a

而修改这样一个用户都不知道的临时变量没有任何意义，所以会发生panic，提醒我们，这里反射修改变量值是行不通的。

```go
func main() {
    a := "eggo"
    v := reflect.ValueOf(a)
    v.SetString("new eggo")
    println(a) // panic
}
```

若想修改成功，就要反射 a 的指针，这样 VlueOf 函数的参数指向的变量就是 a，因为这里直接向下传递指针，所以直接导致局部变量 a 逃移到堆上，没有拷贝临时变量的过程了

所以 main 函数栈帧中，局部变量 a 逃移到堆上，栈上只留一个地址。

参数这里 `_type` 就指向 `*stringtype` 类型元数据，而 data=&a 指向 a，

所以 VlueOf 的返回值就是这样的，typ=&(*stringtype)、ptr=&a、flag，然后会赋值给局部变量v。

接下来，要用v.Elem() 方法，会拿到 v.ptr 指向的变量 a，并把它包装成reflect.Value类型的返回值，返回值中类型是string，地址指向堆上的a，然后这个返回值被赋给v。

此时再通过 v 调用 SetString 方法时，方法接收者 v 作为第一个参数，字符串新值"new eggo"作为第二个参数。

v.ptr 指向堆中 a，所以这一次修改的就是局部变量 a.data，最后这里就会输出修改后的值"new eggo"。



```go
func main() {
    a := "eggo"
    v := reflect.ValueOf(&a)
    v := v.Elem()
    v.SetString("new eggo")
    println(a) // "new eggo"
}
```



通过反射修改变量值的问题有点绕。不过只要理解传参值拷贝的语义，以及通过繁射修改变量值要作用到圆变量身上才有意义。理解起来就是相对容易些。ok，反射中最最关键的两个类型，以及最重要的两个方法就介绍到这里。

## GPM

一个 helloworld 程序，编译后成为一个可执行文件，执行时，可执行文件被加载到内存，对应进程虚拟地址空间中的代码段。

我们感兴趣的是程序执行入口，它并不是我们熟悉的 main.main，不同平台下程序执行入口不同。

在进行一系列检查与初始化等准备工作后，会以 runtime.main 为执行入口通过 newproc() 函数创建 main goroutine，main goroutine 执行起来以后才会调用我们编写的 main.main。



再来看数据段，这里有几个重要的全局变量不得不提。我们知道go语言中 **goroutine** 对应的数据结构是 **runtime.g** ，**工作线程**对应的数据结构是 **runtime.m**。

而全局变量 g0 就是 main goroutine 对应的 g，与其他 goroutine 有所不同，它的 goroutine 栈实际上是在**主线程栈**上分配的。

全局变量 m0 就是主线程对应的 m。g0 持有 m0 的指针，m0 里也记录着 g0 的指针。而且一开始 m0 上执行的 goroutine 正是 g0，m0 和 g0 就这样联系了起来。

全局变量 allgs 记录着所有的 g，allm 自然用于记录所有的 m。最初go语言的调度模型里只有m和g，所以待执行的 g 排排座等在一处，每个m来这里获取一个 g 时都要加锁。

多个 m 分担着多个 g 的执行任务，就会因频繁加锁解锁而发生等待，影响程序并发性能，所以后来在 m 和 g 以外又引入了 p，p 对应的数据结构是 **runtime.p**。

 

p 有一个本地 runq（run queque），这样，只要把一个 p 关联到一个 m，这个 m 就可以从 p 这里直接获取待执行的 g，不用每次都和众多 m 从一个全局队列中争抢任务了。

也就是说，虽然p有一个本地 runq，但是依然有一个全局 runq。它保存在全局变量 sched 中，这个全局变量代表的是调度器，对应的数据结构，是 **runtime.schedt** 。

这里记录着所有空闲的m、空闲的p等等许多和调度相关的内容。其中就有一个全局的runq。如果 p 的本地队列已满，那么等待执行的 g 就会被放到这个全局队列里。

而 m 会先从关联的 p 持有的本地 runq 有中获取带执行的g，没有的话，再到调度器持有的全局队列这里领取一些任务。如果这里也没有了，就会去别的 p 那里分担一些 g 过来。

同 g 和 m 一样，也有一个全局变量 allp 用于保存所有的 p。

在程序初始化过程中，会进行调度器初始化，这时会按照 GOMAXPROCS 这个环境变量，决定创建多少个p，保存在全局变量 allp 中。并且把第一个 p 与 m0 关联起来。

简单来说，g、m、p就是这样的合作关系，现在我们可以更清晰的理解这个经典的示意图了。

![](./img/17.png)

在 main goroutine 创建之前，g、p、m的情况是这样的 g0-m0-allp[0]。 

![](./img/18.png)

main goroutine 创建之后，被加入到当前 p 的本地队列中，然后通过 mstart 函数开启调度循环。

![](./img/19.png)

这个 mstart 函数是所有工作线程的入口，主要就是调用 schedule() 函数，也就是执行调度循环。

其实，对于一个活跃的m而言，不是在执行某个g，就是在执行调度程序，获取某个g，我们暂且不展开调度循环的具体逻辑。

反正目前面临的调度场景很简单，队列里只有 main goroutine 等待执行，所以m0切换到 main goroutine 。

执行入口自然是 runtime.main，它会做很多事情，包括创建监控线程、进行包初始化等等，其中也包括调用我们熟悉的main.main ，终于可以输出"hollo world"了。

值得一提的是，在 main.main 返回之后， runtime.main 就会调用 exit() 函数结束进程。

```go
func main() {
    fmt.Println("hello world")
}
```

接下来，我们把这个 helloworld 的程序改造一下。

如果在 main.main 中不直接输出而是通过一个 goroutine 来输出，那么当 main.main 被调用执行时，就会创建一个新的 goroutine 。我们把它记为 hello goroutine 。

我们通过 go 关键字创建 goroutine ，会被编译器转换为 newproc() 来创建。创建 goroutine 时，我们只负责指定入口、参数 (0, hello)。

而 newproc 会给 goroutine 构造一个栈帧，目的是让 goroutine 任务结束后返回到 goexit() 的函数中，进行 goroutine 资源回收处理等工作，

这很合理，一个 goroutine 在任务完成后是该放到空闲 g 队列里备用？还是该释放？总归要有个出路。

回到这里，如果我们设置 GOMAXPROCS 只创建一个p。新创建的 hello goroutine 会被添加到当前 p 的 runq 中。然后 main.main 就结束返回了，

再然后，exit() 函数被调用，进程就结束了，然后就没有然后了。所以 hello goroutine 没能执行。

问题就在于 main.main 返回后，exit() 函数就会被调用，直接把进程给结束掉，没给  hello goroutine 空出调度执行的时间。

所以要想让 hello goroutine 执行，就要在 main.main 返回之前拖延下时间。

如果是用time.Sleep，实际上会调用 gopark 函数，把当成 goroutine 的状态从 `_Grunning ` 修改为 `_Gwaiting`。

然后 main goroutine 不会回到当前 p 的 runq 中，而是在 timer 中等待，继而调用 schedule 进行调度，hello goroutine 得以执行。

等到 sleep 的时间到达后，timer 会把main goroutine 重新置为 `_Granable` 状态，放回到 p 的 runq 中。再然后 main.main 结束， exit 得以调用，进程退出。

这是只有一个p的情况，如果创建了多个p， hello goroutine 创建之后，虽然默认会添加到当前 p 的本地队列里。但是，在有空闲 p 的情况下，就可以启动新的线程关联到这个空闲的p。并把 hello goroutine 放到它的本地队列中了，同样的，可以使用 time.sleep，或者是等待一个 Channel，又或者是使用 WaitGroup。

反正只要 main.main 不马上返回， hello goroutine 就有时间得以执行了。

```go
func main() {
    go hello()
}
func hello() {
    fmt.Println("hello world")
}
```

这一次，我们通过 halloworld 的程序了解了一个go程序启动的大致过程。认识了g0、m0等等非常重要的全局变量，也初步了解了g、p、m三者的关系。

接下来，我们会把 goroutine 创建、调度、监控线程等关键内容展开来学习一下，逐步加深对go语言中 gpm 模型的理解



```go
func main() {
    name := "Goroutine"
    go hello(name)
}
func hello(name string) {
    fmt.Println("hello", name)
}
```

还是这个 hello goroutine 的例子，只不过给 goroutine 入口函数增加一个参数。

我们已经知道 main goroutine 执行起来会创建一个 hello goroutine 。而创建的任务就交由 newproc() 函数来负责

我们通过函数栈帧看一下 newproc() 函数的调用过程。main 函数**栈帧**自然分配在 main goroutine 的**协程栈**中。

还记得go语言函数栈帧布局吧？call 指令入栈的返回地址之后，是调用者栈基，然后是局部变量区间，以及调用其它函数时传递返回值和参数的区间。

main函数，这里有一个局部变量name。接下来要调用 **newproc** 函数，从newproc 函数签名来看，要接收两个参数，

第一个是传递给协程入口函数的参数占多少字节，第二个是协程入口函数对应的 funcval 指针。

所以在参数空间这里要入栈两个参数，由右至左。先入栈 fn，也就是协程入口函数 hello() 对应的 funcval 指针，再入栈参数大小，一个 string 类型的参数 64 位下占 16 字节。

实际上，这个要传递给 协程入口函数的参数 name，也会被放到第二个参数之后，作为第三个参数，所以局部变量 name 要拷贝过来，这样就好像给 newproc 函数传递了三个参数一样。

而这下面就是 call 指令入栈的返回地址，再然后就是 newproc 函数栈帧了。



而 newproc 函数这里，主要做的，就是切换到 g0 栈，去调用 newproc1() 函数。

至于为什么要切换到 g0 栈，简单来说是因为 g0 的栈空间，它大呀。

因为 runtime 中很多函数都有 no-split 标记，意味着这个函数不支持栈增长。也就是说，编译器不会在这个函数中插入栈增长相关的检测代码。

协程栈本来就比线程栈小得多，这些函数自己要消耗栈空间却又不支持栈增长。那在普通协程上执行他们，万一栈溢出了就不好了。

而 g0 的栈直接分配在线程栈上，栈空间足够大，所以直接切换到 g0 栈来执行这些函数，就不用担心栈溢出的问题了。

再来看，他调用 newproc1 时都传递了些什么参数。fn和size不用多说，就是 newproc 自己接收的那俩参数。

这个 argp 赋值时，是用参数 fn 的地址加上一个指针大小，那就正好是这里 fn 上面的 name 变量。所以，argp 用来定位到协程入口函数的参数，

第四个参数 gp 是当前 goroutine 的指针。我们的例子中，newproc 函数执行在 main gorouting 中，所以 gp 就是 main gorouting 的 g 指针。

最后一个参数 pc ，在 newproc 函数中调用 getcallerpc，得到的是 newproc 函数调用结束后的返回地址，也就是 returen addr 这里，即调用 newproc 函数时由 call 指令入栈的那个返回地址。

![](./img/20.png)

于 newproc1 而言，他的任务是创建一个 goroutine ，而目前已经知道新建 goroutine 入口在哪、参数在哪、占多少字节，还知道他的 父协程 是谁，以及创建完 协程后要返回到哪儿去

 newproc1 首先要通过 acquirem() 禁止当前 m 被抢占。为什么不能抢占？因为接下来要执行的程序中，可能会把当前 p 保存到局部变量中。若此失 m 被抢占，p关联到别的m，等到再次恢复时，继续使用这个局部变量里保存的 p 就会造成问题。所以，为了保持数据一致性，会暂时禁止m被抢占。

继续看，接下来会尝试获取一个空闲的g，如果当前 p 和调度器中都没有空闲的g，就创建一个，并添加到全局变量 allgs 中。

我们依然把这个新创建的 协程记为 hello goroutine ，此时他的状态是 _Gdead ，而且已然拥有自己的协程栈。

接下来，如果 协程入口函数有参数，就把参数移动到协程栈上，对 hello goroutine 而言，就要把 main goroutine 中的name拷贝到自己栈中，再然后就有点意思了。

接下来，会把 goexit 函数的地址加 1 压入协程栈( hello goroutine )。再把 hello goroutine 对应的 g 的 startpc 置为协程入口函数起始地址，g 的 gopc 置为父协程调用 newproc 后的返回地址pc，g.shed 这个结构体用于保存现场。

此时会把 g.sched.sp 置为协程栈(hello goroutine)指针，g.sched.pc 同样指向协程入口函数的起始地址。

现在我们来看 hello goroutine 的协程栈，参数name，这是返回地址，下面是 hello 函数的栈帧，

因为 hello 执行完要返回 goexit +1 这个返回地址，这岂不是就像在 goexit 的函数中调用了协程入口函数hello，并且传递了用户传递的参数name。

而指令指针刚刚跳转到 hello 函数的入口处，却还没有开始执行时的状态。

所以，经这一通伪装，待到这个 协程得到调度执行的时候。通过 g.sched 恢复现场，就可以通过 g.sched.pc 从 hello 函数入口处开始执行了，

而 hello 函数结束后，便会返回到 goexit 函数中，执行协程资源回收等收尾工作。这样一来， goroutine 该如何出场，又该如何收场，就都有了着落，甚是巧妙。

![](./img/21.png)

不过这还没完，newproc1 还会给新建的 goroutine 赋予一个唯一id，给这点g.goid 赋值之前会把 协程的状态置为 `_Grunnable`。

这个状态也意味着这个 g 可以进到 runq 里了。所以接下来会调用 runqput 把这个 g 放到当前 p 的本地队列中。

然后会判断，如果当前有空闲的p `sched.npidle>0`，而且没有处于 spinning (闲)状态的m `&& sched.nmspinning==0`，也就是说所有m都在忙。

同时，主协程已经开始执行了 `&& mainstarted==true`，那么就调用 wakep 函数启动一个m，并把它置为 spinning 状态。

最后，与一开始的 acquirem 相呼应，会调用 releasem 允许当前 m 被抢占。

话说这一边 spinning 状态的 m 启动后，忙不迭的执行调度循环寻找任务，从本地 runq 到全局 runq ，再到其他 p 的 runq，只为找到个待执行的 g。

却也敌不过另一边 main goroutine 早早的结束了进程，

上一次我们使用 time.sleep 拖延了一下 main.main 返回的时间，这一次我们通过等待一个 channel ，看一下协程如何让出，又是怎样恢复的。

```go
func main() {
    ch := make(chan struct{})
    go hello(ch)
    <- ch
}
func hello(ch chan struct{}) {
    fmt.Println("hello goroutine")
    close(ch)
}
```

channel对应的数据结构是 `runtime.hchan`。里面有 channel 缓冲区地址、大小、读写下标，也记录着元素类型、大小，及 channel 是否已关闭，还记录着等待 channel 的那些 g 的读对列与写对列。自然也少不了保护 channel 并发操作安全的一把锁。

我们这个例子中创建的是无缓冲的 channel。`<- ch` 这里会被编译器转换为 runtime.chanrecv1 函数调用，而它实际上会将用 runtime.chanrecv 函数，这个函数的具体逻辑我们到介绍channel时再展开。目前只关注我们的例子会涉及到的一小部分。

ch没有缓冲区，目前也没有哪个 g 等在写等待队列 sendq 中，简言之，没数据可读。所以，当前 goroutine 会阻塞在 ch 这里等待数据。当前 goroutine 自然是 main goroutine 。

而 channel 的读等待对列 recvq 是一个sudog 类型的链表，链表项会记录哪个g等在这里，读到数据后要放到哪里等等。

然后 chanrecv 通过 runtime.gopark 函数使当前 goroutine 挂起，让出cpu。

gopark 首先会调用 acquarem 禁止当前 m 被抢占。然后把 main goroutine 的状态从 `_Grunning` 修改为`_Gwaiting`， main goroutine 不再是执行中的状态了。

接下来，要用 releasem 解除 m 的抢占禁令。最后要用 mcall(park_m)，它主要负责保存当前 goroutine 的执行现场，然后切换到g0栈，调用 mcall 的参数传入的这个函数，对应到这里，就是 park_m 函数，park_m 会根据g0找到当前m，把 m.curg 置为 nil，所以当前 m 正在执行的 g 便不再是 main goroutine 了。

最后会调用 schedule 函数寻找下一个待执行的g，经过上面这一番折腾，hello goroutine 无论是得到当前m的调度，还是被其他m抢了去，总之是可以执行了。

等到 hello goroutine 完成工作，关闭 main goroutine 等待的 channel 时，不止会修改 channel 的 closed 的状态，还会处理等待对列里的这些 g。

我们这个例子只在读对列里有一个 main goroutine 在等待，所以会把他接收的数据置为 nil，并最终调用 goready 函数结束这个 g 的等待状态。

而 goready 函数会切换到 g0 栈并执行 rantime.ready 函数，目前待 ready 的协程自然是 main goroutine ，此时他的状态是 `_Gwaiting`，接下来会被修改为`_Grunnable`，表示他又可以被调度执行了。

然后他会被放到当前 p 的本地 runq 中，同协程创建是一样，接下来也会检查是否有空闲的 p，并且没有 spinning 状态的 m，是的话也会调用 wakep 函数启动新的 m。

接下来，hello goroutine 结束， main goroutine 得到调度执行，最终结束进程。

这样看来。time.sleep 和 channel 底层都会调用 gopark 来实现 goroutine 让出，都会使用 goready 把 goroutine 恢复到runable状态，放回到 runq 中。

![](./img/22.png)

这一次，我们了解了 goroutine 创建的基本步骤，以及 goroutine 让出与恢复到可运行状态的大致过程。

接下来，就要看看这个调度循环开启以后会做什么，又该如何把一个可运行的 goroutine 真正运行起来。



我们已经知道 goroutine 执行 time.sleep 时，状态会从 `_Grunning`变为`_Gwaiting`，并进入到对应timer中等待。

而 timer 中持有一个回调函数，在指定时间到达后，调用这个回调函数，把等在这里的 goroutine 恢复到 `_Grenable` 状态，并放回到 runq 中。

那谁负责在定时器时间到达时触发定时器注册的回调函数呢？其实，每个 p 都持有一个最小堆，存储在 p.timers 中，用于管理自己的 timer ，堆顶timer 就是接下来要出发的那一个。

而每次调度时，都会调用 checkTimers 函数检查并执行已经到时间的那些 timer。

不过，这还不够稳妥，万一所有 m 都在忙，不能及时触发调度的话，可能会导致 timer 执行时间发生较大的偏差。所以还会通过**监控线程**来增加一层保障。

在介绍 hello goroutine 的执行过程时，我们提过监控线程是由 main goroutine 创建的。这个监控线程与 gpm 中的工作线程不同，并不需要依赖p，也不由 gpm 模型调度。

它会重复执行一系列任务，只不过会视情况调整自己的休眠时间，其中一项任务便是保障 timer 正常执行。

监控线程检测到接下来有 timer 要执行时，不仅会按需调整休眠时间，还会在空不出 m 时创建新的工作线程，以保障 timer 可以顺利执行。



当 goroutine 等待一个 channel 时，其状态也会从`_Grunning`变为 `_Gwaiting`，并进入到对应 channel 的读对列或写对列中等待。

如果 goroutine 需要等待 io 事件，就也需要让出。

以 epoll 为例，若 io 事件尚未就绪，需要注册要等待的 io 事件到监听队列中。

而每个监听对象都可以关联一个 event data，所以就在这里记录是哪个 goroutine 在等待。等到时间就绪时，再把它恢复到 runq 中即可。



不过，timer 计时器有设置好的触发时间，等待的channel可读、可写或关闭了，也自会通知到相关协程。而获取就绪的 io 事件需要主动轮询。

所以为了降低l延迟，需要时不时的轮询那么一下，也就是执行 netpoll。

实际上，监控线程、调度器、gc等工作过程中，都会按需执行 netpoll。

全局变量 sched 中会记录上一次 netpoll 执行的时间，监控线程检测到距离上次轮询已经超过十毫秒，就会再执行一次 netpoll。

![](./img/23.png)

上面说的无一例外都是 goroutine 会主动**让出**的情况。那要是一个 goroutine 不会等待 timer、channel、io 事件，就不用让出了吗？那必须不能呀。否则，调度器岂不成了摆设？

那怎么让那些不用等待的 goroutine 让出呢？这就是监控线程的另一个工作任务了，那就是本着公平调度的原则，对运行时间过长的 p 实行**抢占**操作。

就是告诉那些运行时间超过特定预值的 g 该让一让了。怎么知道运行时间过长了呢？

p里面有一个 schedtick 字段。每当调度执行一个新的 g ，并且不继承上个g的时间片时，就会把 schedtick 自增一。

p中还有 sysmontick， sysmontick.schedwhen 记录的是上一次调度的时间。

监控线程如果检测到 p.sysmontick.schedtick 与 p.schedtick 不相等，说明这个 p 又发生了新的调度，就会同步 p.sysmontick.schedtick 的调度次数，并更新这个调度时间p.sysmontick.schedwhen ；但是，若二者相等，那说明自 schedwhen 这个时间点之后，这个 p 并未发生新的调度，或者即使发生了新的调度，也沿用了之前 g 的时间片。

所以可以通过当前时间与 schedwhen 的差值来判断当前 p 上的 g 是否运行时间过长了。那如果真的运行时间过长了，要怎么通知他让出呢？

这就不得不提到栈增长了，除了对 协程栈没什么消耗的函数调用，go 语言编译器都会在函数头部插入栈增长相关代码。实际上，编译器插入的栈增长代码一共有三种。

![](./img/24.png)

如果栈帧比较小，小于`_StackSmall`，插入的代码就是这样的：这个 sp 表示当前 协程栈使用到了什么位置？stackguard0 就是 协程栈空间下届。所以当 协程栈的消耗达到或超过这个 stackguard0 位置时，就需要进行栈增长了。

如果栈帧大小处在`_StackSmall`和 `_StackBig` 之间，插入的代码就是这样的：也就是说，当前 协程栈使用到 sp 这，若再使用 framesize 这么多，超出 stackguard0 的部分大于`_StackSmall`了，就要进行栈增长了。

而对于栈帧大小超过`_StackBig`的函数，插入的代码就又有所不同了。判断是否要栈增长的方式本质上与第二种情况相同，而我们要关注的是这里的 stackPreempt ，它是和协程调度相关的重要标识。当 runtime 希望某个 goroutine 让出 cpu 时，就会把他的 stackgard0 赋值为 stackPreempt ，这是一个非常大的值，真正的栈指针不可能指向这个位置，所以可以安全的用作特殊标识，正因为 stackPreempt 这个值足够大，所以上面两段代码中的判断结果也都会为 true ，进而跳转到 morestack 处。而mostack这里最终会调用 runtime.newstack函数，它实际负责栈增长工作。不过，他在进行栈增长前会先判断 stackard0 是否等于 stackPreempt，等于的话，就不进行栈增长了，而是执行一次 协程调度，所以在 协程不主动让出时，也可以设置 stackprimpt 标识通知它让出。不过，这种抢占方式的缺陷就是过于依赖栈增长代码，如果那个空的for循环 `for{}`，因为与栈增长无关，监控线程等也无法通过设置stackPreempt 的标识来实现抢占，所以最终导致程序卡死。这一问题在1。14版本中得到了解决，因为它实现了异步抢占，具体实现在不同平台中不尽相同。例如，在unix平台中，会向 goroutine 关联的 m 发送信号，接下来，目标线程会被信号中断，转去执行 runtime.sigHandle 了。在 sigHandle 的函数中，检测到信号为 sigPreempt 后，就会调用rantm.doSigPreempt 函数，他会向当前被打断的 协程上下文中注入一个异步抢占函数调用。处理完信号后，sigHandle 返回，被中断的 goroutine 得到恢复，立刻执行被注入的异步抢占函数，该函数最终会调用runtime中的调度逻辑。这不就让出了吗？所以在1。14版本中，这段代码执行起来就不会卡死了。而监控线程的抢占方式又多了一种，异步抢占。

其实为了充分利用cpu，监控线程还会抢占处在系统调用中的p。

因为一个 goroutine 要执行系统调用，就要切换到 g0 栈。在系统调用没执行完之前，这个m和这个g算是抱团了，不能被分开，也就用不到p。

所以，在陷入系统调用之前，当前m会让出p，解除 m.p 与当前 P 的强关联，只在m.oldp 中记录这个 P。

P的数目毕竟有限，如果有其他 goroutine 在等待执行，那么放任p如此闲置就着实浪费了，还是把它关联到其他m继续工作比较划算。

不过，如果当前 m 从系统调用中恢复，会先检查之前的 p 是否被占用，没有的话就继续使用，否则再去申请一个，没申请到的话就把当前 g 放到全局 runq 中去，然后当前线程就睡眠了。

![](./img/25.png)

说了这么多，不是让出就是抢占，那让出了、抢占了之后。m也不能闲着得找到下一个待执行的 G 来运行。

这就是 schedule() 职责了，schedule 这里要给这个 m 找到一个带执行的 g，首先要确定当前 m 是否和当前 g 绑定了。如果绑定了，那当前 m 就不能执行其他 g，所以需要阻塞当前m，等到当前 g 再次得到调度执行时，自会把当前 m 唤醒；如果没有绑定，就先看看 GC 是不是在等待执行。全局变量 sched 这里有一个 gcwaiting 标识，如果 gc 在等待执行，就去执行 gc，回来再继续执行调度程序。

接下来，还会检查一下有没有要执行的 timer 调度程序，还有一定的几率会去全局runq中，获取一部分g到本地runq中。

而获取下一个待执行的 G 时，会先去本地 runq 有中查找，没有的话就调用 findrunable()，这个函数直到获取到待执行的g才会返回。

在 findrunable() 函数这里，也会判断是否要执行gc，然后先尝试从本地runq获取，没有的话，就从全局 runq 获取一部分。如果还没有，就先尝试执行netpoll。恢复那些 IO 事件已经就绪了的G，他们会被放回到全局runq中，然后才会尝试从其他 p 那里 still 一些任务。

当调度程序终于获得一个待执行的 G 之后，还要看看人家有没有绑定的 M，如果有的话，还得乖乖的把G还给对应的m，而当前m就不得不再次进行调度了。如果没有绑定的m就调用execute()函数在当前M上执行这个G。

execute() 函数这里。会建立当前 m 和这个 g 的关联关系，并把 g 的状态从 `_Grunable`修改为`_Grunning`。

如果不继承上一个执行中 goroutine 的时间片，就把p    这里的调度计数 p.schedtick 加一。最后会调用 gogo() 函数从g.sched这里恢复协程栈指针、指令指针等，继续执行。

之前介绍过 goroutine 创建时，会伪造一个执行现场存到 g.sched 中，所以即使这个 G 初次执行，也是有一个完美的执行现场的。

![](./img/26.png)

现在，我们已经知道 goroutine 在某些情况下会主动让出。但有时也需要通过设置 stackPreempt 的标识或异步抢占的方式来通知他让出。

也了解了调度程序如何获取待执行的G并把它运行起来。

其间还穿插介绍了监控线程的主要工作任务，保障计时器正常执行，执行网络轮巡，抢占长时间运行的或处在系统调用的p，这些都是为了保障程序健康高效的执行。

其实，监控线称还有一项任务就是强制执行GC，待带到内存管理部分再展开。



## GC

爱狗从进程虚拟地址空间来看。程序要执行的指令在代码段，全局变量，静态数据等都会分配在数据段。而函数的局部变量，参数和返回值都可以在函数栈帧中找到。但是，由于函数调用栈会在函数板回后销毁。如果不能在编译阶段确定数据对象的大小，或者对象生命周期会超出当前所在函数。那就不适合分配在栈上，而应该分配在堆上。随着程序的运行，有些数据便不会再用到了。直接分配在栈上的数据会随着函数调用栈的销毁。释放自身占用的内存，而这些在堆上分配的数据就不一样了。他们占用的内存需要程序主动释放才可以重新使用。否则，就会成为垃圾，而越积越多的垃圾会不断的消耗系统内存。有些编程语言需要程序员在编写程序时手动释放那些不再需要的分配在堆上的数据。这被称为手动垃圾回收。但是一旦释放的早了，后续对该数据的访问就会出错，因为被释放的内存可能已经被清空。或重新分配，甚至已经还给操作系统，这就是所谓的全挂指针问题。而如果忘了释放，他又会一直占用内存，出现内存泄漏。所以，越来越多的变成语言支持自动垃圾回收，由运行时识别不再有用的数据并释放它们占用的内存。内存何时被释放？被释放的内存如何处理，这些问题都不用我们操心，的确很方便。那么自动垃圾回收要怎么区分哪些数据对象是垃圾呢？还得从虚拟地址空间来看。可以确定的是，程序中用得到的数据一定是从占数据段这些跟结点追踪的到的数据。

虽然能够追踪的到，不代表后续一定会用到。但是从这些跟结点追踪不到的数据就一定不会被用到，也就一定是垃圾。所以，目前主流的垃圾回收算法都是使用可达性近似等价与存活性的。要识别存活对象，可以把占数据段上的数据对象作为root。基于他们进一步追踪，把能追踪到的数据都进行标记，剩下的追踪不到的就是垃圾了。这就是标记清扫算法的核心思想。三色抽象可以清晰的展现追踪式垃圾回收过程中对象状态的变化过程。垃圾回收开始时，所有数据都为白色，然后把直接追踪到的root节点都标记为灰色。灰色代表基于当前节点展开的追踪还未完成。当基于某个节点的追踪任务完成后，便会把该节点标记为黑色。表示他是存活数据，而且无需急于他再次进行追踪了。基于黑色界点找到的所有节点都被标记为灰色表示还要基于他们进一步展开追踪。当没有灰色节点时，就意味着标记工作可以结束了，此时有用数据都为黑色，垃圾都为白色。接下来，回收这些白色对象的内存即可。标记清扫算法实现起来相对简单，但是比较容易造成内存碎片化。而面对大量不连续的小分块内存，要找到合适的内存分块的代价更高。也会造成很多小块内存无法使用的情况。这一问题可以给予bigbugofpages的思想把内存块划分为多种大小规格。对相同规格的内存款进行统一管理。

这样可以更快的匹配到大小合适的空前内存规格类型划分的合理也有助于提高内存使用率。除此之外，还有人提出通过移动数据来减少碎片化的方法。例如，在标记整理算法中，标记阶段与标记清扫算法相同。但是，会在完成标记工作后移动非垃圾数据，是他们尽可能紧凑的放在内存中。虽然标记整理算法有效解决了内存碎片化的问题。但是带来的多次扫描与移动开销也不容小觑，还有一种复制式回收算法也会移动数据。他会把堆内存划分成两个相等的空间，from和two。程序执行时使用from空间。垃圾回收执行时会扫描from空间，把能追踪到的数据复制到two空间。当所有有用的数据都复制到two空间后，把from和two空间的角色交换一下。原来的two空间用作from，原来的from空间则可以全部回收作为新的two空间。这种复制式回收也不会带来碎片化问题，但是只有一半的对内存可以被使用。为了提高对内存的使用率，通常会和其他垃圾回收算法搭配使用。只在一部分对内存中使用复制式回收，例如，在分带回收中就经常搭配使用复制式回收。分代回收的提出主要是基于若分代假说，大部分对象都会在年轻时死亡。如果我们把新创建的对象成为新生代对象，把经受住特定次数的g，c。而依然存活的对象称为老年代对象，基于若分代价说，大部分对象会在最初经历的垃圾回收中死亡。

也就是说，新生代对象成为垃圾的概率高于老年代对象。所以，可以把数据划分为新生代和老年代，降低老年代执行垃圾回收的频率。不用每次都处理所有数据，将明显提升垃圾回收执行的效率。而且新生代和老年代还可以分别采用不同的回收策略，进一步提升回收效益并减少开销。到目前为止，我们介绍的多为追踪式回收，需要扫描堆内存来识别垃圾对象。而饮用技术是垃圾回收则有所不同。引用技术指的是一个数据对象被引用的次数，程序执行过程中会更新对象的引用技术。当饮用技术更新为零时，就表示这个对象不再有用，可以回收它占用的内存了。所以，在饮用技术法中，垃圾识别的任务已经分摊到每一次对数据对象的操作中了。虽然饮用技术法可以及时回收无用内存，但是高频率的更新饮用技术也会造成不小的开销。而且若是a引用了b，b也引用了a，形成循环引用。当a和b的饮用技术更新到只剩彼此的相互饮用时。饮用技术便无法更新到零。也就不能回收对应的内存了，到目前为止，我们的介绍还都是在暂停用户程序。只专注于进行垃圾回收的前提下，展开的，也就是所谓的stoptheworld。这首当其冲的问题就是，用户程序可以接受长时间的暂停吗？实际上，我们总是希望能够尽量缩短暂停的时间。可以将垃圾回收工作分多次完成，也就是用户程序与垃圾回收交替执行。

这被称为增量式垃圾回收，可以缩短每次暂停的时间。但是这也带来了额外的问题，交替执行的过程中保不齐垃圾回收程序前脚刚标记了一个黑色对象。用户程序后脚又修改了它。要是放任不管，垃圾回收程序就会把存活数据误判为垃圾，这里我们要再次用到三色抽象了。因为它不仅可以简洁的展示追踪式垃圾回收的推进过程，还可以帮助推演回收器的正确性。在三色抽象中，黑色对象已经处理完毕，不会被再次扫描。而灰色对象还会被回收器继续处理。所以，若出现黑色对象到白色对象的引用。同时，没有任何灰色对象可以抵达这个白色对象，它就会被判定为垃圾，但实际上它应该是存活数据。三色抽象清晰的描述了垃圾回收中把存活对象误判为垃圾的情况。如果能够做到不出现黑色对象到白色对象的引用，就必然不会出现这样的错误了。这被称为墙三色，不便是若把条件放宽一点，允许出现黑色对象到白色对象的引用。但是可以保证通过灰色对象可以抵达该白色对象，就也可以避免错误的回收。这被称为，若三色不变式，实现强弱，三色不变式的通常做法是建立读写屏障。写屏障会在写操作中插入指令。目的是把数据对象的修改通知到垃圾回收器。所以，写屏障通常都要有一个记录集，而记录集是采用顺序存储还是使用哈希表？记录精确到被修改的对象，还是只记录其所在的页等问题就是写屏障的具体实现要考虑的了。

墙三色不便是提醒我们关注白色指针向黑色对象的斜入操作。无论如何，不允许出现黑色对象到白色对象的饮用，可以把白色指针着为灰色。也可以把写入的黑色对象退回到灰色，这些都属于插入写屏障。而若三色不便是，则提醒我们关注对那些到白色对象路径的破坏行为。例如，要删除灰色对象到白色对象的饮用时，可以把白色对象卓为灰色。这种血屏障属于删除血屏障，再来看看毒屏障。非移动式垃圾回收器中天然的不需要毒屏障。但如果想复制时回收起，这样会移动数据来避免碎片化。那么，g，c和用户程序交替执行时。读数据便也不那么安全了，例如，回收器已经把a复制到two空间去了。之后，交替执行的用户程序却读取了from空间中的陈旧对象。而回收起后续复制b到吐空间时，b的新副本持有的便是a的成就对象指针。当from空间整体被回收，对原from空间中a的访问便会出错。这种情况下，就要建立毒屏障，确保用户程序不会访问到已经存在新副本的成就对象。例如，在检测到引用对象已经存在新副本时，转而读取吐空间的新副本。至此，我们的讨论都还没有超出单核的范畴，而实际应用中不得不考虑多核的场景。暂停用户程序的前提下，多现成病型执行垃圾回收程序，这被称为病型垃圾回收。原本由一个县城全权负责的任务，现在需要分几份交给多个县城。

那么分工不均就会导致有的县城忙死有的县城闲死。而实现较好的复杂均衡，却会增加县城间的同步开销。并形场景下同步似乎是不可回避的问题。否则，就连一轮垃圾回收何时结束也很难愉快的决定。有些垃圾回收器在病形场景下还得规避重复处理数据的问题。例如，复制时回收期在病形场景下。必须要避免数据对象被不同现成重复复制，否则可能造成数据不一致。并发垃圾回收指的是用户程序与垃圾回收程序并发执行。在多核场景下。就会存在用户程序和垃圾回收程序并行执行的情况。这和病型垃圾回收中只考虑垃圾回收程序的病型执行是不同的。就拿写屏障来说，多盒并发场景下，用户程序和回收器可能会同时使用写屏障记录器。所以，并发写屏障的设计还要考虑到用户程序之间，以及与垃圾回收程序之间的竞争问题。如果没有任何stoptheworld的时间，那么垃圾回收开始的消息便很难准确及时的通知到所有现场。可能导致某些县城开启写屏障的动作有所延迟而发生错误，所以实际应用中。在某些阶段采取stoptheworld的方式，在其他阶段支持并发的主体，并发式垃圾回收更容易实现。若在此基础上再支持增量式回收，那便属于主体并发增量式回收。这一次，我们介绍了自动垃圾回收的基本概念。以及集中主流垃圾回收算法的核心思想。

还了解了stoptheworld，增量式病形与病发等垃圾回收运行模式。以及必要的读写屏障知识。够语言的垃圾回收，采用标记清扫算法。支持主体并发，增量式回收，使用插入与删除两种血屏障结合的混合血屏障。下一次就继续来看够语言的gc。







爱狗从进程虚拟地址空间来看。程序要执行的指令在代码段，全局变量，静态数据等都会分配在数据段。而函数的局部变量，参数和返回值都可以在函数栈帧中找到。但是，由于函数调用栈会在函数板回后销毁。如果不能在编译阶段确定数据对象的大小，或者对象生命周期会超出当前所在函数。那就不适合分配在栈上，而应该分配在堆上。随着程序的运行，有些数据便不会再用到了。直接分配在栈上的数据会随着函数调用栈的销毁。释放自身占用的内存，而这些在堆上分配的数据就不一样了。他们占用的内存需要程序主动释放才可以重新使用。否则，就会成为垃圾，而越积越多的垃圾会不断的消耗系统内存。有些编程语言需要程序员在编写程序时手动释放那些不再需要的分配在堆上的数据。这被称为手动垃圾回收。但是一旦释放的早了，后续对该数据的访问就会出错，因为被释放的内存可能已经被清空。或重新分配，甚至已经还给操作系统，这就是所谓的全挂指针问题。而如果忘了释放，他又会一直占用内存，出现内存泄漏。所以，越来越多的变成语言支持自动垃圾回收，由运行时识别不再有用的数据并释放它们占用的内存。内存何时被释放？被释放的内存如何处理，这些问题都不用我们操心，的确很方便。那么自动垃圾回收要怎么区分哪些数据对象是垃圾呢？还得从虚拟地址空间来看。可以确定的是，程序中用得到的数据一定是从占数据段这些跟结点追踪的到的数据。

虽然能够追踪的到，不代表后续一定会用到。但是从这些跟结点追踪不到的数据就一定不会被用到，也就一定是垃圾。所以，目前主流的垃圾回收算法都是使用可达性近似等价与存活性的。要识别存活对象，可以把占数据段上的数据对象作为root。基于他们进一步追踪，把能追踪到的数据都进行标记，剩下的追踪不到的就是垃圾了。这就是标记清扫算法的核心思想。三色抽象可以清晰的展现追踪式垃圾回收过程中对象状态的变化过程。垃圾回收开始时，所有数据都为白色，然后把直接追踪到的root节点都标记为灰色。灰色代表基于当前节点展开的追踪还未完成。当基于某个节点的追踪任务完成后，便会把该节点标记为黑色。表示他是存活数据，而且无需急于他再次进行追踪了。基于黑色界点找到的所有节点都被标记为灰色表示还要基于他们进一步展开追踪。当没有灰色节点时，就意味着标记工作可以结束了，此时有用数据都为黑色，垃圾都为白色。接下来，回收这些白色对象的内存即可。标记清扫算法实现起来相对简单，但是比较容易造成内存碎片化。而面对大量不连续的小分块内存，要找到合适的内存分块的代价更高。也会造成很多小块内存无法使用的情况。这一问题可以给予bigbugofpages的思想把内存块划分为多种大小规格。对相同规格的内存款进行统一管理。

这样可以更快的匹配到大小合适的空前内存规格类型划分的合理也有助于提高内存使用率。除此之外，还有人提出通过移动数据来减少碎片化的方法。例如，在标记整理算法中，标记阶段与标记清扫算法相同。但是，会在完成标记工作后移动非垃圾数据，是他们尽可能紧凑的放在内存中。虽然标记整理算法有效解决了内存碎片化的问题。但是带来的多次扫描与移动开销也不容小觑，还有一种复制式回收算法也会移动数据。他会把堆内存划分成两个相等的空间，from和two。程序执行时使用from空间。垃圾回收执行时会扫描from空间，把能追踪到的数据复制到two空间。当所有有用的数据都复制到two空间后，把from和two空间的角色交换一下。原来的two空间用作from，原来的from空间则可以全部回收作为新的two空间。这种复制式回收也不会带来碎片化问题，但是只有一半的对内存可以被使用。为了提高对内存的使用率，通常会和其他垃圾回收算法搭配使用。只在一部分对内存中使用复制式回收，例如，在分带回收中就经常搭配使用复制式回收。分代回收的提出主要是基于若分代假说，大部分对象都会在年轻时死亡。如果我们把新创建的对象成为新生代对象，把经受住特定次数的g，c。而依然存活的对象称为老年代对象，基于若分代价说，大部分对象会在最初经历的垃圾回收中死亡。

也就是说，新生代对象成为垃圾的概率高于老年代对象。所以，可以把数据划分为新生代和老年代，降低老年代执行垃圾回收的频率。不用每次都处理所有数据，将明显提升垃圾回收执行的效率。而且新生代和老年代还可以分别采用不同的回收策略，进一步提升回收效益并减少开销。到目前为止，我们介绍的多为追踪式回收，需要扫描堆内存来识别垃圾对象。而饮用技术是垃圾回收则有所不同。引用技术指的是一个数据对象被引用的次数，程序执行过程中会更新对象的引用技术。当饮用技术更新为零时，就表示这个对象不再有用，可以回收它占用的内存了。所以，在饮用技术法中，垃圾识别的任务已经分摊到每一次对数据对象的操作中了。虽然饮用技术法可以及时回收无用内存，但是高频率的更新饮用技术也会造成不小的开销。而且若是a引用了b，b也引用了a，形成循环引用。当a和b的饮用技术更新到只剩彼此的相互饮用时。饮用技术便无法更新到零。也就不能回收对应的内存了，到目前为止，我们的介绍还都是在暂停用户程序。只专注于进行垃圾回收的前提下，展开的，也就是所谓的stoptheworld。这首当其冲的问题就是，用户程序可以接受长时间的暂停吗？实际上，我们总是希望能够尽量缩短暂停的时间。可以将垃圾回收工作分多次完成，也就是用户程序与垃圾回收交替执行。

这被称为增量式垃圾回收，可以缩短每次暂停的时间。但是这也带来了额外的问题，交替执行的过程中保不齐垃圾回收程序前脚刚标记了一个黑色对象。用户程序后脚又修改了它。要是放任不管，垃圾回收程序就会把存活数据误判为垃圾，这里我们要再次用到三色抽象了。因为它不仅可以简洁的展示追踪式垃圾回收的推进过程，还可以帮助推演回收器的正确性。在三色抽象中，黑色对象已经处理完毕，不会被再次扫描。而灰色对象还会被回收器继续处理。所以，若出现黑色对象到白色对象的引用。同时，没有任何灰色对象可以抵达这个白色对象，它就会被判定为垃圾，但实际上它应该是存活数据。三色抽象清晰的描述了垃圾回收中把存活对象误判为垃圾的情况。如果能够做到不出现黑色对象到白色对象的引用，就必然不会出现这样的错误了。这被称为墙三色，不便是若把条件放宽一点，允许出现黑色对象到白色对象的引用。但是可以保证通过灰色对象可以抵达该白色对象，就也可以避免错误的回收。这被称为，若三色不变式，实现强弱，三色不变式的通常做法是建立读写屏障。写屏障会在写操作中插入指令。目的是把数据对象的修改通知到垃圾回收器。所以，写屏障通常都要有一个记录集，而记录集是采用顺序存储还是使用哈希表？记录精确到被修改的对象，还是只记录其所在的页等问题就是写屏障的具体实现要考虑的了。

墙三色不便是提醒我们关注白色指针向黑色对象的斜入操作。无论如何，不允许出现黑色对象到白色对象的饮用，可以把白色指针着为灰色。也可以把写入的黑色对象退回到灰色，这些都属于插入写屏障。而若三色不便是，则提醒我们关注对那些到白色对象路径的破坏行为。例如，要删除灰色对象到白色对象的饮用时，可以把白色对象卓为灰色。这种血屏障属于删除血屏障，再来看看毒屏障。非移动式垃圾回收器中天然的不需要毒屏障。但如果想复制时回收起，这样会移动数据来避免碎片化。那么，g，c和用户程序交替执行时。读数据便也不那么安全了，例如，回收器已经把a复制到two空间去了。之后，交替执行的用户程序却读取了from空间中的陈旧对象。而回收起后续复制b到吐空间时，b的新副本持有的便是a的成就对象指针。当from空间整体被回收，对原from空间中a的访问便会出错。这种情况下，就要建立毒屏障，确保用户程序不会访问到已经存在新副本的成就对象。例如，在检测到引用对象已经存在新副本时，转而读取吐空间的新副本。至此，我们的讨论都还没有超出单核的范畴，而实际应用中不得不考虑多核的场景。暂停用户程序的前提下，多现成病型执行垃圾回收程序，这被称为病型垃圾回收。原本由一个县城全权负责的任务，现在需要分几份交给多个县城。

那么分工不均就会导致有的县城忙死有的县城闲死。而实现较好的复杂均衡，却会增加县城间的同步开销。并形场景下同步似乎是不可回避的问题。否则，就连一轮垃圾回收何时结束也很难愉快的决定。有些垃圾回收器在病形场景下还得规避重复处理数据的问题。例如，复制时回收期在病形场景下。必须要避免数据对象被不同现成重复复制，否则可能造成数据不一致。并发垃圾回收指的是用户程序与垃圾回收程序并发执行。在多核场景下。就会存在用户程序和垃圾回收程序并行执行的情况。这和病型垃圾回收中只考虑垃圾回收程序的病型执行是不同的。就拿写屏障来说，多盒并发场景下，用户程序和回收器可能会同时使用写屏障记录器。所以，并发写屏障的设计还要考虑到用户程序之间，以及与垃圾回收程序之间的竞争问题。如果没有任何stoptheworld的时间，那么垃圾回收开始的消息便很难准确及时的通知到所有现场。可能导致某些县城开启写屏障的动作有所延迟而发生错误，所以实际应用中。在某些阶段采取stoptheworld的方式，在其他阶段支持并发的主体，并发式垃圾回收更容易实现。若在此基础上再支持增量式回收，那便属于主体并发增量式回收。这一次，我们介绍了自动垃圾回收的基本概念。以及集中主流垃圾回收算法的核心思想。

还了解了stoptheworld，增量式病形与病发等垃圾回收运行模式。以及必要的读写屏障知识。够语言的垃圾回收，采用标记清扫算法。支持主体并发，增量式回收，使用插入与删除两种血屏障结合的混合血屏障。下一次就继续来看够语言的gc。